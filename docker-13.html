<!DOCTYPE html><html lang="zh"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="baidu-site-verification" content="erIKW497yS"><meta name="google-site-verification" content="UgdHTfiMSYvSc5WkTMWIBaRheQv9f_np2Dm0RUlPFco"><title> Docker笔记（十三）：容器日志采集实践 · 空山新雨的技术空间</title><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content="Docker笔记（十三）：容器日志采集实践 - 空山新雨"><meta name="keywords" content="Spring,DevOps,技术管理"><meta name="author" content="空山新雨"><link rel="short icon" href="/images/favicon.ico"><link rel="stylesheet" href="/css/bubuzou.css"><link rel="search" type="application/opensearchdescription+xml" href="http://blog.jboost.cn/atom.xml" title="空山新雨的技术空间"><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="//unpkg.com/valine/dist/Valine.min.js"></script></head><body><header><div class="header row"> <a href="/" class="logo-link"><img src="/images/logo.png"></a><ul id="nav_list" class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" data-hover="博文" class="nav-list-link">博文</a></li><li class="nav-list-item"><a href="/archives/" target="_self" data-hover="归档" class="nav-list-link">归档</a></li><li class="nav-list-item"><a href="/about/" target="_self" data-hover="关于" class="nav-list-link">关于</a></li></ul><div class="search"><a id="search_btn" href="#search"></a></div><div id="nav_btn" class="nav-btn"><span></span><span></span><span></span></div></div></header><div class="row scroll-con"><section class="container"><!-- for archive page--><div id="postAr" class="post"><article class="post-block"><h1 class="post-title">Docker笔记（十三）：容器日志采集实践</h1><div class="post-info">2020-04-01<p class="visit"><i data-identity="docker-13.html" class="article-timer"></i><span>次访问</span></p></div><div class="post-content"><p>日志是服务运行过程中的一个关键环节，借助日志，我们可以排查定位问题，也可以借助集中化的日志管理平台（如ELK）来做一些必要的数据统计分析。在Docker环境中，日志的采集比传统环境更为复杂，因此了解Docker日志的管理机制，及基于此熟悉日志采集的最佳实践对于开发运维人员来说也是避不开的一个知识点。那就开始吧。</p>
<a id="more"></a>
<h2 id="Docker容器的日志管理机制"><a href="#Docker容器的日志管理机制" class="headerlink" title="Docker容器的日志管理机制"></a>Docker容器的日志管理机制</h2><h3 id="1-Docker-Daemon日志"><a href="#1-Docker-Daemon日志" class="headerlink" title="1. Docker Daemon日志"></a>1. Docker Daemon日志</h3><p>Docker Daemon在Linux中本身作为systemd service启动，因此可以通过 <code>sudo journalctl -u docker</code> 命令来查看Daemon本身的日志。</p>
<h3 id="2-Docker容器日志"><a href="#2-Docker容器日志" class="headerlink" title="2. Docker容器日志"></a>2. Docker容器日志</h3><p>通过 <code>docker logs container_id|container_name</code> 可以查看Docker容器的输出日志，但这里的日志只包含容器的标准输出（STDOUT）与标准错误输出（STDERR），适用于一些将日志输出到STDOUT的容器,比如Nginx，查看nginx的dockerfile可发现其是将日志文件链接到了STDOUT与STDERR来实现的，</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RUN ln -sf /dev/stdout /var/log/nginx/access.log</span><br><span class="line">&amp;&amp; ln -sf /dev/stderr /var/log/nginx/error.log</span><br></pre></td></tr></table></figure>
<p>但如果容器内部应用日志是输出到日志文件（比如Spring Boot项目或Tomcat容器，一般将日志输出到日志文件中），则无法通过 <code>docker logs</code> 命令查看。</p>
<blockquote>
<p><code>docker logs</code> 会显示历史日志，日志太多的话要等半天才能看到最新日志，同时也对Docker Daemon造成一定的压力，可使用 <code>docker logs --tail 200 container_id</code>来查看最新的N条或使用<code>docker logs -f container_id</code>（类似于tail -f）</p>
</blockquote>
<h3 id="3-Docker日志处理机制"><a href="#3-Docker日志处理机制" class="headerlink" title="3. Docker日志处理机制"></a>3. Docker日志处理机制</h3><p>当我们启动一个容器时，其实是作为Docker Daemon的一个子进程运行，Docker Daemon可以拿到容器里进程的标准输出与标准错误输出，然后通过Docker的Log Driver模块来处理。如下图所示</p>
<p><img src="/assets/docker-log-driver.png" alt="docker-log-driver.png"></p>
<p>目前支持的Log Drvier包括：</p>
<ul>
<li>none：容器没有日志，<code>docker logs</code>不输出任何内容</li>
<li>local：日志以自定义格式存储</li>
<li>json-file：日志以json格式存储，默认的Log Driver</li>
<li>syslog：将日志写入syslog。syslog守护程序必须在主机上运行</li>
<li>journald：将日志写入journald。journald守护程序必须在主机上运行</li>
<li>gelf：将日志写入Graylog Extended Log Format端点，如Graylog或Logstash</li>
<li>fluentd：将日志写入fluentd。fluentd守护程序必须在主机上运行</li>
<li>awslogs：将日志写入Amazon CloudWatch Logs</li>
<li>splunk：通过HTTP Event Collector将日志写入splunk</li>
<li>etwlogs：将日志作为ETW（Event Tracing for Windows）事件写入。只在Windows平台可用</li>
<li>gcplogs：将日志写入Google Cloud Platform Logging</li>
<li>logentries：将日志写入Rapid7 Logentries</li>
</ul>
<p>使用Docker-CE版本时，<strong><code>docker logs</code>命令仅适用于 local， json-file， journald 三种Log Driver</strong>。</p>
<p>可通过<code>docker info</code>来查看Docker Daemon（针对所有容器）或<code>docker inspect</code>来查看单个容器所使用的Log Driver</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Docker Daemon</span></span><br><span class="line">[devuser@test-server-1 ~]$ docker  info |grep  "Logging Driver"</span><br><span class="line">Logging Driver: json-file</span><br><span class="line"><span class="meta">#</span><span class="bash"> 单个Docker 容器</span></span><br><span class="line">[devuser@test-server-1 ~]$ docker inspect  -f '&#123;&#123;.HostConfig.LogConfig.Type&#125;&#125;'  76f82aa32468</span><br><span class="line">json-file</span><br></pre></td></tr></table></figure>
<p>修改Docker Daemon使用的Log Driver可通过修改配置文件 /etc/docker/daemon.json 进行，重启Docker后该配置对该Docker Daemon管理的所有容器生效， 如</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"log-driver"</span>: <span class="string">"local"</span>,</span><br><span class="line">    <span class="attr">"log-opts"</span>: &#123;</span><br><span class="line">        <span class="attr">"max-size"</span>: <span class="string">"10m"</span>,</span><br><span class="line">        <span class="attr">"max-file"</span>: <span class="number">3</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>设置单个容器的Log Driver则可以在容器运行时通过参数指定，如</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@tool-server ~]# docker run -d --name nginx -p 80:80 --log-driver local  --log-opt max-size=10m  --log-opt max-file=3  --restart=always nginx</span><br><span class="line">63155291e724276d6154a26958b0e523a003958b1cdf7df9f1f0903bfc989b99</span><br><span class="line"></span><br><span class="line">[root@tool-server ~]# tail -f /var/lib/docker/containers/63155291e724276d6154a26958b0e523a003958b1cdf7df9f1f0903bfc989b99/local-logs/container.log</span><br><span class="line">stdoutҭʡ󹾖ā192.168.40.160 - - [02/Apr/2020:06:05:56 +0000] "GET / HTTP/1.1" 200 612 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36" "-"ܻ </span><br><span class="line">stdout򪸶¡󹾖㿱92.168.40.160 - - [02/Apr/2020:06:05:56 +0000] "GET /favicon.ico HTTP/1.1" 404 555 "http://192.168.40.110/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36" "-"</span><br></pre></td></tr></table></figure>
<p>以下对常用的几种Log Driver进行详细介绍</p>
<ol>
<li>local</li>
</ol>
<p>local Log Driver会将容器的STDOUT/STDERR输出写到宿主机的磁盘。前面示例了将Docker Daemon或单个容器的Log Driver设置为local，可以看到local的日志保存路径为 <code>/var/lib/docker/containers/{container_id}/local-logs/container.log</code></p>
<p>local Log Driver支持的配置属性如下</p>
<table>
<thead>
<tr>
<th style="text-align:left">配置属性</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">max-size</td>
<td style="text-align:left">单个日志文件的最大大小，默认为20m（单位可为k,m,g）</td>
</tr>
<tr>
<td style="text-align:left">max-file</td>
<td style="text-align:left">最多存在多少个日志文件，文件数超过该值则会删除最旧的文件，默认为5</td>
</tr>
<tr>
<td style="text-align:left">compress</td>
<td style="text-align:left">是否对切割文件进行压缩，默认为true</td>
</tr>
</tbody>
</table>
<ol start="2">
<li>json-file</li>
</ol>
<p>json-file Log Driver是Docker默认启用的Driver，将容器的STDOUT/STDERR输出以json的格式写到宿主机的磁盘，日志文件路径为 <code>/var/lib/docker/containers/{container_id}/{container_id}-json.log</code></p>
<p>格式如下，包含三个字段： log, stream, time。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@tool-server ~]# tail -f /var/lib/docker/containers/2cef9daeac7b009c636ed2b1a7ad8fe3342bc0d5dcd55e69d7a45a586d7abc47/2cef9daeac7b009c636ed2b1a7ad8fe3342bc0d5dcd55e69d7a45a586d7abc47-json.log</span><br><span class="line">&#123;"log":"2020-03-31T10:27:30.639+0000 I  SHARDING [conn4] Marking collection yapi.project as collection version: \u003cunsharded\u003e\n","stream":"stdout","time":"2020-03-31T10:27:30.639749587Z"&#125;</span><br><span class="line">&#123;"log":"2020-03-31T10:27:30.756+0000 I  SHARDING [conn2] Marking collection yapi.log as collection version: \u003cunsharded\u003e\n","stream":"stdout","time":"2020-03-31T10:27:30.756744876Z"&#125;</span><br></pre></td></tr></table></figure>
<p>json-file将日志的每一行封装到一个json串中，因此像Java的异常栈日志将会被拆分为多条json，在导入到ELK日志管理系统中时需要做合并处理。</p>
<p>json-file Log Driver支持的配置属性如下</p>
<table>
<thead>
<tr>
<th style="text-align:left">配置属性</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">max-size</td>
<td style="text-align:left">单个日志文件的最大大小，单位可为k,m,g。默认-1，表示无限制</td>
</tr>
<tr>
<td style="text-align:left">max-file</td>
<td style="text-align:left">最多存在多少个日志文件，文件数超过该值则会删除最旧的文件，默认为1</td>
</tr>
<tr>
<td style="text-align:left">labels</td>
<td style="text-align:left">在启动Docker容器时以逗号分隔的与日志相关的标签列表</td>
</tr>
<tr>
<td style="text-align:left">env</td>
<td style="text-align:left">在启动Docker容器时以逗号分隔的与日志相关的环境变量列表</td>
</tr>
<tr>
<td style="text-align:left">env-regex</td>
<td style="text-align:left">类似于env，用于匹配与日志相关的环境变量的正则表达式</td>
</tr>
<tr>
<td style="text-align:left">compress</td>
<td style="text-align:left">是否对切割文件进行压缩，默认为disabled</td>
</tr>
</tbody>
</table>
<ol start="3">
<li>journald</li>
</ol>
<p>journald Log Driver将容器的STDOUT/STDERR发送到systemd journal，与local，json-file一样可以使用 <code>docker logs</code> 来查看。也可以使用 journalctl命令来查看，如</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@tool-server ~]# docker run -d --name nginx -p 80:80 --log-driver journald  --log-opt labels=profile  --log-opt env=ONLINE --label profile=dev --env "ONLINE=false"  --restart=always nginx</span><br><span class="line">2011dc967d7e068b14d974bdc083d072fd09498a7de74984d482897d1b5c4200</span><br><span class="line"></span><br><span class="line">[root@tool-server ~]# journalctl -f CONTAINER_NAME=nginx</span><br><span class="line">-- Logs begin at Tue 2020-03-31 18:24:36 CST. --</span><br><span class="line"></span><br><span class="line">Apr 02 18:20:05 tool-server 2011dc967d7e[3655]: 192.168.40.160 - - [02/Apr/2020:10:20:05 +0000] "GET / HTTP/1.1" 304 0 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36" "-"</span><br></pre></td></tr></table></figure>
<p>journalctl的命令形式</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">journalctl CONTAINER_NAME=nginx # 输出指定容器的日志</span><br><span class="line">journalctl -b CONTAINER_NAME=nginx # 输出从上次启动以来的所有日志</span><br><span class="line">journalctl -o json CONTAINER_NAME=nginx # 以json格式显示日志，包含了label，env中指定的属性值</span><br><span class="line">journalctl -f CONTAINER_NAME=nginx  # 类似于tail -f</span><br></pre></td></tr></table></figure>
<p>journald Log Driver支持的配置属性如下</p>
<table>
<thead>
<tr>
<th style="text-align:left">配置属性</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">tag</td>
<td style="text-align:left">指定要在日志中设置CONTAINER_TAG与SYSLOG_IDENTIFIER值的模板</td>
</tr>
<tr>
<td style="text-align:left">labels</td>
<td style="text-align:left">定义一个标签列表，可在后面通过 –label 设置标签的值，该标签值会包含在日志体中</td>
</tr>
<tr>
<td style="text-align:left">env</td>
<td style="text-align:left">定义一个环境变量列表，可在后面通过 –env 指定环境变量的值，并且值会包含在日志体重</td>
</tr>
<tr>
<td style="text-align:left">env-regex</td>
<td style="text-align:left">与env类似，用于匹配与日志相关的环境变量的正则表达式</td>
</tr>
</tbody>
</table>
<p>下图是使用 <code>journalctl -o json CONTAINER_NAME=nginx</code> 命令输出的完整json格式日志，其中包含了前面设置的profile标签与ONLINE环境变量。<br><img src="/assets/docker-journald-log.png" alt="docker-journald-log"></p>
<p>除此之外，journald日志体中还会加上下面的数据</p>
<ul>
<li>CONTAINER_ID： 容器ID，12位</li>
<li>CONTAINER_ID_FULL：完整的容器ID，64位</li>
<li>CONTAINER_NAME：容器名称</li>
<li>CONTAINER_TAG，SYSLOG_IDENTIFIER：容器的tag</li>
</ul>
<p>具体从上图也可以看出。</p>
<ol start="4">
<li>syslog</li>
</ol>
<p>syslog Log Driver将日志发送到syslog的服务器，在Linux中，一般使用rsyslog服务。</p>
<p>修改rsyslog配置，打开udp或tcp监听</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@tool-server ~]# vim /etc/rsyslog.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> Provides UDP syslog reception</span></span><br><span class="line"><span class="meta">$</span><span class="bash">ModLoad imudp</span></span><br><span class="line"><span class="meta">$</span><span class="bash">UDPServerRun 514</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Provides TCP syslog reception</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="variable">$ModLoad</span> imtcp</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="variable">$InputTCPServerRun</span> 514</span></span><br></pre></td></tr></table></figure>
<p>重启rsyslog</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@tool-server ~]# systemctl restart  rsyslog</span><br><span class="line"></span><br><span class="line">[root@tool-server ~]# netstat -ano|grep 514</span><br><span class="line">udp        0      0 0.0.0.0:514             0.0.0.0:*                           off (0.00/0/0)</span><br><span class="line">udp6       0      0 :::514                  :::*                                off (0.00/0/0)</span><br></pre></td></tr></table></figure>
<p>以syslog Log Driver启动nginx容器</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@tool-server ~]# docker run -d --name nginx -p 80:80 --log-driver syslog --log-opt syslog-address=udp://127.0.0.1:514  --restart=always nginx</span><br><span class="line">989db94a01c36b7ea767bcb8db8ccc64bd558291ef7bcb364efa1352c78b8878</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看syslog日志</span></span><br><span class="line">[root@tool-server ~]# tail -f /var/log/messages</span><br><span class="line">Apr  2 18:58:06 localhost 989db94a01c3[3655]: 192.168.40.160 - - [02/Apr/2020:10:58:06 +0000] "GET / HTTP/1.1" 304 0 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36" "-"</span><br></pre></td></tr></table></figure>
<h2 id="容器日志采集实践"><a href="#容器日志采集实践" class="headerlink" title="容器日志采集实践"></a>容器日志采集实践</h2><ol>
<li><p>对于使用STDOUT/STDERR输出日志的容器，比如nginx，可通过默认的json-file，从前文提到的目录下通过filebeat或logstash进行监听采集</p>
</li>
<li><p>对于使用日志文件记录的容器，比如tomcat，可通过目录挂载的方式将容器日志目录挂载到宿主机目录，然后监听宿主机目录进行日志采集，比如启动时指定参数 <code>-v /data/tomcat/logs:/usr/local/tomcat/logs</code>。但这种方式如果同一应用的容器在一个服务器节点上启动多个时，会造成日志文件名相同产生冲突，对于这种情况，如果使用的是logback日志框架，之前的文章<a href="https://mp.weixin.qq.com/s/ql22PC_PJQ-0SuJyXpf4TQ" target="_blank" rel="noopener">自定义logback日志文件的名称</a> 提供了一种方案</p>
</li>
<li><p>如果既有标准输出又有日志文件输出，可考虑第三方日志采集框架，比如阿里巴巴开源的log-pilot</p>
</li>
<li><p>如果是Serverless环境，即没有具体的物理机或虚拟机，通过云容器服务部署的情况，则可以通过挂载云盘的方式，将容器日志目录挂载到云盘目录下，通过监听云盘目录进行日志采集</p>
</li>
</ol>
<p>出于篇幅与时间关系，这里只列出几种不同场景的日志采集方案，1,2场景比较好理解，对于4一般云平台都有相关的文档可查阅，场景3后续可再整理一篇实操文来补充说明。</p>
<hr>
<p>作者：空山新雨<br>近期作者写了几十篇技术博客，内容包括Java、Spring Boot、Spring Cloud、Docker，技术管理心得等<br>欢迎关注作者微信公众号：空山新雨的技术空间，一起学习成长  </p>
<p><img src="/assets/qrcode-05.jpg" alt="微信公众号"></p>
</div></article></div><div class="right-container"><div class="widget"><div id="arAnchorBar"></div></div></div></section></div><div class="right-menu"></div><div class="modal search-modal"><div class="input-field"><input type="text" id="search_input"><label for="search-input">搜索</label></div><div id="search_result" class="search-result"></div></div><div class="blog-overlay"></div><footer class="row"><div class="footer-con"><div class="paginator"><a href="/ansible.html" title="Ansible简明教程" class="prev">PREV</a><a href="/linux-autoboot.html" title="Linux开机自启动配置" class="next">NEXT</a></div><a href="#comment" class="comment-anchor"></a><div id="vcomments"></div><script>new Valine({
    el: "#vcomments",
    appId: "g1Ew6IgbqodabnGjq0nDI39n-gzGzoHsz",
    appKey: "PhFNiYoBJ1Fge6n8stpsfggG",
    notify: false,
    verify: false,
    avatar: "robohash",
    visitor: true,
    placeholder: "随便说点什么～.～",
});</script><div class="copyright"><p>© 2019 - 2020 <a target="_blank">空山新雨</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> <br> and <a href="https://github.com/Bulandent/hexo-theme-bubuzou" target="_blank">hexo-theme-bubuzou</a></p><p> <span style="padding-right: 6px;"> </span></p></div><div class="totop"><i></i></div></div></footer><script async src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script src="/scripts/jquery-1.8.2.min.js"></script><script src="/scripts/ar-anchor.js"></script><script src="/scripts/main.js"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-65933410-1",'auto');ga('send','pageview');</script><script>const valineAPI = (() => {
try {
    AV.init("g1Ew6IgbqodabnGjq0nDI39n-gzGzoHsz", "PhFNiYoBJ1Fge6n8stpsfggG");
} catch(error) {}
const isExist = (identity) => {
    identity = identity || getRealPath();
    let query = new AV.Query('Timer');
    return new Promise((resolve, reject) => {
    query.equalTo("identity", identity);
    query.find().then(results => {
        resolve(results.length > 0);
    }, error => reject(error));
    })
}

const _get = (identity) => {
    let query = null;
    if(identity && identity instanceof Array){
    let querys = [];
    for(let i = 0; i < identity.length; ++i) {
        querys[i] = new AV.Query('Timer');
        querys[i].equalTo('identity', identity[i]);
    }
    query = AV.Query.or.apply(null ,querys);
    } else {
    identity = identity || getRealPath();
    query = new AV.Query("Timer");
    query.equalTo("identity", identity);
    }

    return new Promise((resolve, reject) => {
    query.find()
    .then(results => resolve(results))
    .catch(error => reject(error))
    })
}

const create = (identity) => {
    identity = identity || getRealPath();
    return new Promise((resolve, reject) => {
    let Todo = AV.Object.extend('Timer');
    let todo = new Todo();
    todo.set("times", 1);
    todo.set("identity", identity);
    todo.save().then(res => resolve(true), error => reject(error));
    })
}

const update = (identity) => {
    identity = identity || getRealPath();
    return new Promise((resolve, reject) => {
    let query = new AV.Query('Timer');
    query.equalTo("identity", identity);
    query.find().then(todos => {
        todos.forEach(todo => {
        todo.set("times", todo.attributes.times + 1);
        });
        return AV.Object.saveAll(todos);
    }).then(todos => resolve(true), error => reject(error));
    })
}

return {
    isExist,
    _get,
    update,
    create
}
})()

const calcAndWriteTimes = () => {
let isPost = true;

let timerAllDOM = document.querySelectorAll(".article-timer");

if(isPost) {
    let identity = timerAllDOM[0].getAttribute("data-identity");
    valineAPI.isExist(identity)
    .then(exist => {
    if(exist) {
        return valineAPI.update(identity);
    }
    return new Promise(resolve => resolve(true));
    })
    .then( succuess => valineAPI._get(identity))
    .then( result => timerAllDOM[0].innerText = result[0].attributes.times)
    .catch(error => console.log(error.message))
    return ;
}

let timerDOMCache = {};

for(let timerDOM of timerAllDOM) {
    let identity = timerDOM.getAttribute("data-identity");
    if(timerDOMCache.hasOwnProperty(identity)){
    timerDOMCache[identity].dom.push(timerDOM);
    }else{
    timerDOMCache[identity] = {
        dom: [timerDOM],
        times: undefined
    };
    }
}

let identities = Object.keys(timerDOMCache);
valineAPI._get(identities).then(results => {
    for(let result of results) {
    let {identity, times} = result.attributes;
    timerDOMCache[identity].times = times;
    timerDOMCache[identity].dom.map(item => item.innerText = times);
    }
    for(let identity of identities) {
    if(timerDOMCache[identity].times){
        continue;
    }
    timerDOMCache[identity].dom.map(item => item.innerText = 1);
    valineAPI.create(identity);
    }
}).catch(error => console.log(error.message))
}

if(true){
calcAndWriteTimes();
}</script></body></html>