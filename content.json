{"meta":{"title":"空山新雨","subtitle":null,"description":"分享技术与管理的点滴","author":"ronwxy","url":"http://blog.jboost.cn","root":"/"},"pages":[{"title":"关于我","date":"2019-06-05T08:11:27.000Z","updated":"2019-07-09T11:18:59.689Z","comments":true,"path":"about/index.html","permalink":"http://blog.jboost.cn/about/index.html","excerpt":"","text":"上海交通大学计算机应用技术硕士毕业，十多年软件技术研发经验 多年软件及互联网行业从业经验。从世界500强到国企，到民企，再到创业公司，经历过几百人参与的跨国大项目，也从0到1主管研发过多款互联网产品 以技术负责人身份主导过多个项目的微服务架构实践，负责过日均TB级大数据平台的研发与运维 多年技术团队管理经验，担任过技术主管，技术经理，技术总监等职务，目前在一公司担任技术总监、研发副总职位 曾利用空闲时间整理过一些技术分享，但终究由于阶段性太忙或其它原因未能坚持。 虽然现在较少写代码，但一直有意愿将多年企业产品与项目技术实践及团队管理的经验分享出来，一方面给有需求的软件与互联网行业技术人员（尤其是计算机相关专业，并有志于从事软件技术工作的高校学生）以参考，另一方面也是对自己技术与经验的梳理、总结。于是花了点时间整了这个博客，希望能坚持下来。 我的github地址，里面有文章涉及源码或其它项目，欢迎follow、打星 为了能及时收到更新的分享文章，欢迎关注我的微信公众号"}],"posts":[{"title":"Spring Boot从入门到实战（十）：异步处理","slug":"springboot-async","date":"2019-07-22T10:25:49.000Z","updated":"2019-07-22T11:54:07.947Z","comments":true,"path":"2019/07/22/springboot-async.html","link":"","permalink":"http://blog.jboost.cn/2019/07/22/springboot-async.html","excerpt":"在业务开发中，有时候会遇到一些非核心的附加功能，比如短信或微信模板消息通知，或者一些耗时比较久，但主流程不需要立即获得其结果反馈的操作，比如保存图片、同步数据到其它合作方等等。如果将这些操作都置于主流程中同步处理，势必会对核心流程的性能造成影响，甚至由于第三方服务的问题导致自身服务不可用。这时候就应该将这些操作异步化，以提高主流程的性能，并与第三方解耦，提高主流程的可用性。","text":"在业务开发中，有时候会遇到一些非核心的附加功能，比如短信或微信模板消息通知，或者一些耗时比较久，但主流程不需要立即获得其结果反馈的操作，比如保存图片、同步数据到其它合作方等等。如果将这些操作都置于主流程中同步处理，势必会对核心流程的性能造成影响，甚至由于第三方服务的问题导致自身服务不可用。这时候就应该将这些操作异步化，以提高主流程的性能，并与第三方解耦，提高主流程的可用性。 在Spring Boot中，或者说在Spring中，我们实现异步处理一般有以下几种方式： 1. 通过 @EnableAsync 与 @Asyc 注解结合实现2. 通过异步事件实现3. 通过消息队列实现 1. 基于注解实现我们以前在Spring中提供异步支持一般是在配置文件 applicationContext.xml 中添加类似如下配置12&lt;task:annotation-driven executor=\"executor\" /&gt;&lt;task:executor id=\"executor\" pool-size=\"10-200\" queue-capacity=\"2000\"/&gt; Spring的 @EnableAsync 注解的功能与&lt;task:annotation-driven/&gt;类似，将其添加于一个 @Configuration 配置类上，可对Spring应用的上下文开启异步方法支持。 @Async 注解可以标注在方法或类上，表示某个方法或某个类里的所有方法需要通过异步方式来调用。 我们以一个demo来示例具体用法，demo地址：https://github.com/ronwxy/springboot-demos/tree/master/springboot-async 添加 @EnableAsync 注解 在一个 @Configuration 配置类上添加 @EnableAysnc 注解，我们一般可以添加到启动类上，如12345678@SpringBootApplication@EnableAsyncpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 配置相关的异步执行线程池 可通过配置类的方式对异步线程池进行配置，并提供异步执行时出现异常的处理方法，如1234567891011121314151617181920212223242526272829303132333435363738394041@Configurationpublic class AsyncConfig implements AsyncConfigurer &#123; @Value(\"$&#123;async.corePoolSize:10&#125;\") private int corePoolSize; @Value(\"$&#123;async.maxPoolSize:200&#125;\") private int maxPoolSize; @Value(\"$&#123;async.queueCapacity:2000&#125;\") private int queueCapacity; @Value(\"$&#123;async.keepAlive:5&#125;\") private int keepAlive; public Executor getAsyncExecutor() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(corePoolSize); executor.setMaxPoolSize(maxPoolSize); executor.setQueueCapacity(queueCapacity); executor.setKeepAliveSeconds(keepAlive); executor.setThreadNamePrefix(\"async-\"); executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); executor.setDaemon(false); //以用户线程模式运行 executor.initialize(); return executor; &#125; public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() &#123; return new MyAsyncUncaughtExceptionHandler(); &#125; public static class MyAsyncUncaughtExceptionHandler implements AsyncUncaughtExceptionHandler &#123; public void handleUncaughtException(Throwable throwable, Method method, Object... objects) &#123; System.out.println(\"catch exception when invoke \" + method.getName()); throwable.printStackTrace(); &#125; &#125;&#125; 这里我们通过实现 AsyncConfigurer 接口提供了一个异步执行线程池对象，各参数的说明可以参考【线程池的基本原理，看完就懂了】，里面有很详细的介绍。且通过实现 AsyncUncaughtExceptionHandler 接口提供了一个异步执行过程中未捕获异常的处理类。 定义异步方法 异步方法的定义只需要在类（类上注解表示该类的所有方法都异步执行）或方法上添加 @Async 注解即可，如12345678910111213@Servicepublic class AsyncService &#123; @Async public void asyncMethod()&#123; System.out.println(\"2. running in thread: \" + Thread.currentThread().getName()); &#125; @Async public void asyncMethodWithException() &#123; throw new RuntimeException(\"exception in async method\"); &#125;&#125; 测试 我们可以通过如下测试类来对异步方法进行测试 1234567891011121314151617181920212223@RunWith(SpringRunner.class)@SpringBootTestpublic class AnnotationBasedAsyncTest &#123; @Autowired private AsyncService asyncService; @Test public void testAsync() throws InterruptedException &#123; System.out.println(\"1. running in thread: \" + Thread.currentThread().getName()); asyncService.asyncMethod(); Thread.sleep(3); &#125; @Test public void testAysncWithException() throws InterruptedException &#123; System.out.println(\"1. running in thread: \" + Thread.currentThread().getName()); asyncService.asyncMethodWithException(); Thread.sleep(3); &#125;&#125; 因为异步方法在一个新的线程中执行，可能在主线程执行完后还没来得及处理，所以通过sleep来等待它执行完成。具体执行结果读者可自行尝试运行，这里就不贴图了。 2. 基于事件实现第二种方式是通过Spring框架的事件监听机制实现，但Spring的事件监听默认是同步执行的，所以实际上还是需要借助 @EnableAsync 与 @Async 来实现异步。 添加 @EnableAsync 注解 与上同，可添加到启动类上。 自定义事件类通过继承 ApplicationEvent 来自定义一个事件 1234567891011public class MyEvent extends ApplicationEvent &#123; private String arg; public MyEvent(Object source, String arg) &#123; super(source); this.arg = arg; &#125; //getter/setter&#125; 定义事件处理类支持两种形式，一是通过实现 ApplicationListener 接口，如下 123456789@Component@Asyncpublic class MyEventHandler implements ApplicationListener&lt;MyEvent&gt; &#123; public void onApplicationEvent(MyEvent event) &#123; System.out.println(\"2. running in thread: \" + Thread.currentThread().getName()); System.out.println(\"2. arg value: \" + event.getArg()); &#125;&#125; 二是通过 @EventListener 注解，如下12345678910@Componentpublic class MyEventHandler2 &#123; @EventListener @Async public void handle(MyEvent event)&#123; System.out.println(\"3. running in thread: \" + Thread.currentThread().getName()); System.out.println(\"3. arg value: \" + event.getArg()); &#125;&#125; 注意两者都需要添加 @Async 注解，否则默认是同步方式执行。 定义事件发送类可以通过实现 ApplicationEventPublisherAware 接口来使用 ApplicationEventPublisher 的 publishEvent()方法发送事件， 12345678910111213@Componentpublic class MyEventPublisher implements ApplicationEventPublisherAware &#123; protected ApplicationEventPublisher applicationEventPublisher; public void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) &#123; this.applicationEventPublisher = applicationEventPublisher; &#125; public void publishEvent(ApplicationEvent event)&#123; this.applicationEventPublisher.publishEvent(event); &#125;&#125; 测试 可以通过如下测试类来进行测试，1234567891011121314@RunWith(SpringRunner.class)@SpringBootTestpublic class EventBasedAsyncTest &#123; @Autowired private MyEventPublisher myEventPublisher; @Test public void testAsync() throws InterruptedException &#123; System.out.println(\"1. running in thread: \" + Thread.currentThread().getName()); myEventPublisher.publishEvent(new MyEvent(this,\"testing event based async\")); Thread.sleep(3); &#125;&#125; 运行后发现两个事件处理类都执行了，因为两者都监听了同一个事件 MyEvent 。 3. 基于消息队列实现以上两种方式都是基于服务器本机运行，如果服务进程出现异常退出，可能导致异步执行中断。如果需要保证任务执行的可靠性，可以借助消息队列的持久化与重试机制。阿里云上的消息队列服务提供了几种类型的消息支持，如顺序消息、定时/延时消息、事务消息等（详情可参考：https://help.aliyun.com/document_detail/29532.html?spm=5176.234368.1278132.btn4.6f43db25Rn8oey ），如果项目是基于阿里云部署的，可以考虑使用其中一类消息服务来实现业务需求。 4. 总结本文对spring boot下异步处理的几种方法进行了介绍，如果对任务执行的可靠性要求不高，则推荐使用第一种方式，如果可靠性要求较高，则推荐使用自建消息队列或云消息队列服务的方式。本文demo源码地址：https://github.com/ronwxy/springboot-demos/tree/master/springboot-async/src/main/java/cn/jboost/async我的个人博客地址：http://blog.jboost.cn我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"Docker笔记（六）：容器管理","slug":"docker-6","date":"2019-07-21T03:04:16.000Z","updated":"2019-07-22T10:24:14.304Z","comments":true,"path":"2019/07/21/docker-6.html","link":"","permalink":"http://blog.jboost.cn/2019/07/21/docker-6.html","excerpt":"容器是Docker中的另一核心概念，在Docker中，应用的运行都是在容器内进行的，容器则基于镜像创建。前面已对Docker镜像做了基本介绍，本文对Docker容器管理的相关内容做一个梳理。","text":"容器是Docker中的另一核心概念，在Docker中，应用的运行都是在容器内进行的，容器则基于镜像创建。前面已对Docker镜像做了基本介绍，本文对Docker容器管理的相关内容做一个梳理。 1. 启动容器启动容器的命令格式如下1docker run [OPTIONS] IMAGE-NAME [COMMAND] [ARG...] 其中OPTIONS部分可指定容器运行的一些可选项，常用选项包括： -d 将容器以后台进程（daemon）的形式运行 -p 指定容器内应用暴露端口与主机端口的映射，如 -p 8080:80 表示将容器内80端口映射到主机的8080端口（主机端口在前，容器端口在后） -v 指定容器与主机的挂载目录映射，如 -v /var/log:/log 表示将容器的/log目录挂载到主机的/var/log目录（同样主机目录在前，容器目录在后），后续对容器的/log写操作实际作用于主机的/var/log目录 -e 为容器设置环境变量 -t 为容器启动一个伪终端（pseudo-tty） -i 让容器的标准输入保持打开，一般与 -t 配合使用，让容器启动后就打开一个可交互的命令行界面 -w 指定容器的工作目录 COMMAND [ARG..] 部分就是容器需要运行的应用进程启动命令与参数，如果镜像中有通过 CMD， 或 ENTRYPOINT 指定了容器启动程序，则可省略。另外可通过 –name 指定容器的名称，以及 –restart 来指定重启策略，–restart有三种取值，代表容器支持的三种不同的重启策略 取值 描述 always 除非被docker stop命令明确停止，否则一直尝试重启处于停止态的容器；如果Docker重启，也会自动启动容器 unless-stopped 与always的区别是，停止态的容器不在Docker重启的时候被重启 on-failed 在容器退出时返回值不为0的时候，重启容器；如果Docker重启，容器也会被启动，不管之前是否处于停止状态 以启动一个mysql数据库服务为例12345docker run -d -p 3306:3306 --name mysql \\ -v /home/devuser/apps/mysql/conf/my.cnf:/etc/mysql/conf.d/my.cnf \\ -v /home/devuser/apps/mysql/logs:/var/log/mysql \\ -v /home/devuser/apps/mysql/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=Passw0rd --restart=always mysql:5.7 上述命令启动了一个mysql容器服务，-d 表示以后台进程运行，执行命令后只返回一个容器ID，不会输出任何其它信息；-p 将容器暴露的端口3306映射到宿主机的3306端口，外部主机就可以通过宿主机IP与3306端口来访问mysql服务； –name 指定了容器名称为mysql； -v 将mysql的配置文件路径、日志路径、数据存储路径映射到了宿主机对应的路径目录；-e 设置了一个环节变量指定mysql root账号的密码；–restart 指定容器在异常退出时，包括Docker重启时，自动启动容器。 我们前面有提过，当我们执行CLI命令时，实际上是客户端（Docker Client）通过发送请求到Docker后台进程（Docker Daemon），由Docker后台进程来执行的，那么当我们执行上述docker run命令的时候，Docker后台进程具体都干了些啥呢？一般来说，包括如下几个操作步骤 检测本地是否存在指定的镜像，如果不存在，就从公共仓库下载 利用镜像创建一个容器，并启动它 分配一个文件系统，并在只读的镜像层上面挂载一层可读写层（容器存储层） 从宿主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行应用程序完毕后容器被终止 2. 管理已有容器一般对已有容器的管理包括如下几个操作： 查看运行中的容器 docker ps 或 docker container ls 查看所有容器 docker ps -a 或 docker container ls -a 停止运行 docker stop xxx 开始停止状态的容器 docker start xxx 重启运行状态的容器 docker restart xxx 删除停止状态的容器 docker rm xxx 强制删除容器（包括运行状态中） docker rm -f xxx 删除所有停止状态的容器 docker container prune 其中xxx既可以是容器ID（短ID即可，只要与其它区分开来），也可以是容器名称。docker rm之前必须要先docker stop将容器置为停止状态，而docker rm -f可以强制删除运行状态的容器，其背后是通过Linux/POSIX信号来实现的，docker rm -f命令直接发出SIGKILL信号，不会给容器内运行进程任何缓冲的时间，立即终止，而docker stop命令却是先发送SIGTERM信号，通知容器进程结束，会为进程预留一个清理并优雅停止的机会，如果一段时间后进程还没有终止，那么就会发送SIGKILL信号，来终止进程的运行。 我们也可以像镜像操作中一样，组合使用命令来更方便地操作，如强制删除所有容器（慎用）1docker rm -f $(docker ps -aq) 3. 进入容器容器在运行时指定 -d 选项时， 是以后台进程的形式运行的，如果我们需要进入容器查看或操作，可以通过docker exec命令，docker exec命令的格式如下1docker exec [OPTIONS] container-id COMMAND OPTIONS常用的一般是 -t， -i，意义跟在docker run选项中一样 —— 为容器启动一个伪终端（pseudo-tty），并保持标准输入打开，从而可以像Linux命令行一样进行交互， COMMAND一般为 bash。 另外还有一个命令是docker attach xxx，其中xxx是容器ID，但推荐使用docker exec，因为docker attach中当执行exit退出容器时，容器也会随之终止，但docker exec则不会。 如果不进入容器，也可以通过docker logs xxx，xxx是容器ID，来查看容器的输出信息。 4. 导入导出容器可以使用docker export命令将一个容器的快照进行导出，如1docker export xxx &gt; mycontainer.tar 其中xxx是容器ID，可以通过docker ps -a查看，上述命令将容器的当前快照导出到了本地文件。 docker import命令则可以将一个容器快照文件导入为镜像，如1cat mycontainer.tar | docker import - test/myimage:v1.0 可以通过URL来导入，如1docker import http://test.com/testimage.tgz test/myimage2:v1.0 由此可见，我们获取镜像又多了一个来源——从已有容器快照文件导入。 5. 总结本文对容器的一些基本操作进行了介绍，需要注意的是如之前所说，容器应以无状态的形式运行，所有产生的数据应该通过挂载数据卷的方式写入宿主机文件目录，避免容器销毁时造成数据丢失；尽量使用docker stop + docker rm的方式来替代docker rm -f，使容器内运行程序“优雅”地退出。有时候可能遇到这样的场景，容器创建运行后，我们需要对运行的一些参数进行更新或添加，这时候该怎么操作。后文会对该场景进行介绍，欢迎关注。 我的个人博客地址：http://blog.jboost.cn我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"}]},{"title":"Docker笔记（五）：整一个自己的镜像","slug":"docker-5","date":"2019-07-17T08:32:35.000Z","updated":"2019-07-22T10:24:14.300Z","comments":true,"path":"2019/07/17/docker-5.html","link":"","permalink":"http://blog.jboost.cn/2019/07/17/docker-5.html","excerpt":"获取镜像的途径有两个，一是从镜像仓库获取，如官方的Docker Hub，二是自定义。上文已经介绍如何从镜像仓库获取镜像，本文基于一个Springboot项目，来介绍自定义一个镜像的基本流程。","text":"获取镜像的途径有两个，一是从镜像仓库获取，如官方的Docker Hub，二是自定义。上文已经介绍如何从镜像仓库获取镜像，本文基于一个Springboot项目，来介绍自定义一个镜像的基本流程。 1. 定制镜像的本质我们知道镜像是分层存储的，镜像的构建也是一层一层进行的，一层构建完后，就变为只读，在其上再构建下一层。因此定制镜像，实际上就是定义每一层要干的事，比如执行某个命令，设置一个环境变量，声明一个暴露端口等等。然后在构建时，按照各层的定义，一层一层地完成构建，最终形成一个包含这些层的镜像。 2. Dockerfile文件Docker中定义各层要干的事的文件叫Dockerfile，它是一个文本文件，包含了一条条的指令，每一条指令对应一层镜像，指令的内容就描述了这一层该如何构建。如下示例了一个非常简单的Dockerfile，12FROM nginxRUN echo &apos;&lt;h1&gt;Hello jboost!&lt;/h1&gt;&apos; &gt; /usr/share/nginx/html/index.html 我们定制镜像，必须要以某一个镜像为基础，在其上构建自己需要的层，如上示例中，我们是以nginx镜像为基础，然后在第二层定制了我们自己的内容——修改index.html的内容为&lt;h1&gt;Hello jboost!&lt;/h1&gt;，这样运行容器打开nginx主页时就不会显示默认的页面内容了。 上面示例中接触了Dockerfile的两个指令 FROM：FROM指令指定基础镜像，每一个定制镜像必须要有一个基础镜像，所以必须要有一条FROM指令，并且是Dockerfile的第一条指令 RUN：RUN指令指定需要执行的命令，后面接的命令就像是shell脚本一样可执行 Dockerfile还提供了许多其它指令，后续我们再集中介绍，本文只对接触到的指令做简单说明。 3. 自定义一个镜像这部分以一个Springboot项目为基础，介绍自定义一个镜像涉及的基本环节。项目地址为：https://github.com/ronwxy/swagger-register ，该项目是一个Swagger API文档注册服务，其它项目可将Swagger API信息注册到该服务，进行统一查看与管理。 3.1 定义Dockerfile文件首先，我们在项目的根目录下创建一个Dockerfile文件（文件名就叫Dockerfile），其内容为：12345678FROM openjdk:8-jdk-alpineENV PROFILE=devRUN mkdir /app /logsCOPY ./target/swagger-register-1.0.0-SNAPSHOT.jar /app/app.jarWORKDIR /appVOLUME /register-dataEXPOSE 11090CMD [&quot;java&quot;, &quot;-Dspring.profiles.active=$&#123;PROFILE&#125;&quot;, &quot;-jar&quot;, &quot;app.jar&quot;] 从上往下依次介绍如下 第一行：FORM openjdk:8-jdk-alpine， 表示以openjdk:8-jdk-alpine这个镜像为基础镜像，因为这是一个Springboot项目所以必须要有jdk支持，我们在定制镜像时，可以找一个最适合的镜像作为基础镜像。 第二行：ENV PROFILE=dev， 定义了一个环境变量，这个环境变量可以在后面被引用 第三行：RUN mkdir /app /logs，通过mkdir命令创建了两个目录，用来保存jar执行文件及日志 第四行：COPY ./target/swagger-register-1.0.0-SNAPSHOT.jar /app/app.jar 将target目录下的jar包复制到/app目录下，并且进行重命名 第五行：WORKDIR /app， 指定工作目录为/app，后面各层的当前目录就是指定的工作目录 第六行：VOLUME /register-data， 定义一个匿名数据卷，前面说过写操作不要直接在容器内进行，而要改为写挂载的数据卷目录，这个定义可在运行容器时通过 -v 来覆盖。 第七行：EXPOSE 11090， 声明了运行容器时提供的服务端口，也仅仅是个声明而已，只是告诉使用的人要映射这个端口，通过 -p 可映射端口。 第八行：CMD [“java”, “-Dspring.profiles.active=${PROFILE}”, “-jar”, “app.jar”]， 指定了容器启动命令，因为是一个Springboot项目，所以就是一个java -jar的执行命令，容器启动的时候就会执行该命令来运行Springboot服务，这里引用了第二行定义的环境变量PROFILE 3.2 配置maven插件定义好Dockerfile后，为了方便构建镜像，我们可以借助maven的dockerfile插件dockerfile-maven-plugin，在pom.xml的build部分加入配置如下 123456789101112131415161718192021&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- Docker maven plugin --&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.4.10&lt;/version&gt; &lt;configuration&gt; &lt;repository&gt;$&#123;docker.image.prefix&#125;/$&#123;project.artifactId&#125;&lt;/repository&gt; &lt;buildArgs&gt; &lt;JAR_FILE&gt;target/$&#123;project.build.finalName&#125;.jar&lt;/JAR_FILE&gt; &lt;/buildArgs&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- Docker maven plugin --&gt; &lt;/plugins&gt;&lt;/build&gt; repository指定了镜像的名称，docker.image.prefix需要properties部分进行定义，我这里是springboot。 3.3 构建镜像下载源码：https://github.com/ronwxy/swagger-register.git ，然后在项目的根目录下执行如下命令(前提是本地已经装好了docker与maven及jdk)1mvn clean package -Dmaven.test.skip=true dockerfile:build 该命令首先会执行mvn clean package -Dmaven.test.skip=true对项目进行打包，生成./target/swagger-register-1.0.0-SNAPSHOT.jar文件，然后基于当前目录下的Dockerfile文件进行构建，如下图所示 由上图可看出，该镜像构建分八步(对应Dockerfile的八行指令)，每一步生成一个镜像层，每一层都有唯一的ID。由图中也可以看出，除了COPY之类的命令外，每一层的构建实际上是先基于上一层启动一个容器，然后执行该层定义的操作，再移除这个容器来实现的，如第八步中12345Step 8/8 : CMD [\"java\", \"-Dspring.profiles.active=$&#123;PROFILE&#125;\", \"-jar\", \"app.jar\"][INFO] [INFO] ---&gt; Running in f4acd0b53bca[INFO] Removing intermediate container f4acd0b53bca[INFO] ---&gt; a9ee579f2d62 先启动一个ID为f4acd0b53bca的容器，在其中执行CMD所定义的命令，然后再移除容器f4acd0b53bca，最后生成ID为a9ee579f2d62的镜像。 构建完后，我们就可以在本地镜像中通过docker iamges看到我们定制的镜像了，如图 图中springboot/swagger-register镜像即为我们刚刚构建好的定制镜像。 3.4 启动容器我们可以通过以下命令来启动一个刚才定制镜像的容器1docker run -d --name swagger-register -p 11090:11090 -v /home/jenkins/swagger-register/register-data:/register-data -v /home/jenkins/swagger-register/logs:/logs --restart=always springboot/swagger-register:latest 其中： -d 表示以后台进程方式运行 –name 指定容器名称 -p 指定端口映射，左边为宿主机端口，右边为容器服务端口 -v 指定数据卷挂载，左边为宿主机目录，右边为容器目录 –restart=always 表示在docker启动时自动启动该容器 关于容器相关的内容后面详细介绍，这里不展开说明了。启动容器后， 我们就可以浏览器打开地址 http://宿主机ip:11090/doc.html 来访问服务了（打开页面后内容是空的，因为没有任何服务注册Swagger API， 相关内容可参考 swagger api文档集中化注册管理） 4. 总结本文介绍了一个基于Springboot项目的Docker镜像定制及使用过程，对镜像的构建过程，及Dockerfile的基本指令以及容器的运行做了基本介绍。后续会对Dockerfile的其它指令及Dockerfile的一些最佳实践进行更为详细的介绍，欢迎关注。我的个人博客地址：http://blog.jboost.cn我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"}]},{"title":"Docker笔记（四）：Docker镜像管理","slug":"docker-4","date":"2019-07-16T13:22:11.000Z","updated":"2019-07-17T00:30:59.318Z","comments":true,"path":"2019/07/16/docker-4.html","link":"","permalink":"http://blog.jboost.cn/2019/07/16/docker-4.html","excerpt":"在Docker中，应用是通过容器来运行的，而容器的运行是基于镜像的，类似面向对象设计中类与对象的关系——没有类的定义就谈不上实例的创建与使用，没有镜像的定义就谈不上容器的创建与运行。","text":"在Docker中，应用是通过容器来运行的，而容器的运行是基于镜像的，类似面向对象设计中类与对象的关系——没有类的定义就谈不上实例的创建与使用，没有镜像的定义就谈不上容器的创建与运行。 1. 获取镜像镜像从哪里来，一般两个途径，一是公共镜像库，如官方镜像库Docker Hub，上面有大量的高质量的镜像直接可拿来用；二是自定义，我们可基于一个已有镜像，在其基础上增加一些层（还记得镜像的分层存储特性吧），然后构建形成自己的镜像。 如果我们知道某个镜像的名称，则可直接通过docker pull来下载镜像到本地，如ubuntu、redis、nginx等，docker pull命令的格式如下1docker pull [选项] [Docker Registry的地址[:端口号]/]仓库名[:标签] 其中选项可设置： -a, –all-tags：下载仓库中所有标签（一般指版本）的镜像 –disable-content-trust：跳过镜像验证，默认为true Docker Registry的地址即镜像仓库地址，一般为域名或IP加端口号，如果不指定则默认为Docker Hub；仓库名包含两部分，&lt;用户名&gt;/&lt;软件名&gt;，对于Docker Hub，如果不给出用户名，则默认为library，表示官方提供；标签一般是对应软件的版本号，如果不指定则默认为latest。 比如我们要下一个nginx镜像，则可执行如下命令 12345678[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker pull nginxUsing default tag: latestlatest: Pulling from library/nginxfc7181108d40: Already exists d2e987ca2267: Pull complete 0b760b431b11: Pull complete Digest: sha256:48cbeee0cb0a3b5e885e36222f969e0a2f41819a68e07aeb6631ca7cb356fed1Status: Downloaded newer image for nginx:latest 这里我们没有指定选项，也没有指定镜像仓库地址，那么默认会从Docker Hub获取镜像（但Docker Hub由于在国外，速度比较慢，所以一般要设置国内加速器，参考Docker笔记（三）：Docker安装与配置第二部分：配置国内镜像)，也没有给出用户名，所以默认是library（第三行），没有指定标签，所以默认是latest（第二行），由第四至第六行可见，这个镜像包含三个层，并且第一个层已经存在了（之前下载的镜像已经包含了这个层， 直接复用），镜像分层的概念及层的复用，应该已经理解了。 如果我们不知道镜像的完整名称怎么办，那就搜索一下，有两个途径，一是通过命令，假设我们记不起nginx全称了， 只记得ngi，则可通过如下命令搜索123456789101112131415[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker search ngiNAME DESCRIPTION STARS OFFICIAL AUTOMATEDnginx Official build of Nginx. 11693 [OK] jwilder/nginx-proxy Automated Nginx reverse proxy for docker con… 1628 [OK]richarvey/nginx-php-fpm Container running Nginx + PHP-FPM capable of… 726 [OK]bitnami/nginx Bitnami nginx Docker Image 69 [OK]linuxserver/nginx An Nginx container, brought to you by LinuxS… 69 tiangolo/nginx-rtmp Docker image with Nginx using the nginx-rtmp… 48 [OK]nginx/nginx-ingress NGINX Ingress Controller for Kubernetes 20 nginxdemos/hello NGINX webserver that serves a simple page co… 18 [OK]jlesage/nginx-proxy-manager Docker container for Nginx Proxy Manager 17 [OK]schmunk42/nginx-redirect A very simple container to redirect HTTP tra… 17 [OK]crunchgeek/nginx-pagespeed Nginx with PageSpeed + GEO IP + VTS + more_s… 13 blacklabelops/nginx Dockerized Nginx Reverse Proxy Server. 12 [OK]... 该命令会从Docker Hub搜索镜像名包含ngi的镜像，其中STARS表示收藏用户数，OFFICIAL为[OK]表示官方提供的镜像，AUTOMATED [OK]表示由自动构建生成，一般选择STARS最多，官方提供的镜像。这种方式获取到的信息有限，比如具体包含哪些版本不知道。还有一个途径是直接在Docker Hub网站上搜索，打开 https://hub.docker.com ， 在搜索框输入ngi，如下图 则会列出所有满足条件的镜像，点开nginx结果链接，可以看到提供的版本（通过版本链接可以查看定义对应镜像的Dockerfile），及相应的文档说明。这种方式获取的信息更加全面，所以推荐这种方式！ 另外，当我们没有执行docker pull，直接通过docker run xx来运行一个容器时，如果没有对应的镜像，则会先自动下载镜像，再基于镜像启动一个容器，比如我们在Docker笔记（三）：Docker安装与配置中检验docker是否安装成功时运行的hello-world 2. 管理本地镜像将镜像下载到本地后，我们可以基于镜像来创建、运行容器，及对镜像进行管理。 查看本地镜像 12345[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEnginx latest f68d6e55e065 2 weeks ago 109MBmysql latest c7109f74d339 5 weeks ago 443MBhello-world latest fce289e99eb9 6 months ago 1.84kB 上面各列依次列出了镜像名称、标签（版本）、镜像ID、创建时间、镜像大小。镜像可以拥有多个标签（版本）。镜像的大小总和一般要大于实际的磁盘占有量，为什么？回忆一下镜像的分层存储概念，层是可以复用的，某个层其中一个镜像有了，另一个镜像就不会再下载了。口说无凭，我们来验证下，docker system df可列出镜像、容器、数据卷所占用的空间 123456[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker system dfTYPE TOTAL ACTIVE SIZE RECLAIMABLEImages 3 1 497.1MB 497.1MB (99%)Containers 1 0 0B 0BLocal Volumes 0 0 0B 0BBuild Cache 0 0 0B 0B 通过docker image ls列出的各镜像大小总共约552MB，但这里列出的镜像大小只有约497MB，这下有凭有据了吧。 根据条件列出镜像123docker image ls nginx # 根据名称列出镜像docker image ls nginx:latest # 根据名称与标签列出镜像docker image ls -f since=hello-world:latest # -f 是--filter的缩写，过滤器参数，列出在hello-world:latest之后建立的镜像，before=hello-world:latest则查看之前建立的镜像 指定显示格式12345docker image ls -q # 只显示镜像IDdocker image ls --digests # 列出镜像摘要docker image ls --format \"&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Repository&#125;&#125;\" # 使用Go的模板语法格式化显示，这里显示格式为 镜像ID：镜像名称docker image ls --format \"table &#123;&#123;.ID&#125;&#125;\\t&#123;&#123;.Repository&#125;&#125;\\t&#123;&#123;.Tag&#125;&#125;\" # 自己定义表格格式 虚悬镜像有时候会看到某些镜像既没有仓库名，也没有标签，均为 &lt;none&gt;。这些镜像原本是有镜像名和标签的，随着官方镜像维护，发布了新版本后(新版本会复用之前的镜像名称与标签，一般是bug修复版)，重新docker pull xx 时， 这个镜像名被转移到了新下载的镜像身上，而旧的镜像上的这个名称则被取消，从而成为了&lt;none&gt; 。除了docker pull可能导致这种情况， docker build也同样可以导致这种现象。由于新旧镜像同名，旧镜像名称被取消，从而出现仓库名、标签均为 &lt;none&gt; 的镜像。这类无标签镜像被称为虚悬镜像(dangling image) ，可以用下面的命令专门显示这类镜像：1docker image ls -f dangling=true 一般虚悬镜像没什么意义了，可以通过如下命令删除1docker image prune 中间层镜像为了加速镜像构建、重复利用资源，Docker会利用中间层镜像。所以在使用一段时间后，可能会看到一些依赖的中间层镜像。默认的docker image ls列表中只会显示顶层镜像，如果希望显示包括中间层镜像在内的所有镜像的话，可以加 -a1$ docker image ls -a 这样会看到很多无标签的镜像，与虚悬镜像不同，这些无标签的镜像很多都是中间层镜像，是其它镜像所依赖的镜像。这些无标签镜像不应该删除，否则会导致上层镜像因为依赖丢失而出错。实际上，这些镜像也没必要删除，因为相同的层只会存一遍，而这些镜像是别的镜像的依赖，因此并不会因为它们被列出来而多存了一份，无论如何你也会需要它们。只要删除那些依赖它们的镜像后，这些依赖的中间层镜像也会被连带删除。 删除镜像删除镜像命令格式1docker image rm [选项] &lt;镜像1&gt; [&lt;镜像2&gt; ...] 选项可以设置： -f, –force 强制删除镜像 –no-prune 不删除没有标签的父镜像 &lt;镜像1&gt;、&lt;镜像2&gt; 等可以是镜像的名称，镜像的全ID，也可以是镜像ID的前面几个数字（只要与其它镜像区分开来就行），或者是镜像摘要。 如删除镜像名称为mysql的镜像1234567[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker image rm mysqlUntagged: mysql:latestUntagged: mysql@sha256:415ac63da0ae6725d5aefc9669a1c02f39a00c574fdbc478dfd08db1e97c8f1bDeleted: sha256:c7109f74d339896c8e1a7526224f10a3197e7baf674ff03acbab387aa027882aDeleted: sha256:35d60530f024aa75c91a123a69099f7f6eaf5ad7001bb983f427f674980d8482Deleted: sha256:49d8bb533eee600076e3a513a203ee24044673fcef0c1b79e088b2ba43db2c17... 由上面命令的执行结果可见，删除镜像包括另个行为：Untagged、Deleted。 当我们使用上面命令来删除镜像的时候，实际上是在要求删除某个/某些标签的镜像。所以首先需要做的是将满足要求的所有镜像标签都取消，这就是Untagged的行为。一个镜像可以对应多个标签，因此当我们删除了所指定的标签后，可能还有别的标签指向了这个镜像，如果是这种情况，那么Delete行为就不会发生，仅仅是取消了这个镜像的符合要求的所有标签。所以并非所有的docker image rm都会产生删除镜像的行为，有可能仅仅是取消了某个标签而已。 当该镜像所有的标签都被取消了，该镜像很可能就失去了存在的意义，因此会触发删除行为。镜像是多层存储结构，因此在删除的时候也是从上层向基础层方向依次进行判断删除。如果某个其它镜像正依赖于当前镜像的某一层，这种情况，依旧不会触发删除该层的行为。直到没有任何镜像依赖当前层时，才会真实的删除当前层。 另外还需要注意是容器对镜像的依赖。如果基于镜像启动的容器存在（即使容器没有运行处于停止状态） ，同样不可以删除这个镜像。我们之前说了容器是以镜像为基础，再加一层容器存储层组成的多层存储结构去运行的。所以如果这些容器是不需要的，应该先将它们删除，然后再来删除镜像。 通过组合命令来删除12docker image rm $(docker image ls -q nginx) # 删除镜像名称为nginx的所有镜像docker image rm $(docker image ls -q -f since=hello-world:latest) # 删除所有在hello-world:latest之后建立的镜像 3. 总结本文对镜像的获取及本地镜像的基本管理做了介绍，本文镜像的获取途径都是从镜像仓库直接获取，镜像的另一个获取途径便是自定义，接下来会通过实例来进行介绍，欢迎关注。我的个人博客地址：http://blog.jboost.cn我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"}]},{"title":"Docker笔记（三）：Docker安装与配置","slug":"docker-3","date":"2019-07-14T11:54:05.000Z","updated":"2019-07-15T00:47:02.022Z","comments":true,"path":"2019/07/14/docker-3.html","link":"","permalink":"http://blog.jboost.cn/2019/07/14/docker-3.html","excerpt":"Docker分为Docker CE社区免费版与Docker EE企业收费版。Docker EE主要是在安全性及镜像、容器高级管理方面提供了一些额外的支持。对于中小型企业、团队或个人来说，用Docker CE即可。","text":"Docker分为Docker CE社区免费版与Docker EE企业收费版。Docker EE主要是在安全性及镜像、容器高级管理方面提供了一些额外的支持。对于中小型企业、团队或个人来说，用Docker CE即可。 1. 安装Docker CEDocker CE有三个更新渠道： Stable：提供最新的GA（General Availability）稳定版，每六个月一版，如 18.09 表示18年9月版，下一版就是19.03——19年3月版 Test：提供GA之前的Pre-release版 Nightly：提供最新的build版本，每天一版 我们一般使用stable版。Docker CE支持在多种操作系统下安装，本文只介绍比较常见的Ubuntu 18.04 LTS、CentOS7、及Windows 10上的安装与配置。 1.1 Ubuntu 18.04 LTS 上安装Docker CE支持的64位Ubuntu系统版本为 Cosmic 18.10 Bionic 18.04 (LTS) Xenial 16.04 (LTS) Docker CE在Ubuntu上支持 overlay2， aufs， 以及 btrfs 几种存储驱动程序，对于Linux内核版本为4或以上系统的安装，Docker CE默认使用 overlay2，如果需要使用 aufs，则需要手动配置（参考： Use the AUFS storage driver） 卸载旧版本 如果系统安装有旧版本，旧版本命名为 docker， docker.io，或docker.engine，可使用如下命令进行卸载1$ sudo apt-get remove docker docker-engine docker.io containerd runc 目录/var/lib/docker下的内容，包括镜像、容器、数据卷、网络等，会被保留。 使用APT安装 apt源使用HTTPS来确保软件下载过程中不被篡改，所以首先添加使用HTTPS传输需要的软件包以及CA证书1234567$ sudo apt-get update$ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common 为了确认下载软件包的合法性，添加Docker官方的GPG key：12$ curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg | sudo apt-key add - 由于国内网络原因，我们一般要使用国内源，否则安装将会灰常灰常慢。向source.list中添加Docker软件源（以下命令添加的是stable版本的APT镜像源，如果需要test或nightly版，将stable改为对应test或nightly即可）1234$ sudo add-apt-repository \\\"deb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu \\$(lsb_release -cs) \\stable\" 然后，便可更新apt软件包缓存，开始安装了12$ sudo apt-get update$ sudo apt-get install docker-ce 以上命令默认会安装软件源里的最新版本，如果需要安装指定版本，则可通过查看可用版本，然后指定版本安装，查看版本1$ apt-cache madison docker-ce 安装指定版本1$ sudo apt-get install docker-ce=&lt;VERSION_STRING&gt; 使用脚本自动安装 Docker提供了一个方便的安装脚本来在开发测试环境安装Docker CE的edge或测试版，Ubuntu上可使用这套脚本来安装Docker CE的edge版12$ curl -fsSL https://get.docker.com -o get-docker.sh$ sudo sh get-docker.sh --mirror Aliyun 启动Docker CE 12$ sudo systemctl enable docker #开启开机自动启动$ sudo systemctl start docker #启动docker 用户组配置 docker命令默认是使用Unix socket与Docker引擎进行通信（回顾下除了Unix socket还有REST API及网络端口），只有root用户或docker用户组里的用户才有权限访问Docker引擎的Unix socket，因此，需要将使用docker的用户加入docker用户组（处于安全考虑，一般尽量不要直接使用root用户来操作）12$ sudo groupadd docker #添加docker用户组$ sudo usermod -aG docker $USER #将当前用户加到docker用户组 退出账号重新登录即可。 测试安装是否成功 1$ docker run hello-world 如果显示如下图，则说明安装已成功 卸载 1$ sudo apt-get purge docker-ce 以上命令可以卸载docker-ce，但是之前的镜像、容器、数据卷等不会自动删除，可通过如下命令彻底删除1$ sudo rm -rf /var/lib/docker 1.2 CentOS 7 上安装Docker CE支持64位的CentOS7，并且要求内核版本不低于3.10。CentOS 7满足最低内核的要求，但由于版本较低，一些功能（如 overlay2 存储层驱动）无法使用，并且部分功能可能不太稳定。可以通过uname -r命令来查看系统内核版本，如12[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# uname -r3.10.0-957.1.3.el7.x86_64 卸载旧版本 如果安装了旧版本，需要先卸载。旧版本的Docker称为docker或者docker-engine，卸载命令12345678910$ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine 使用yum安装 安装依赖包123$ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 由于国内网络原因，我们一般要使用国内源，否则安装可能会灰常灰常慢。添加yum软件源1234$ sudo yum-config-manager \\ --add-repo \\ https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce .repo 如果要安装nightly或test版，执行如下对应的命令12$ sudo yum-config-manager --enable docker-ce-nightly # 启用nightly， 将--enbale改为disable又可以禁用$ sudo yum-config-manager --enable docker-ce-test # 启用test 安装最新版本12$ sudo yum makecache fast # 更新软件源缓存$ sudo yum install docker-ce # 安装最新版本 安装指定版本12$ sudo yum list docker-ce --showduplicates | sort -r # 列出可用版本$ sudo yum install docker-ce-&lt;VERSION_STRING&gt; # 安装指定版本 使用脚本自动安装 执行如下命令，则会自动安装Docker CE的edge版，注意只在开发或测试环境这么用（建议最好还是用stable版） 12$ curl -fsSL get.docker.com -o get-docker.sh$ sudo sh get-docker.sh --mirror Aliyun 启动Docker CE 12$ sudo systemctl enable docker #开启开机自动启动$ sudo systemctl start docker #启动docker 用户组配置 docker命令默认是使用Unix socket与Docker引擎进行通信（回顾下除了Unix socket还有REST API及网络端口），只有root用户或docker用户组里的用户才有权限访问Docker引擎的Unix socket，因此，需要将使用docker的用户加入docker用户组（处于安全考虑，一般尽量不要直接使用root用户来操作）12$ sudo groupadd docker #添加docker用户组$ sudo usermod -aG docker $USER #将当前用户加到docker用户组 退出账号重新登录即可。 测试安装是否成功 1$ docker run hello-world 如果显示如下图，则说明安装已成功 如果在 CentOS 中使用 Docker CE 看到下面的这些警告信息：12WARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled 可以添加内核配置参数以启用这些功能。1234$ sudo tee -a /etc/sysctl.conf &lt;&lt;-EOFnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOF 然后重新加载 sysctl.conf 即可1$ sudo sysctl -p 卸载 12$ sudo yum remove docker-ce # 卸载docker-ce$ sudo rm -rf /var/lib/docker # 该目录下的镜像、容器、数据卷、网络等不会自动删除 1.3 Windows 10 上安装windows 10上的安装非常简单，直接下载stable版本安装。安装完后，在 Windows 搜索栏输入 Docker 点击 Docker for Windows 开始运行 2. 配置国内镜像Docker默认是从Docker Hub（官方的镜像仓库）拉取镜像的，国内访问一般会比较慢，因此可以配置一些镜像加速器，很多云服务商提供了自己的加速器服务，如Azure中国，阿里云（需要登录获取），七牛云等。 Ubuntu、CentOS上，配置国内镜像只需要在/etc/docker/daemon.json中写入如下内容（如果文件不存在则创建一个）123456&#123; \"registry-mirrors\": [ \"https://dockerhub.azk8s.cn\", \"https://reg-mirror.qiniu.com\" ]&#125; 然后重新启动服务12$ sudo systemctl daemon-reload$ sudo systemctl restart docker 对于Windows 10，在系统右下角托盘Docker图标上右键菜单选择Settings ，打开配置窗口后在左侧导航菜单选择 Daemon 。在 Registrymirrors 一栏中填写加速器地址 https://dockerhub.azk8s.cn ，之后点击Apply 保存， Docker 就会自动重启并应用配置的镜像地址了。 可以通过docker info命令来检查加速器是否生效，如果执行命令能看到类似如下信息，则说明加速器配置生效了。12Registry Mirrors: https://dockerhub.azk8s.cn/ 3. 总结Docker分Docker CE与Docker EE两个版本，对大多数人来说，一般使用Docker CE就行了。我们在安装Docker CE时，最好安装stable版，比较稳定可靠。同时，Linux安装时，记得配置Docker软件源，不然有可能太慢。安装完后，需要配置镜像加速器，加快镜像的下载速度。工具有了，接下来就是探索实践了，加油吧少年！我的个人博客地址：http://blog.jboost.cn我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"}]},{"title":"Docker笔记（二）：Docker管理的对象","slug":"docker-2","date":"2019-07-14T00:36:56.000Z","updated":"2019-07-15T00:44:22.854Z","comments":true,"path":"2019/07/14/docker-2.html","link":"","permalink":"http://blog.jboost.cn/2019/07/14/docker-2.html","excerpt":"在Docker笔记（一）：什么是Docker中，我们提到了Docker管理的对象包含镜像、容器、网络、数据卷等，本文就来介绍下这些对象及用途。","text":"在Docker笔记（一）：什么是Docker中，我们提到了Docker管理的对象包含镜像、容器、网络、数据卷等，本文就来介绍下这些对象及用途。 1. 镜像所谓镜像，是一个静态的概念。它对我们期望干的事情做了一些定义，比如要运行什么程序，需要哪些依赖，需要什么样的配置，需要开放哪个网络端口等等。Docker的镜像是一个特殊的文件系统，提供了运行时需要的程序、库、资源、配置等文件，还包含一些为运行时准备的配置参数（如环境变量、匿名数据卷、用户等），镜像不包含任何动态数据，其内容在构建之后也不会被改变。镜像的文件系统有一个分层存储的概念，采用的是Union FS技术，因此，镜像并不是简单地由一组文件组成，而是由多层文件系统叠加联合组成。如下图所示 镜像构建时，会一层一层地构建，前一层是后一层的基础，每层构建完后就变成只读的，不会再发生改变。镜像分层存储的一大好处是复用，镜像的每一层可以在不同镜像间复用，这就好比我们开发项目时将一些公共功能封装成jar包，在各个项目可以直接依赖使用一样。关于镜像的更多内容，在后续使用时再详述。 2. 容器相对镜像，容器是一个动态的运行时的概念，它与镜像的关系类似于面向对象中类与实例的关系。容器可以被创建、启动、停止、删除等。容器运行实质上就是运行一个进程，但与那些直接在宿主机上运行的进程不同，容器运行在自己的独立的隔离的命名空间中——拥有自己的root文件系统、网络配置、进程空间，甚至自己的用户ID空间，因此虽然是以进程的形式运行，但好像是运行在一个独立的系统中一样，这样相比直接运行于宿主机的进程，容器的运行显得更为安全。前面说到镜像的分层存储概念，对于容器来说，实际上也是以镜像作为基础层，在其上创建了一个当前容器的存储层，如下图 以镜像ubuntu:15.04为基础层所创建的容器，都有一个自己的可读写的存储层（镜像的存储层是只读的）。容器存储层的生命周期与容器一样，容器销毁时，容器的存储层也会随之消亡，任何保存在容器存储层的数据也都会随容器的删除而丢失，因此一般我们要保持容器存储层的无状态化，所有文件的写操作，都应该使用数据卷或绑定宿主机目录。 3. 数据卷数据卷是一个独立于容器，可供一个或多个容器使用的特殊目录，它绕过了Union FS，不会随容器的销毁而消亡。这好比我们在阿里云上建虚机，再加载一个数据盘一样，一般产生的数据都要保存在数据盘，而不是虚机的系统盘。数据卷具备如下特性： 可以在容器之间共享和重用 对数据卷的修改会立马生效 数据卷的更新，不会影响到镜像 数据卷默认会一直存在，不会随容器的删除而消亡 4. 网络Docker容器是如何与外部进行网络通信的？一般来说，我们在运行容器时，只需要指定容器服务端口与宿主机端口的映射，就可以通过宿主机IP与映射的端口访问容器服务了，因为Docker默认使用了Bridge的模式来实现容器与外部的通信。Docker的网络子系统通过使用一些驱动程序，是可插拔式的，默认提供了如下几种驱动： bridge：默认的网络驱动。运行在容器中的应用程序一般是通过网桥与外部进行通信。 host：容器直接使用宿主机的网络通信。host只在基于Docker 17.06或以上版本的Swarm服务中可用 overlay：overlay可将多个Docker daemon进程连接起来使得Swarm服务之间能相互通信，也可以将overlay用于Swarm服务与容器之间，或运行在不同Docker daemon上的容器之间的通信，不需要操作系统层面的路由配置。 macvlan：macvlan允许你分配一个mac地址给容器，让它像一台物理设备一样加入你的网络中。Docker daemon通过mac地址将请求路由给容器，适用于那些希望直接连到物理网络的遗留应用。 none：禁用所有网络。一般与一个自定义的网络驱动一起使用。none不能用于Swarm服务。 其它第三方网络插件：可从Docker Hub或其它第三方供应商获取安装。 总之，bridge适用于在同一台宿主机运行多个容器的场景；host适用于不应与宿主机进行网络隔离的场景；overlay适用于运行在不同宿主机上的容器间通信，或多个应用通过Swarm服务来共同协作的场景；macvlan适用于从虚拟机迁移配置或希望容器作为物理机一样使用网络的场景。 5. 总结本文对Docker所管理的几个基本对象——镜像、容器、数据卷、网络做了简单介绍，这是认识或学习Docker的基础，在后续实践操作过程中，将会对各部分进行更详细的使用说明，欢迎持续关注。我的个人博客地址：http://blog.jboost.cn我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"}]},{"title":"Docker笔记（一）：什么是Docker","slug":"docker-1","date":"2019-07-13T02:13:25.000Z","updated":"2019-07-13T09:59:13.911Z","comments":true,"path":"2019/07/13/docker-1.html","link":"","permalink":"http://blog.jboost.cn/2019/07/13/docker-1.html","excerpt":"1. 前言接触Docker也有两年多了，断断续续玩过一些应用场景，如安装一些常用工具服务，部署业务项目，基于gitlab+jenkins pipeline+docker的CI/CD实现等。了解其基本知识与操作，但不能说深度掌握，故借此系列进行梳理与学习，也希望对有意学习Docker的人提供参考。","text":"1. 前言接触Docker也有两年多了，断断续续玩过一些应用场景，如安装一些常用工具服务，部署业务项目，基于gitlab+jenkins pipeline+docker的CI/CD实现等。了解其基本知识与操作，但不能说深度掌握，故借此系列进行梳理与学习，也希望对有意学习Docker的人提供参考。 2. Docker简介Docker最初是dotCloud公司（后来也改名为Docker）的一个内部项目，于2013年3月开源。Docker使用Google推出的Go语言实现，基于Linux内核的cgroup、namespace、Union FS等技术（先不用急着了解这些都是啥），对进程进行隔离，是操作系统层面的虚拟化技术。相对于传统的硬件层面的虚拟化技术（虚拟机），Docker显得更为轻量化。下图为传统虚拟机与Docker的结构对比 由上图可看出传统虚拟机技术是在硬件层面虚拟出一套硬件（CPU、内存、磁盘、网卡等）后，在其上运行一个完整的操作系统，再在操作系统上运行应用进程；而Docker的应用进程是直接运行在宿主机的内核上，也不需要进行硬件虚拟，因此，Docker要比传统虚拟机更为轻便。 总结Docker相对传统虚拟化技术的优势如下： 更高的资源利用率：Docker不需要硬件虚拟与运行完整操作系统的开销，所以资源利用率更高，同样配置的主机，采用Docker往往可以运行更多数量的应用。 更高效的使用体验：在操作系统上安装一些常用软件，如mysql，redis等，往往需要折腾好一阵，有些还要手动安装各种依赖，而采用Docker，可能几行命令就可以让一个服务快速运行起来。 一致的运行环境：Docker镜像功能可以把程序运行需要的环境进行封装，确保程序在开发、测试、生产环境都能保持一致性，避免因环境不一致导致程序运行异常。 CI/CD支持：使用Docker可以定制镜像来实现持续集成、持续部署，如基于gitlab + jenkins pipeline + docker的自动化部署。 更轻松的维护：因为Docker保证了运行环境的一致性，因此应用的迁移或缩放将变得很容易；Docker的分层存储与镜像技术，也使得应用重复部分的复用变得更简单，基于基础镜像可以进一步扩展定义自己的镜像，也可以直接使用官方镜像来使用。 3. Docker的基本架构Docker的基本架构图如下 主要包括几部分： Docker daemon（Docker守护进程 dockerd）：Docker的执行引擎，负责监听处理Docker客户端请求与管理Docker相关对象，如镜像、容器、网络、数据卷等。一个Docker守护进程可与其它Docker守护进程进行通信，作为Docker服务进行管理。 Docker client（Docker客户端 docker）：Docker客户端（docker CLI命令）是大多数用户用来与Docker守护进程交互的方式，比如你在命令行执行docker run，Docker客户端将发送该命令请求到Docker守护进程，由守护进程执行。Docker客户端可通过REST API, UNIX Socket或网络接口来与Docker守护进程进行通信，并且可与多个Docker守护进程进行通信。 Docker Registry（Docker注册中心）：用来存储Docker镜像的仓库，类似于Maven的Nexus。Docker官方提供了一个公共镜像仓库Docker Hub（ https://hub.docker.com/ ），docker相关命令默认会从Docker Hub上搜索与下载镜像，我们可以配置一些国内镜像仓库地址来进行加速，甚至搭建自己的私有镜像仓库。 Docker Objects：Docker管理的对象，主要包括镜像、容器、网络、数据卷等。 4. Docker的用途根据第二部分Docker的优势及笔者的经验来看，目前Docker主要用于 常用软件服务的搭建运行，如Mysql、Redis、Nginx等 业务服务的发布部署，尤其是基于SpringBoot的微服务 CI/CD实现，结合Gitlab的webhook，Jenkins的pipeline，实现自动化集成与部署 快速的弹性伸缩，在容器集群化管理的场景中，如Swarm、K8s解决方案中，可基于容器对服务进行快速的弹性伸缩来应对业务量的突发情况 执行环境封装，如一些深度学习框架模型，打成Docker镜像的方式进行发布，可以快速在不同的环境中运行起来 … 5. 总结在微服务架构、DevOps这些概念盛行的时代，容器化技术变得越来越重要，几乎成为每一位开发人员需要掌握的技能。本系列文章是笔者基于自身实践及相关文献参考，对Docker相关技术进行整理，欢迎关注，共同学习。我的个人博客地址：http://blog.jboost.cn我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"}]},{"title":"ubuntu18.04上搭建KVM虚拟机环境超完整过程","slug":"ubuntu-kvm","date":"2019-07-11T06:13:23.000Z","updated":"2019-07-12T11:19:00.269Z","comments":true,"path":"2019/07/11/ubuntu-kvm.html","link":"","permalink":"http://blog.jboost.cn/2019/07/11/ubuntu-kvm.html","excerpt":"看标题这是篇纯运维的文章。在中小型企业中，一般很少配置专业的运维人员，都是由开发人员兼着。同时，对有志于技术管理的开发人员来说，多了解一些运维及整个软件生命周期的知识，是很有帮助的，因为带团队不仅仅是个管人的活，更多的是在你的部下遇到难题或者无人能上的时候，你能协助他解决或亲自上阵，这比只会“吆五喝六”的管理者将能获得更高的敬重与威信。闲话不多说了，记录下整个KVM虚拟机的搭建过程吧。","text":"看标题这是篇纯运维的文章。在中小型企业中，一般很少配置专业的运维人员，都是由开发人员兼着。同时，对有志于技术管理的开发人员来说，多了解一些运维及整个软件生命周期的知识，是很有帮助的，因为带团队不仅仅是个管人的活，更多的是在你的部下遇到难题或者无人能上的时候，你能协助他解决或亲自上阵，这比只会“吆五喝六”的管理者将能获得更高的敬重与威信。闲话不多说了，记录下整个KVM虚拟机的搭建过程吧。 1. KVM安装1.1 配置确认首先需要确认服务器的硬件是否支持虚拟化，执行如下命令确认 12devuser@server_01:~$ egrep -c '(vmx|svm)' /proc/cpuinfo48 如果输出结果大于0，意味着服务器硬件是支持虚拟化的。否则，重启进入BIOS设置中启用VT技术。执行如下命令安装kvm-ok程序，来确定服务器是否能够运行硬件加速的KVM虚拟机 12345devuser@server_01:~$ sudo apt install cpu-checkerdevuser@server_01:~$ sudo kvm-okINFO: /dev/kvm existsKVM acceleration can be used 1.2 安装KVM安装KVM及依赖项12devuser@server_01:~$ sudo apt updatedevuser@server_01:~$ sudo apt install qemu qemu-kvm libvirt-bin bridge-utils virt-manager 启动libvirtd服务，并设置开机自动启动12devuser@server_01:~$ sudo systemctl start libvirtd.servicedevuser@server_01:~$ sudo systemctl enable libvirtd.service 执行service libvirtd status查看libvirtd服务状态，如图 1.3 桥接网络配置一般虚拟机网络配置有Bridge、NAT等几种模式。NAT模式下，虚拟机不需要配置自己的IP，通过宿主机来访问外部网络；Bridge模式下， 虚拟机需要配置自己的IP，然后虚拟出一个网卡， 与宿主机的网卡一起挂到一个虚拟网桥上（类似于交换机）来访问外部网络，这种模式下，虚拟机拥有独立的IP，局域网其它主机能直接通过IP与其通信。简单理解，就是NAT模式下，虚机隐藏在宿主机后面了，虚机能通过宿主机访问外网，但局域网其它主机访问不到它，Bridge模式下，虚机跟宿主机一样平等地存在，局域网其它主机可直接通过IP与其通信。一般我们创建虚机是用来部署服务供使用的， 所以都是用Bridge模式。 ubuntu 18中，网络配置通过netplan来实现了，如下，更改配置文件 /etc/netplan/50-cloud-init.yaml 1234567891011121314151617181920212223devuser@cserver_01:~$ sudo vim /etc/netplan/50-cloud-init.yaml# This file is generated from information provided by# the datasource. Changes to it will not persist across an instance.# To disable cloud-init's network configuration capabilities, write a file# /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg with the following:# network: &#123;config: disabled&#125;network: ethernets: enp6s0: dhcp4: true enp7s0: dhcp4: no dhcp6: no version: 2 bridges: br0: interfaces: [enp7s0] dhcp4: no addresses: [192.168.40.241/24] gateway4: 192.168.40.1 nameservers: addresses: [114.114.114.114,8.8.8.8] 将宿主机原有网卡enp7s0挂到网桥br0上，并指定IP地址为192.168.40.241，nameservers指定DNS服务器。修改完后，通过sudo netplan apply重启网络服务生效，然后通过ifconfig查看，原来挂在enp7s0网卡下的IP现在挂到了br0上，宿主机及所有其它虚拟机都通过该网桥来与外部通讯。我们也可以通过brctl show来直观地查看，1234567devuser@server_01:~$ brctl showbridge name bridge id STP enabled interfacesbr0 8000.2a5be3ec2698 no enp7s0docker0 8000.02424524dcce no veth580af8e veth74119f3 vethe7a2b0f vethfe89039 目前因为还没虚机，所以只有宿主机的网卡enp7s0挂在网桥br0上。同时也可以看到docker容器也是通过网桥docker0来通讯的。 2. 虚拟机安装2.1 安装虚拟机安装命令123456sudo virt-install --name=dev-server1 --memory=16384,maxmemory=16384 \\--vcpus=4,maxvcpus=4 --os-type=linux --os-variant=rhel7 \\--location=/home/devuser/tools/CentOS-7-x86_64-DVD-1810.iso \\--disk path=/var/lib/libvirt/images/devserver1.img,size=300 \\--bridge=br0 --graphics=none --console=pty,target_type=serial \\--extra-args=\"console=tty0 console=ttyS0\" 其中–name指定虚机名称；–memory=16384,maxmemory=16384配置了16G内存；–vcpus=4,maxvcpus=4配置了4个CPU内核；centos7需要指定–os-variant=rhel7；–disk path=xx,size=300指定了磁盘路径与大小，这里是300G。 如果执行上述命令出现qemu-kvm: could not open &#39;xx/CentOS-7-x86_64-DVD-1810.iso&#39;: Permission denied异常退出时，可通过修改/etc/libvirt/qemu.conf文件将user = &quot;root&quot;，group = &quot;root&quot;前面的注释去掉解决（https://github.com/jedi4ever/veewee/issues/996） 如无问题，安装程序将出现如下配置界面 可通过输入选项对应的数字来选择不同的配置，依次操作如下步骤完成时区设置：输入2，回车，选择时区设置；输入1，回车，选择“Set timezone”；输入2，回车，选择“Asia”；回车，输入64，回车，选择“Shanghai” 然后进行安装设置，依次操作如下：输入5，回车，进入安装设置；输入c，回车，选择默认的磁盘进行安装；输入c，回车，使用默认的“2) Use All Space”；输入1，回车，选择“1) Standard Partition”进行标准分区；输入c，回车，完成分区设置 最后进入root密码设置，操作如下：输入8，回车，进入root密码设置；输入密码，回车；输入确认密码，回车 完成上述设置后，输入b开始进行安装 等待一段时间后，安装程序停在如下界面 按回车继续，最后输入用户名root，及前面设置的密码登录系统 2.2 虚拟机网络配置虚拟机安装完后，是没有分配IP的，我们通过ip a命令查看， 这时候的eth0下面空空如也，什么都没有。在/etc/sysconfig/network-scripts/ifcfg-eth0文件中添加如下内容 1234567891011121314151617181920[root@localhost ~]# vi /etc/sysconfig/network-scripts/ifcfg-eth0TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=static #静态指定IPDEFROUTE=yes#IPV4_FAILURE_FATAL=no#IPV6INIT=yes#IPV6_AUTOCONF=yes#IPV6_DEFROUTE=yes#IPV6_FAILURE_FATAL=no#IPV6_ADDR_GEN_MODE=stable-privacyNAME=eth0UUID=449ed621-97a8-45b9-902f-0d347e27de98DEVICE=eth0ONBOOT=yes #开机自动启动IPADDR=192.168.40.96NETMASK=255.255.255.0GATEWAY=192.168.40.1DNS1=192.168.40.1 并通过systemctl restart network重启网络生效，这时候再运行ip a查看，eth0下面已经有配置的IP了。不出意外的话，局域网其它主机就可以通过该IP来远程SSH连接了。 这时候我们再通过brctl show来查看网桥挂载情况，br0下面已经多了一个vnet0虚拟网卡了。123456789devuser@server_01:~$ brctl showbridge name bridge id STP enabled interfacesbr0 8000.2a5be3ec2698 no enp7s0 vnet0docker0 8000.02424524dcce no veth580af8e veth74119f3 vethd270ee8 vethe7a2b0f vethfe89039 虚拟机装完后，默认的hostname是localhost，针对centos7，我们可以通过如下命令来修改hostname1[root@localhost ~]# hostnamectl set-hostname dev-server1 然后在/etc/hosts文件中添加127.0.0.1的host映射 dev-server1123[root@localhost ~]# vi /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 dev-server1::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 3. 虚拟机管理 列出当前运行的虚拟机virsh list1234devuser@server_01:~$ virsh list Id Name State---------------------------------------------------- 5 dev-server1 running 如果列出所有的，则virsh list --all 从宿主机进入虚拟机virsh console，后面接虚拟机ID或名称12345678devuser@server_01:~$ virsh console 5Connected to domain dev-server1Escape character is ^]CentOS Linux 7 (Core)Kernel 3.10.0-957.el7.x86_64 on an x86_64dev-server1 login: 输入用户名，密码即可登录虚拟机，按Ctrl+]可退出。 启动与关闭虚拟机virsh start|shutdown 12345devuser@cserver_01:~$ virsh start dev-server1Domain dev-server1 starteddevuser@server_01:~$ virsh shutdown 5Domain 5 is being shutdown libvirtd启动时，自动启动虚拟机 12devuser@server_01:~$ virsh autostart dev-server1Domain dev-server1 marked as autostarted 挂起/恢复虚拟机 12devuser@server_01:~$ virsh suspend dev-server1 # 挂起虚拟机devuser@server_01:~$ virsh resume dev-server1 # 恢复挂起的虚拟机 销毁虚拟机 1devuser@server_01:~$ virsh undefine dev-server1 # 彻底销毁虚拟机，会删除虚拟机配置文件，但不会删除虚拟磁盘 我的个人博客地址：http://blog.jboost.cn我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"高效实践","slug":"高效实践","permalink":"http://blog.jboost.cn/categories/高效实践/"}],"tags":[{"name":"kvm","slug":"kvm","permalink":"http://blog.jboost.cn/tags/kvm/"}]},{"title":"软件项目研发流程该怎么规范","slug":"project-process","date":"2019-07-08T11:14:47.000Z","updated":"2019-07-09T11:13:37.300Z","comments":true,"path":"2019/07/08/project-process.html","link":"","permalink":"http://blog.jboost.cn/2019/07/08/project-process.html","excerpt":"在软件项目研发管理过程中，是否经常出现这样的场景：开发人员不知道什么时候转测；项目经理拿个Excel文档群里一发，某任务前天就应该完成的，怎么现在还没开始搞；前端问这部分UI是谁在做，什么时候能做完；测试说线上这个bug又是谁改出来的，这次没转测这模块……等等。整个协作感觉一团乱麻，团队内部充满了甩锅与抱怨的氛围。软件项目的研发流程该怎么规范，让团队成员都能目标明确，步调一致，让产品迭代充满节奏感。本文基于笔者项目研发管理经验整理，希望起到抛砖引玉的作用，探讨高效团队的协作流程模式。","text":"在软件项目研发管理过程中，是否经常出现这样的场景：开发人员不知道什么时候转测；项目经理拿个Excel文档群里一发，某任务前天就应该完成的，怎么现在还没开始搞；前端问这部分UI是谁在做，什么时候能做完；测试说线上这个bug又是谁改出来的，这次没转测这模块……等等。整个协作感觉一团乱麻，团队内部充满了甩锅与抱怨的氛围。软件项目的研发流程该怎么规范，让团队成员都能目标明确，步调一致，让产品迭代充满节奏感。本文基于笔者项目研发管理经验整理，希望起到抛砖引玉的作用，探讨高效团队的协作流程模式。 1. 协作流程图 基本原则： 所有问题可跟踪 （需求、Bug、优化） 所有工作透明化 （工作量、进展、Block因素） 2. 各阶段内容详解2.1. 需求收集确认本阶段主要是与产品经理相关的活动内容： 产品经理在每次版本开始之前定期收集各方需求，包括客户反馈、领导意见（对很多中小企业来说，老板就是最大的“用户”）、市场调研及技术团队需求等来源，输出需求列表 在版本开始之前召开版本计划会议，参与者包括项目经理、产品经理，及项目核心成员，按优先级梳理需求列表，输出下次版本的初步任务列表（之所以说初步，是因为该列表后面可能根据评审情况进行调整） 产品经理基于初步任务列表完成详细需求文档，组织团队成员——包括相关UI、开发、测试，召开 需求评审会议，输出评审意见及修正完成时间 产品经理针对需求评审会议中团队提出的意见建议，在修正完成时间内及时修正需求文档，并及时通知团队相关成员，输出确定的需求文档 注：可在需求评审会议后，进行任务的初步认领分配与时间估算，初步确定转测、上线时间节点 2.2. 设计开发 项目经理根据需求文档完成任务拆解，并在任务管理系统中创建对应任务单，指定经办人 各经办人认领任务后，根据自身任务的期限，及时与依赖方沟通，确定依赖任务的完成时间，以免影响自身任务进度，存在问题及时向项目经理反馈。 UI设计完成后，相关开发人员与产品经理需对UI设计进行确认，如果涉及内容较多，可组织UI评审会议（由产品经理或项目经理权衡组织） 涉及流程的开发任务需要有必要的设计，技术相关负责人负责对设计review，没有review的设计不能开发；任务开发完成需要进行代码review 项目经理定期组织项目例会（紧急版本建议每天一次，较长期版本建议一周一次或两次），持续跟进任务进度与问题，并及时协调处理，以保障进度预期 在预定转测时间节点前一天，开发人员编写转测文档，描述本次版本调整内容（附上任务列表）及注意事项，并通知项目相关人员（钉钉群或邮件） 2.3. 测试 需求评审会议后，测试人员需对各功能模块编写测试用例文档，并在转测前组织测试评审会议，对各功能各环节进行复核与查漏补缺 一次版本任务可根据情况分批测试，并确定每轮转测的内容与时间节点；分批测试完成后，需在上线前进行集成测试，注意预留一定的时间用于问题修复 测试完成，需要将测试结论通报项目相关人员（钉钉群或邮件），包括遗留问题与是否达到上线要求结论 注：产品经理可在转测后对开发实现进行验收，以确定开发是否符合需求实际，以便及时进行调整 2.4. 上线 上线人员需在上线前编写上线方案文档，记录此次上线内容，并对此次上线操作进行推演，对所涉及的所有操作按步骤进行记录，如数据库操作，代码merge，jenkins构建等；对可能存在的问题进行备注及对应的处理方案，并提交技术相关负责人review 项目经理结合测试结论及其它各方面情况，决策是否上线，并将意见通知到项目相关人员（钉钉群或邮件） 上线人员按照上线方案文档记录的步骤，依次完成上线操作（上线操作最好至少由两人完成，一人操作，一人检视，避免出错） 上线完成后，测试人员与产品经理对此次上线进行线上验证，确保线上功能流程无问题 验证无误后，由项目经理或其他指定负责人将上线通知发布至利益相关者，包括项目团队所有成员及相关合作方，说明上线时间、上线内容、影响因素、注意事项等（即时通讯群或邮件） 2.5. 复盘 版本结束后，项目经理根据情况对上个周期组织复盘总结会，总结存在的问题与原因，及后续规避的办法，总结积累的经验等 以上各阶段并不是完全串行推进的，相互之间存在一些穿插，比如下一版本需求的收集整理与当前版本的开发是并行推进的，开发与测试也可以以分阶段转测的形式并行推进，等等。 3. 一些常用工具 jira 用于项目任务管理，其中Agile插件可方便查看整体任务面板，对任务状态一目了然，需要求团队成员养成及时更新状态的习惯 confluence 文档管理，用于各类文档的集中化维护，以上所述的如需求文档、开发设计文档、转测文档、上线文档等均可使用confluence以项目空间的形式集中化管理。 gitlab 代码管理 jenkins 项目部署构建工具 nexus 搭建maven私有库 4. 总结团队工作讲求步调与节奏，好的流程与规范可以让一个水平一般的人也能充分发挥其作用，从而让团队整体稳步前进，高效产出。而不好的流程，或根本不重视流程的团队，却往往一盘散沙，甩锅与抱怨充斥，战斗力低下。本文以相对较粗粒度对软件项目的基本流程管理做了介绍，更细节的内容可能需要团队根据内部具体情况进行相应处理与对待。链接： https://pan.baidu.com/s/1WBHsIWoquKTQHJ6IaSql3Q 是笔者基于以前团队敏捷项目管理及一些具体问题的思考分享PPT，供参考。提取码：awya 我的个人博客地址：http://blog.jboost.cn我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"teamwork","slug":"teamwork","permalink":"http://blog.jboost.cn/categories/teamwork/"}],"tags":[{"name":"agile","slug":"agile","permalink":"http://blog.jboost.cn/tags/agile/"}]},{"title":"线程池的基本原理，看完就懂了","slug":"threadpool","date":"2019-07-05T09:32:30.000Z","updated":"2019-07-09T11:19:28.733Z","comments":true,"path":"2019/07/05/threadpool.html","link":"","permalink":"http://blog.jboost.cn/2019/07/05/threadpool.html","excerpt":"本文内容是基于研发部门内部的分享整理，记录下来供学习或回顾。","text":"本文内容是基于研发部门内部的分享整理，记录下来供学习或回顾。 1. 为什么要用线程池 降低资源消耗。通过重复利用已创建的线程降低线程创建、销毁线程造成的消耗。 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配、调优和监控 2. ThreadPoolExecutor线程池类参数详解 参数 说明 corePoolSize 核心线程数量，线程池维护线程的最少数量 maximumPoolSize 线程池维护线程的最大数量 keepAliveTime 线程池除核心线程外的其他线程的最长空闲时间，超过该时间的空闲线程会被销毁 unit keepAliveTime的单位，TimeUnit中的几个静态属性：NANOSECONDS、MICROSECONDS、MILLISECONDS、SECONDS workQueue 线程池所使用的任务缓冲队列 threadFactory 线程工厂，用于创建线程，一般用默认的即可 handler 线程池对拒绝任务的处理策略 当线程池任务处理不过来的时候（什么时候认为处理不过来后面描述），可以通过handler指定的策略进行处理，ThreadPoolExecutor提供了四种策略： ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常；也是默认的处理方式。 ThreadPoolExecutor.DiscardPolicy：丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程） ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 可以通过实现RejectedExecutionHandler接口自定义处理方式。 3. 线程池任务执行3.1. 添加执行任务 submit() 该方法返回一个Future对象，可执行带返回值的线程；或者执行想随时可以取消的线程。Future对象的get()方法获取返回值。Future对象的cancel(true/false)取消任务，未开始或已完成返回false，参数表示是否中断执行中的线程 execute() 没有返回值。 3.2. 线程池任务提交过程一个线程提交到线程池的处理流程如下图 如果此时线程池中的数量小于corePoolSize，即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务。 如果此时线程池中的数量等于corePoolSize，但是缓冲队列workQueue未满，那么任务被放入缓冲队列。 如果此时线程池中的数量大于等于corePoolSize，缓冲队列workQueue满，并且线程池中的数量小于maximumPoolSize，建新的线程来处理被添加的任务。 如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量等于maximumPoolSize，那么通过 handler所指定的策略来处理此任务。 当线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止。这样，线程池可以动态的调整池中的线程数。 总结即：处理任务判断的优先级为 核心线程corePoolSize、任务队列workQueue、最大线程maximumPoolSize，如果三者都满了，使用handler处理被拒绝的任务。 注意： 当workQueue使用的是无界限队列时，maximumPoolSize参数就变的无意义了，比如new LinkedBlockingQueue(),或者new ArrayBlockingQueue(Integer.MAX_VALUE); 使用SynchronousQueue队列时由于该队列没有容量的特性，所以不会对任务进行排队，如果线程池中没有空闲线程，会立即创建一个新线程来接收这个任务。maximumPoolSize要设置大一点。 核心线程和最大线程数量相等时keepAliveTime无作用. 3.3. 线程池关闭 shutdown() 不接收新任务,会处理已添加任务 shutdownNow() 不接受新任务,不处理已添加任务,中断正在处理的任务 4. 常用队列介绍 ArrayBlockingQueue： 这是一个由数组实现的容量固定的有界阻塞队列. SynchronousQueue： 没有容量，不能缓存数据；每个put必须等待一个take; offer()的时候如果没有另一个线程在poll()或者take()的话返回false。 LinkedBlockingQueue： 这是一个由单链表实现的默认无界的阻塞队列。LinkedBlockingQueue提供了一个可选有界的构造函数，而在未指明容量时，容量默认为Integer.MAX_VALUE。 队列操作: 方法 说明 add 增加一个元索; 如果队列已满，则抛出一个异常 remove 移除并返回队列头部的元素; 如果队列为空，则抛出一个异常 offer 添加一个元素并返回true; 如果队列已满，则返回false poll 移除并返回队列头部的元素; 如果队列为空，则返回null put 添加一个元素; 如果队列满，则阻塞 take 移除并返回队列头部的元素; 如果队列为空，则阻塞 element 返回队列头部的元素; 如果队列为空，则抛出一个异常 peek 返回队列头部的元素; 如果队列为空，则返回null 5. Executors线程工厂类 Executors.newCachedThreadPool();说明: 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程.内部实现：new ThreadPoolExecutor(0,Integer.MAX_VALUE,60L,TimeUnit.SECONDS,new SynchronousQueue()); Executors.newFixedThreadPool(int);说明: 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。内部实现：new ThreadPoolExecutor(nThreads, nThreads,0L,TimeUnit.MILLISECONDS,new LinkedBlockingQueue()); Executors.newSingleThreadExecutor();说明:创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照顺序执行。内部实现：new ThreadPoolExecutor(1,1,0L,TimeUnit.MILLISECONDS,new LinkedBlockingQueue()) Executors.newScheduledThreadPool(int);说明:创建一个定长线程池，支持定时及周期性任务执行。内部实现：new ScheduledThreadPoolExecutor(corePoolSize) 【附】阿里巴巴Java开发手册中对线程池的使用规范 【强制】创建线程或线程池时请指定有意义的线程名称，方便出错时回溯。正例： 123456public class TimerTaskThread extends Thread &#123; public TimerTaskThread()&#123; super.setName(\"TimerTaskThread\"); ... &#125;&#125; 【强制】线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。说明： 使用线程池的好处是减少在创建和销毁线程上所花的时间以及系统资源的开销，解决资源不足的问题。如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。 【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。说明： Executors 返回的线程池对象的弊端如下：1） FixedThreadPool 和 SingleThreadPool:允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。2） CachedThreadPool 和 ScheduledThreadPool:允许的创建线程数量为 Integer.MAX_VALUE， 可能会创建大量的线程，从而导致 OOM。 6. 总结ThreadPoolExecutor通过几个核心参数来定义不同类型的线程池，适用于不同的使用场景；其中在任务提交时，会依次判断corePoolSize， workQueque， 及maximumPoolSize，不同的状态不同的处理。技术领域水太深，如果不是日常使用，基本一段时间后某些知识点就忘的差不多了，因此阶段性地回顾与总结，对夯实自己的技术基础很有必要。我的个人博客地址：http://blog.jboost.cn我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"高效实践","slug":"高效实践","permalink":"http://blog.jboost.cn/categories/高效实践/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"concurrency","slug":"concurrency","permalink":"http://blog.jboost.cn/tags/concurrency/"}]},{"title":"Spring Boot从入门到实战（九）：统一异常处理","slug":"springboot-error","date":"2019-07-03T06:35:02.000Z","updated":"2019-07-22T10:30:36.823Z","comments":true,"path":"2019/07/03/springboot-error.html","link":"","permalink":"http://blog.jboost.cn/2019/07/03/springboot-error.html","excerpt":"都说管理的精髓就是“制度管人，流程管事”。而所谓流程，就是对一些日常工作环节、方式方法、次序等进行标准化、规范化。且不论精不精髓，在技术团队中，对一些通用场景，统一规范是必要的，只有步调一致，才能高效向前。如前后端交互协议，如本文探讨的异常处理。","text":"都说管理的精髓就是“制度管人，流程管事”。而所谓流程，就是对一些日常工作环节、方式方法、次序等进行标准化、规范化。且不论精不精髓，在技术团队中，对一些通用场景，统一规范是必要的，只有步调一致，才能高效向前。如前后端交互协议，如本文探讨的异常处理。 1. Spring Mvc中的异常处理在spring mvc中，跟异常处理的相关类大致如下 上图中，spring mvc中处理异常的类（包括在请求映射时与请求处理过程中抛出的异常），都是 HandlerExceptionResolver 接口的实现，并且都实现了 Ordered 接口。与拦截器链类似，如果容器中存在多个实现了 HandlerExceptionResolver 接口的异常处理类，则它们的 resolveException 方法会被依次调用，顺序由order决定，值越小的先执行，只要其中一个调用返回不是null，则后续的异常处理将不再执行。 各实现类简单介绍如下： DefaultHandlerExceptionResolver： 这个是默认实现，处理Spring定义的各种标准异常，将其转换为对应的Http Status Code，具体处理的异常参考 doResolveException 方法 ResponseStatusExceptionResolver：用来支持@ResponseStatus注解使用的实现，如果自定义的异常通过@ResponseStatus注解进行了修饰，并且容器中存在ResponseStatusExceptionResolver的bean，则自定义异常抛出时会被该bean进行处理，返回注解定义的Http Status Code及内容给客户端 ExceptionHandlerExceptionResolver：用来支持@ExceptionHandler注解使用的实现，使用该注解修饰的方法来处理对应的异常。不过该注解的作用范围只在controller类，如果需要全局处理，则需要配合@ControllerAdvice注解使用。 SimpleMappingExceptionResolver：将异常映射为视图 HandlerExceptionResolverComposite：就是各类实现的组合，依次执行，只要其中一个处理返回不为null，则不再处理。 因为本文主要是对spring boot如何对异常统一处理进行探讨，所以以上只对各实现做了基本介绍，更加详细的内容可查阅相关文档或后续再补上。 2. Spring Boot中如何统一异常处理通过第一部分介绍，可以使用@ExceptionHandler + @ControllerAdvice 组合的方式来实现异常的全局统一处理。对于REST服务来说，spring mvc提供了一个抽象类 ResponseEntityExceptionHandler， 该类类似于上面介绍的 DefaultHandlerExceptionResolver，对一些标准的异常进行了处理，但不是返回 ModelAndView对象， 而是返回 ResponseEntity对象。故我们可以基于该类来实现REST服务异常的统一处理定义异常处理类 BaseWebApplicationExceptionHandler 如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@RestControllerAdvicepublic class BaseWebApplicationExceptionHandler extends ResponseEntityExceptionHandler &#123; private boolean includeStackTrace; public BaseWebApplicationExceptionHandler(boolean includeStackTrace)&#123; super(); this.includeStackTrace = includeStackTrace; &#125; private final Logger logger = LoggerFactory.getLogger(getClass()); @ExceptionHandler(BizException.class) public ResponseEntity&lt;Object&gt; handleBizException(BizException ex) &#123; logger.warn(\"catch biz exception: \" + ex.toString(), ex.getCause()); return this.asResponseEntity(HttpStatus.valueOf(ex.getHttpStatus()), ex.getErrorCode(), ex.getErrorMessage(), ex); &#125; @ExceptionHandler(&#123;IllegalArgumentException.class, IllegalStateException.class&#125;) public ResponseEntity&lt;Object&gt; handleIllegalArgumentException(Exception ex) &#123; logger.warn(\"catch illegal exception.\", ex); return this.asResponseEntity(HttpStatus.BAD_REQUEST, HttpStatus.BAD_REQUEST.name().toLowerCase(), ex.getMessage(), ex); &#125; @ExceptionHandler(Exception.class) public ResponseEntity&lt;Object&gt; handleException(Exception ex) &#123; logger.error(\"catch exception.\", ex); return this.asResponseEntity(HttpStatus.INTERNAL_SERVER_ERROR, HttpStatus.INTERNAL_SERVER_ERROR.name().toLowerCase(), ExceptionConstants.INNER_SERVER_ERROR_MSG, ex); &#125; protected ResponseEntity&lt;Object&gt; handleExceptionInternal( Exception ex, @Nullable Object body, HttpHeaders headers, HttpStatus status, WebRequest request) &#123; if (HttpStatus.INTERNAL_SERVER_ERROR.equals(status)) &#123; request.setAttribute(WebUtils.ERROR_EXCEPTION_ATTRIBUTE, ex, WebRequest.SCOPE_REQUEST); &#125; logger.warn(\"catch uncustom exception.\", ex); return this.asResponseEntity(status, status.name().toLowerCase(), ex.getMessage(), ex); &#125; protected ResponseEntity&lt;Object&gt; asResponseEntity(HttpStatus status, String errorCode, String errorMessage, Exception ex) &#123; Map&lt;String, Object&gt; data = new LinkedHashMap&lt;&gt;(); data.put(BizException.ERROR_CODE, errorCode); data.put(BizException.ERROR_MESSAGE, errorMessage); //是否包含异常的stack trace if(includeStackTrace)&#123; addStackTrace(data, ex); &#125; return new ResponseEntity&lt;&gt;(data, status); &#125; private void addStackTrace(Map&lt;String, Object&gt; errorAttributes, Throwable error) &#123; StringWriter stackTrace = new StringWriter(); error.printStackTrace(new PrintWriter(stackTrace)); stackTrace.flush(); errorAttributes.put(BizException.ERROR_TRACE, stackTrace.toString()); &#125;&#125; 这里有几点： 定义了一个includeStackTrace变量，来控制是否输出异常栈信息 自定义了一个异常类BizException，表示可预知的业务异常，并对它提供了处理方法，见handleBizException方法 对其它未预知异常，用Exception类型进行最后处理，见handleException方法 重写了超类的handleExceptionInternal方法，统一响应内容的字段与格式 针对REST服务，使用的是@RestControllerAdvice注解，而不是@ControllerAdvice BaseWebApplicationExceptionHandler是通过增强的方式对controller抛出的异常做了统一处理，那如果请求都没有到达controller怎么办，比如在过滤器那边就抛异常了，Spring Boot其实对错误的处理做了一些自动化配置，参考ErrorMvcAutoConfiguration类，具体这里不详述，只提出方案——自定义ErrorAttributes实现，如下所示1234567891011public class BaseErrorAttributes extends DefaultErrorAttributes &#123; private boolean includeStackTrace; @Override public Map&lt;String, Object&gt; getErrorAttributes(WebRequest webRequest, boolean includeStackTrace) &#123; Map&lt;String, Object&gt; errorAttributes = new LinkedHashMap&lt;String, Object&gt;(); addStatus(errorAttributes, webRequest); addErrorDetails(errorAttributes, webRequest, this.includeStackTrace); return errorAttributes; &#125; 以上只列出了主要部分，具体实现可参考源码。这里同样定义了includeStackTrace来控制是否包含异常栈信息。 最后，将以上两个实现通过配置文件注入容器，如下：123456789101112131415161718192021222324252627282930313233@Configuration@ConditionalOnClass(&#123;Servlet.class, DispatcherServlet.class, WebMvcConfigurer.class&#125;)@ConditionalOnMissingBean(ResponseEntityExceptionHandler.class)@AutoConfigureBefore(ErrorMvcAutoConfiguration.class)public class ExceptionHandlerAutoConfiguration &#123; @Profile(&#123;\"test\", \"formal\", \"prod\"&#125;) @Bean public ResponseEntityExceptionHandler defaultGlobalExceptionHandler() &#123; //测试、正式环境，不输出异常的stack trace return new BaseWebApplicationExceptionHandler(false); &#125; @Profile(&#123;\"default\",\"local\",\"dev\"&#125;) @Bean public ResponseEntityExceptionHandler devGlobalExceptionHandler() &#123; //本地、开发环境，输出异常的stack trace return new BaseWebApplicationExceptionHandler(true); &#125; @Profile(&#123;\"test\", \"formal\", \"prod\"&#125;) @Bean public ErrorAttributes basicErrorAttributes() &#123; //测试、正式环境，不输出异常的stack trace return new BaseErrorAttributes(false); &#125; @Profile(&#123;\"default\",\"local\",\"dev\"&#125;) @Bean public ErrorAttributes devBasicErrorAttributes() &#123; //本地、开发环境，输出异常的stack trace return new BaseErrorAttributes(true); &#125;&#125; 上面的@Profile主要是控制针对不同环境，输出不同的响应内容。以上配置的意思是在profile为default、local、dev时，响应内容中包含异常栈信息；profile为test、formal、prod时，响应内容不包含异常栈信息。这么做的好处是，开发阶段，当前端联调时，如果出错，可直接从响应内容中看到异常栈，方便服务端开发人员快速定位问题，而测试、生产环境， 就不要返回异常栈信息了。 3. 基于Spring Boot的异常处理规范 异常的表示形式异常一般可通过自定义异常类，或定义异常的信息，比如code，message之类，然后通过一个统一的异常类进行封装。如果每一种异常都定义一个异常类，则会造成异常类过多，所以实践开发中我一般倾向于后者。可以定义一个接口，该接口主要是方便后面的异常处理工具类实现12345public interface BaseErrors &#123; String getCode(); String getMsg();&#125; 然后定义一个枚举，实现该接口，在该枚举中定义异常信息，如123456789101112131415161718public enum ErrorCodeEnum implements BaseErrors &#123; qrcode_existed(\"该公众号下已存在同名二维码\"), authorizer_notexist(\"公众号不存在\"), private String msg; private ErrorCodeEnum(String msg) &#123; this.msg = msg; &#125; public String getCode() &#123; return name(); &#125; public String getMsg() &#123; return msg; &#125;&#125; 封装异常处理分场景定义了ClientSideException，ServerSideException，UnauthorizedException，ForbiddenException异常，分别表示客户端异常（400），服务端异常（500），未授权异常（401），禁止访问异常（403），如ClientSideException定义12345678910public class ClientSideException extends BizException &#123; public &lt;E extends Enum&lt;E&gt; &amp; BaseErrors&gt; ClientSideException(E exceptionCode, Throwable cause) &#123; super(HttpStatus.BAD_REQUEST, exceptionCode, cause); &#125; public &lt;E extends Enum&lt;E&gt; &amp; BaseErrors&gt; ClientSideException(E exceptionCode) &#123; super(HttpStatus.BAD_REQUEST, exceptionCode, null); &#125;&#125; 并且提供一个异常工具类ExceptionUtil，方便不同场景使用， rethrowClientSideException：抛出ClientSideException，将以status code 400返回客户端。由客户端引起的异常调用该方法，如参数校验失败。 rethrowUnauthorizedException： 抛出UnauthorizedException，将以status code 401返回客户端。访问未授权时调用，如token校验失败等。 rethrowForbiddenException： 抛出ForbidenException，将以status code 403返回客户端。访问被禁止时调用，如用户被禁用等。 rethrowServerSideException： 抛出ServerSideException，将以status code 500返回客户端。服务端引起的异常调用该方法，如调用第三方服务异常，数据库访问出错等。 在实际使用时，分两种情况， 不通过try/catch主动抛出异常，如： 1234if (StringUtils.isEmpty(appId)) &#123; LOG.warn(\"the authorizer for site[&#123;&#125;] is not existed.\", templateMsgRequestDto.getSiteId()); ExceptionUtil.rethrowClientSideException(ErrorCodeEnum.authorizer_notexist);&#125; 通过try/catch异常重新抛出（注意：可预知的异常，需要给客户端返回某种提示信息的，必须通过该方式重新抛出。否则将返回统一的code 500,提示“抱歉，服务出错了，请稍后重试”的提示信息）如： 1234567try &#123; String result = wxOpenService.getWxOpenComponentService().getWxMpServiceByAppid(appId).getTemplateMsgService().sendTemplateMsg(templateMessage); LOG.info(\"result: &#123;&#125;\", result);&#125; catch (WxErrorException wxException) &#123; //这里不需要打日志，会统一在异常处理里记录日志 ExceptionUtil.rethrowServerSideException(ExceptionCodeEnum.templatemsg_fail, wxException);&#125; 具体实现参考源码： https://github.com/ronwxy/base-spring-boot/tree/master/spring-boot-autoconfigure/src/main/java/cn/jboost/springboot/autoconfig/error另附demo源码：https://github.com/ronwxy/springboot-demos/tree/master/springboot-error 4. 总结本文写完感觉信息量有点多，对于不具备一定基础的人来说理解可能有点难度。如果有任何疑问，欢迎交流。后续有需要的话也可以针对某个环节再进行细化补充。本文所提的规范不一定是最好的实践，但规范或流程的管理，都是遵循先僵化，后优化，再固化的步骤，先解决有没有的问题，再解决好不好的问题。我的个人博客地址：http://blog.jboost.cn我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注）———————————————————————————————————————————————————————————————欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"使用nvm来管理Node多版本","slug":"use-nvm","date":"2019-07-02T00:41:51.000Z","updated":"2019-07-09T11:19:28.689Z","comments":true,"path":"2019/07/02/use-nvm.html","link":"","permalink":"http://blog.jboost.cn/2019/07/02/use-nvm.html","excerpt":"最近在为前端配置jenkins持续集成环境时，在运行npm install下载依赖包的时候，速度极慢，而本地很快。对比node版本，一个v10.15.3，速度很快，一个v8.10.0，速度极慢。两者都设置了国内镜像。升级node能否解决问题？有没有工具支持node多版本管理，像python的anaconda一样？答案是有，叫nvm —— node version manager。","text":"最近在为前端配置jenkins持续集成环境时，在运行npm install下载依赖包的时候，速度极慢，而本地很快。对比node版本，一个v10.15.3，速度很快，一个v8.10.0，速度极慢。两者都设置了国内镜像。升级node能否解决问题？有没有工具支持node多版本管理，像python的anaconda一样？答案是有，叫nvm —— node version manager。 项目地址： https://github.com/nvm-sh/nvm 1. 安装linux下：12345# 下载并执行安装curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash# 安装后执行source使其生效source ~/.bashrc 为了加速node的下载，可在~/.bashrc中添加 export NVM_NODEJS_ORG_MIRROR=https://npm.taobao.org/mirrors/node windows：参考 https://github.com/coreybutler/nvm-windows/releases 2. 使用 列出所有node版本nvm ls-remote 只列出长期支持版本，一般生产环境使用long term support版nvm ls-remote --lts 安装指定版本nvm install v10.15.3 安装完后即可查看安装的node及npm的版本 12node -v npm -v 查看已安装版本nvm ls 使用指定的版本，重连bash即失效nvm use 10.15.3 设置默认，重连也生效nvm alias default 10.15.3 配置npm国内淘宝镜像123npm config set registry https://registry.npm.taobao.org --globalnpm config set disturl https://npm.taobao.org/dist --global 3. 总结nvm可在一个系统中非常便捷地管理多个node版本，并能自由切换使用哪个版本，方便需要多版本并存的场景。 我的个人博客地址：http://blog.jboost.cn我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy————————————————————————————————————————欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"高效实践","slug":"高效实践","permalink":"http://blog.jboost.cn/categories/高效实践/"}],"tags":[{"name":"node","slug":"node","permalink":"http://blog.jboost.cn/tags/node/"},{"name":"npm","slug":"npm","permalink":"http://blog.jboost.cn/tags/npm/"}]},{"title":"redission-tomcat 快速实现从单机部署到多机部署","slug":"session-redis","date":"2019-06-29T01:01:24.000Z","updated":"2019-07-09T11:19:28.777Z","comments":true,"path":"2019/06/29/session-redis.html","link":"","permalink":"http://blog.jboost.cn/2019/06/29/session-redis.html","excerpt":"一些项目初期出于简单快速，都是做单机开发与部署，但是随着业务的扩展或对可用性要求的提高，单机环境已不满足需求。单机部署往多机部署切换，其中可能存在的一个重要环节就是session的共享（如果一开始就是基于token的认证则可忽略）。本文介绍一个基于redis的tomcat session管理开源项目：redission-tomcat，可无代码侵入式地快速实现session共享。","text":"一些项目初期出于简单快速，都是做单机开发与部署，但是随着业务的扩展或对可用性要求的提高，单机环境已不满足需求。单机部署往多机部署切换，其中可能存在的一个重要环节就是session的共享（如果一开始就是基于token的认证则可忽略）。本文介绍一个基于redis的tomcat session管理开源项目：redission-tomcat，可无代码侵入式地快速实现session共享。 1. 简介redisson是与jedis类似的一个redis客户端，其功能比jedis要更丰富一些。redission-tomcat是一个基于redis的tomcat session管理器项目，项目地址：https://github.com/redisson/redisson/tree/master/redisson-tomcat 。相比于其它实现，该项目的存储更为高效，写操作也更为优化。每一个session参数是在调用HttpSession.setAttribute时写入redis的，其它方案却一般是每次都将整个session进行序列化后写入。 2. 使用 将redisson-all-3.11.0.jar，redisson-tomcat-8-3.11.0.jar（针对tomcat8，其它版本可在上述项目地址页面找到下载链接）两个jar包下载放到tomcat的lib目录下。 在tomcat conf目录下的context.xml文件中添加如下配置 123&lt;Manager className=\"org.redisson.tomcat.RedissonSessionManager\"configPath=\"$&#123;catalina.base&#125;/conf/redisson.conf\" readMode=\"MEMORY\" updateMode=\"AFTER_REQUEST\" broadcastSessionEvents=\"false\"/&gt; 其中 configPath：指向Redisson的json或yaml格式的配置文件，第3步中给出。 readMode：session属性的读取模式。可取值 1. MEMORY, 该模式会将session属性同时保存到本地tomcat session与redis中，后续的session更新通过redis事件传播到本地tomcat session；2. REDIS，只将session属性保存到redis中。默认为REDIS。 updateMode：session属性的更新模式。可取值 1. DEFAULT，session属性只通过setAttribute方法保存到redis中；2. AFTER_REQUEST，在每次请求之后，将所有session属性保存至redis。默认为DEFAULT。 broadcastSessionEvents：如果设置为true，则sessionCreated与sessionDestroyed事件将会被广播到所有tomcat实例，并使所有注册的HttpSessionListeners监听器被触发。默认为false。 在tomcat conf目录下新增配置文件redisson.conf，内容如下12345678910111213141516171819202122232425&#123; \"singleServerConfig\":&#123; \"idleConnectionTimeout\":10000, \"connectTimeout\":10000, \"timeout\":3000, \"retryAttempts\":3, \"retryInterval\":1500, \"password\":\"123456\", \"subscriptionsPerConnection\":5, \"clientName\":null, \"address\": \"redis://127.0.0.1:6379\", \"subscriptionConnectionMinimumIdleSize\":1, \"subscriptionConnectionPoolSize\":50, \"connectionMinimumIdleSize\":24, \"connectionPoolSize\":64, \"database\":0, \"dnsMonitoringInterval\":5000 &#125;, \"threads\":16, \"nettyThreads\":32, \"codec\":&#123; \"class\":\"org.redisson.codec.FstCodec\" &#125;, \"transportMode\":\"NIO\"&#125; 以上为单机模式redis环境配置，其中password，address修改为自己的值。如果是集群模式，则配置文件为12345678910111213141516171819202122232425262728293031323334353637&#123; \"sentinelServersConfig\":&#123; \"idleConnectionTimeout\":10000, \"connectTimeout\":10000, \"timeout\":3000, \"retryAttempts\":3, \"retryInterval\":1500, \"failedSlaveReconnectionInterval\":3000, \"failedSlaveCheckInterval\":60000, \"password\":null, \"subscriptionsPerConnection\":5, \"clientName\":null, \"loadBalancer\":&#123; \"class\":\"org.redisson.connection.balancer.RoundRobinLoadBalancer\" &#125;, \"subscriptionConnectionMinimumIdleSize\":1, \"subscriptionConnectionPoolSize\":50, \"slaveConnectionMinimumIdleSize\":24, \"slaveConnectionPoolSize\":64, \"masterConnectionMinimumIdleSize\":24, \"masterConnectionPoolSize\":64, \"readMode\":\"SLAVE\", \"subscriptionMode\":\"SLAVE\", \"sentinelAddresses\":[ \"redis://127.0.0.1:26379\", \"redis://127.0.0.1:26389\" ], \"masterName\":\"mymaster\", \"database\":0 &#125;, \"threads\":16, \"nettyThreads\":32, \"codec\":&#123; \"class\":\"org.redisson.codec.FstCodec\" &#125;, \"transportMode\":\"NIO\"&#125; 我们可以使用nginx来实现负载均衡，参考配置1234567891011121314151617upstream cnserver&#123; server 127.0.0.1:8080 weight=2 fail_timeout=10s max_fails=1; server 127.0.0.1:8081 weight=2 fail_timeout=10s max_fails=1;&#125;server &#123; listen 80; server_name localhost; index index.html index.htm; location /rest/ &#123; index index.html; proxy_pass http://cnserver/rest/; &#125;&#125; 以上即为使用redisson-tomcat来实现单机部署到多机部署的所有配置。 3. 总结技术架构都是随着业务的发展而不断演进。在业务发展初期，用户量、业务复杂度都相对较低，为了实现快速上线验证，往往采用简单单一的架构。许多项目可能还没来得及进行架构演进升级就GG了，而有幸继续成长的项目必然会随着业务的扩张不断优化与升级。本文介绍的redisson-tomcat可帮助单机项目快速切换到多机支持，当然只是在session管理环节。如果涉及到其它如文件上传，定时任务等分布式支持，则要另做相应调整了。 我的个人博客地址：http://blog.jboost.cn我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy （一个不只有实战干货的技术公众号， 欢迎关注）———————————————————————————————————————————————————————————————欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"高效实践","slug":"高效实践","permalink":"http://blog.jboost.cn/categories/高效实践/"}],"tags":[{"name":"session","slug":"session","permalink":"http://blog.jboost.cn/tags/session/"},{"name":"tomcat","slug":"tomcat","permalink":"http://blog.jboost.cn/tags/tomcat/"},{"name":"redission","slug":"redission","permalink":"http://blog.jboost.cn/tags/redission/"}]},{"title":"swagger api文档集中化注册管理","slug":"swagger-register","date":"2019-06-28T08:59:05.000Z","updated":"2019-07-09T11:19:30.989Z","comments":true,"path":"2019/06/28/swagger-register.html","link":"","permalink":"http://blog.jboost.cn/2019/06/28/swagger-register.html","excerpt":"接口文档是前后端开发对接时很重要的一个组件。手动编写接口文档既费时，又存在文档不能随代码及时更新的问题，因此产生了像swagger这样的自动生成接口文档的框架。swagger文档一般是随项目代码生成与更新，访问地址也是基于项目地址，因此对项目数不多的团队还好。如果团队的项目很多，比如采用微服务架构的团队，动则几十甚至上百个服务项目，那就意味着前端开发人员需要记住几十甚至上百个swagger文档地址，那就很不友好了。目前貌似还没有较流行的API文档集中化管理项目（也或者是我没找到），因此花了点时间自己集成了一个，介绍如下。","text":"接口文档是前后端开发对接时很重要的一个组件。手动编写接口文档既费时，又存在文档不能随代码及时更新的问题，因此产生了像swagger这样的自动生成接口文档的框架。swagger文档一般是随项目代码生成与更新，访问地址也是基于项目地址，因此对项目数不多的团队还好。如果团队的项目很多，比如采用微服务架构的团队，动则几十甚至上百个服务项目，那就意味着前端开发人员需要记住几十甚至上百个swagger文档地址，那就很不友好了。目前貌似还没有较流行的API文档集中化管理项目（也或者是我没找到），因此花了点时间自己集成了一个，介绍如下。 1. swagger-bootstrap-ui项目该项目是github上的一个开源项目（https://github.com/xiaoymin/swagger-bootstrap-ui ），对swagger ui做了增强，功能整体看起来要丰富一些。来看看效果， 该项目的调试url地址原本是基于自身服务的，我将它改为了注册服务的url地址，以支持注册服务的接口调试。调整后的源码地址： https://github.com/ronwxy/swagger-bootstrap-ui 2. swagger api注册服务该项目集成了swagger-bootstrap-ui，并提供了swagger api注册接口，接受所有提供了有效配置的服务项目注册，让注册的服务在一个页面上可统一查看，再也不用记太多文档地址了。 启动注册服务后，访问 http://localhost:11090/doc.html 打开文档页面。如上图，可通过下拉列表来选择不同项目，加载项目的接口文档查看或调试。项目地址： https://github.com/ronwxy/swagger-register （如果觉得有用，不要吝啬你的star，反正又不要钱，O(∩_∩)O） 3. 服务端配置在业务服务端，需要提供一些配置。首先，需要配置一些Bean，如下提供了一个配置类（这里只列出了主要部分，完整代码参考： https://github.com/ronwxy/base-spring-boot）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class Swagger2AutoConfiguration &#123; @Bean public Docket restApi() &#123; ParameterBuilder builder = new ParameterBuilder(); builder.name(\"x-auth-token\").description(\"授权token\") .modelRef(new ModelRef(\"string\")) .parameterType(\"header\") .required(false); return new Docket(DocumentationType.SWAGGER_2) .groupName(groupName) .select() .apis(RequestHandlerSelectors.basePackage(apisBasePackage)) .paths(PathSelectors.any()) .build() .globalOperationParameters(Collections.singletonList(builder.build())) .apiInfo(apiInfo()); &#125; @Profile(&#123;\"dev\"&#125;) @Bean public CommandLineRunner swaggerRegistar(ConfigurableApplicationContext context) &#123; return new SwaggerInfoRegistar(context); &#125; /** * use to register swagger api info url to swagger api registry; * * @author liubo */ public class SwaggerInfoRegistar implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; String url = buildLocalSwaggerDocsUrl(); registerLocalSwaggerUrl(url); &#125; /** * register the v2/api-docs url * * @param url */ private void registerLocalSwaggerUrl(String url) &#123; RestTemplate restTemplate = new RestTemplate(); restTemplate.getMessageConverters().add(new FormHttpMessageConverter()); MultiValueMap&lt;String, Object&gt; body = new LinkedMultiValueMap&lt;&gt;(); body.add(\"project\", getApiTitle()); body.add(\"url\", url); ResponseEntity&lt;Map&gt; re = restTemplate.postForEntity(getSwaggerRegisterUrl(), body, Map.class); if (HttpStatus.OK.equals(re.getStatusCode())) &#123; logger.info(\"swagger api registered success to &#123;&#125;\", getSwaggerRegisterUrl()); &#125; else &#123; logger.warn(\"swagger api registered failed [&#123;&#125;]\", re.getBody().get(\"msg\")); &#125; &#125; &#125;&#125; 该类完成了swagger的基本配置，同时将swagger的/v2/api-docs地址注册到了步骤2中介绍的注册服务。 然后，因为要从注册服务端调用该业务服务的接口进行调试，存在跨域，因此服务需要做跨域支持，配置文件中添加如下定义， 1234567891011121314151617181920@Bean@ConditionalOnMissingBean(name = \"corsFilterRegistrationBean\")public FilterRegistrationBean corsFilterRegistrationBean() &#123; UrlBasedCorsConfigurationSource corsConfigurationSource = new UrlBasedCorsConfigurationSource(); CorsConfiguration corsConfiguration = new CorsConfiguration(); corsConfiguration.applyPermitDefaultValues(); corsConfiguration.setAllowedMethods(Arrays.asList(CorsConfiguration.ALL)); corsConfiguration.addExposedHeader(HttpHeaders.DATE); corsConfigurationSource.registerCorsConfiguration(\"/**\", corsConfiguration); CorsFilter corsFilter = new CorsFilter(corsConfigurationSource); FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); filterRegistrationBean.setFilter(corsFilter); filterRegistrationBean.setOrder(Ordered.HIGHEST_PRECEDENCE); filterRegistrationBean.addUrlPatterns(\"/*\"); return filterRegistrationBean;&#125; 最后，在属性配置文件application.yml中配置一些必要的属性，123456swagger: api-title: Demo标题 #会展示在下拉列表框中，一般写项目名称 api-description: Demo描述，集中注册 group-name: Demo项目 apis-base-package: cn.jboost.springboot.swagger # API类所在包名 swagger-registry-path: http://localhost:11090/swagger/register #就是2中注册服务的注册接口地址 配置完后， 就可以像一般项目一样编写接口类，加swagger注解。项目启动时， 会自动向注册服务完成注册，刷新注册服务的文档页面即可在下拉列表看到。 4. 总结本文介绍了一个基于swagger ui增强版项目swagger-bootstrap-ui的接口文档集中化管理实现。采用该实现，将所有swagger在线接口文档集中管理，有效提高前后端对接效率。 如果觉得本文有用，欢迎转发、推荐。 我的个人博客地址：http://blog.jboost.cn我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy （欢迎关注，及时获取技术干货分享）———————————————————————————————————————————————————————————————欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"高效实践","slug":"高效实践","permalink":"http://blog.jboost.cn/categories/高效实践/"}],"tags":[{"name":"swagger","slug":"swagger","permalink":"http://blog.jboost.cn/tags/swagger/"}]},{"title":"Spring Boot从入门到实战（八）：集成AOPLog来记录接口访问日志","slug":"springboot-aoplog","date":"2019-06-27T03:03:57.000Z","updated":"2019-07-22T10:30:15.221Z","comments":true,"path":"2019/06/27/springboot-aoplog.html","link":"","permalink":"http://blog.jboost.cn/2019/06/27/springboot-aoplog.html","excerpt":"日志是一个Web项目中必不可少的部分，借助它我们可以做许多事情，比如问题排查、访问统计、监控告警等。一般通过引入slf4j的一些实现框架来做日志功能，如log4j,logback,log4j2，其性能也是依次增强。在springboot中，默认使用的框架是logback。我们经常需要在方法开头或结尾加日志记录传入参数或返回结果，以此来复现当时的请求情况。但是手动添加日志，不仅繁琐重复，也影响代码的美观简洁。本文引入一个基于AOP实现的日志框架，并通过spring-boot-starter的方式完成集成。 原文地址：http://blog.jboost.cn/2019/06/27/springboot-aoplog.html","text":"日志是一个Web项目中必不可少的部分，借助它我们可以做许多事情，比如问题排查、访问统计、监控告警等。一般通过引入slf4j的一些实现框架来做日志功能，如log4j,logback,log4j2，其性能也是依次增强。在springboot中，默认使用的框架是logback。我们经常需要在方法开头或结尾加日志记录传入参数或返回结果，以此来复现当时的请求情况。但是手动添加日志，不仅繁琐重复，也影响代码的美观简洁。本文引入一个基于AOP实现的日志框架，并通过spring-boot-starter的方式完成集成。 原文地址：http://blog.jboost.cn/2019/06/27/springboot-aoplog.html 1. aop-logging项目项目地址： https://github.com/ronwxy/aop-logging该项目基于 https://github.com/nickvl/aop-logging.git ， 在其基础上添加了ReqId来串联某次客户端请求（参考com.github.nickvl.xspring.core.log.aop.ReqIdFilter）, 添加了方法执行时长（参考com.github.nickvl.xspring.core.log.aop.AOPLogger.logTheMethod方法中elapsedTime）。 该项目提供了基于注解的AOP日志功能。根据不同的日志级别，提供的注解有LogTrace,LogDebug,LogInfo,LogWarn,LogError,LogFatal,LogException，可修饰于类（等同于该类内所有方法上添加）与方法上，前面六个分别表示在不同日志级别下记录方法被调用的日志，LogException表示在方法抛出异常时，记录相应日志。这些注解都提供了一个LogPoint枚举类型的属性value，取值{IN,OUT,BOTH}，分别表示在方法调用入口、方法调用返回前，以及包含两者的位置打印对应日志，默认为BOTH。 2. 集成可以通过基于xml或基于java配置的方式来集成AOP日志功能，我这里基于java配置（基于xml的方式参考源码README文件）并且通过spring-boot-starter的形式进行封装（源码地址： https://github.com/ronwxy/base-spring-boot ），避免每个项目都需要配置。自动配置类如下12345678910111213141516171819202122232425262728293031@Configuration@ConditionalOnClass(AOPLogger.class)@ConditionalOnMissingBean(AOPLogger.class)public class AopLoggerAutoConfiguration &#123; private static final boolean SKIP_NULL_FIELDS = true; private static final Set&lt;String&gt; EXCLUDE_SECURE_FIELD_NAMES = Collections.emptySet(); @Bean public AOPLogger aopLogger() &#123; AOPLogger aopLogger = new AOPLogger(); aopLogger.setLogAdapter(new UniversalLogAdapter(SKIP_NULL_FIELDS, EXCLUDE_SECURE_FIELD_NAMES)); return aopLogger; &#125; /** * 注册一个过滤器，用来生成一个reqId，标记一次请求，从而将本次请求所产生的日志串联起来 * @param * @return */ @Bean public FilterRegistrationBean reqIdFilter() &#123; ReqIdFilter reqIdFilter = new ReqIdFilter(); FilterRegistrationBean registrationBean = new FilterRegistrationBean(); registrationBean.setFilter(reqIdFilter); List&lt;String&gt; urlPatterns = Collections.singletonList(\"/*\"); registrationBean.setUrlPatterns(urlPatterns); registrationBean.setOrder(100); return registrationBean; &#125;&#125; 将基础框架base-spring-boot通过mvn clean install进行本地安装后，即可在项目中通过依赖进行引入（基础框架中已在spring-boot-parent中引入，直接继承亦可），如12345&lt;dependency&gt; &lt;groupId&gt;cn.jboost.springboot&lt;/groupId&gt; &lt;artifactId&gt;aoplog-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 3. 使用引入依赖之后，我们再定义一个日志配置文件logback-spring.xml，为了后面方便地将日志导入ELK做集中的日志分析管理，该配置文件中将日志以json格式输出，并根据日志级别分别写入debug.log,info.log,warn.log,error.log以及interface.log（专用于接口访问日志），配置示例如下（完整配置参考： https://github.com/ronwxy/springboot-demos/blob/master/springboot-aoplog/src/main/resources/logback-spring.xml）1234567891011121314151617181920212223242526272829303132&lt;appender name=\"interfaceLog\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt;$&#123;logPath&#125;/elk/interface.log&lt;/file&gt; &lt;encoder class=\"net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder\"&gt; &lt;providers&gt; &lt;pattern&gt; &lt;pattern&gt; &#123; \"project\": \"$&#123;projectName&#125;\", \"timestamp\": \"%date&#123;\\\"yyyy-MM-dd'T'HH:mm:ss,SSSZ\\\"&#125;\", \"log_level\": \"%level\", \"thread\": \"%thread\", \"class_name\": \"%X&#123;callingClass&#125;\", \"class_method\":\"%X&#123;callingMethod&#125;\", \"line_number\": null, \"message\": \"%message\", \"stack_trace\": \"%exception&#123;5&#125;\", \"req_id\": \"%X&#123;reqId&#125;\", \"elapsed_time\": \"#asLong&#123;%X&#123;elapsedTime&#125;&#125;\" &#125; &lt;/pattern&gt; &lt;/pattern&gt; &lt;/providers&gt; &lt;/encoder&gt; &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;/filter&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;$&#123;logPath&#125;/bak/interface.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;totalSizeCap&gt;1GB&lt;/totalSizeCap&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; 为了将该日志配置文件可以不经修改地达到复用，将一些参数配置外置了，故需在配置文件applicaiton.yml中配置如下参数12345logger: path: D:\\logs #默认当前项目路径下的logs目录 level: info # 默认info apiPackage: cn.jboost.springboot.aoplog.controller #必须配置, api接口类所在包 rootPackage: cn.jboost.springboot #必须配置，项目根包，记录该包内各类通过slf4j输出的日志 最后，直接在需要记录访问日志的接口类上加注解@LogInfo就行了，如12345678910@RestController@RequestMapping(\"test\")@LogInfopublic class AoplogTestController &#123; @GetMapping public String test(@RequestParam String user)&#123; return \"Hi \" + user; &#125;&#125; 注意：在pom.xml中默认添加的spring-boot-maven-plugin下需要添加repackage的goal才能自动生成日志目录与日志文件，如下所示 123456789101112131415&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 启动程序，调用@LogInfo标注的接口类下的API时，可以看到控制台有打印接口访问日志，如执行demo程序（源码： https://github.com/ronwxy/springboot-demos/tree/master/springboot-aoplog ），调用 http://localhost:8080/test?user=jboost 时，控制台打印日志如下12[2019-06-27 14:29:59] [INFO ] [http-nio-8080-exec-1] [cn.jboost.springboot.aoplog.controller.AoplogTestController:184] --calling: test(user=jboost)[2019-06-27 14:29:59] [INFO ] [http-nio-8080-exec-1] [cn.jboost.springboot.aoplog.controller.AoplogTestController:189] --returning: test(1 arguments):Hi jboost 日志文件interface.log中打印日志如下，（其中req_id在本次请求的所有日志都相同，这样就可以将一次请求的所有日志串联起来，便于分析与定位问题；elapsed_time标明了方法执行时长，可用于接口性能监测）12&#123;\"project\":\"aoplog-test\",\"timestamp\":\"2019-06-27T14:29:59,030+0800\",\"log_level\":\"INFO\",\"thread\":\"http-nio-8080-exec-1\",\"class_name\":\"cn.jboost.springboot.aoplog.controller.AoplogTestController\",\"class_method\":\"test\",\"line_number\":null,\"message\":\"calling: test(user=jboost)\",\"stack_trace\":\"\",\"req_id\":\"5d146267aa147904bc014e71\",\"elapsed_time\":null&#125;&#123;\"project\":\"aoplog-test\",\"timestamp\":\"2019-06-27T14:29:59,036+0800\",\"log_level\":\"INFO\",\"thread\":\"http-nio-8080-exec-1\",\"class_name\":\"cn.jboost.springboot.aoplog.controller.AoplogTestController\",\"class_method\":\"test\",\"line_number\":null,\"message\":\"returning: test(1 arguments):Hi jboost\",\"stack_trace\":\"\",\"req_id\":\"5d146267aa147904bc014e71\",\"elapsed_time\":2&#125; 4. 总结Web项目中经常需要通过查看接口请求及返回参数来定位问题，手动编写代码打印显得繁琐而重复。使用aop-logging通过简单的注解即可实现接口日志自动打印。本文介绍的方案与日志配置模板可直接用于实际项目开发。当然，注解不仅可用于Controller层，也可以用于Service等其它层，但一般Controller层加上即可，避免日志打印过多。 本文示例项目源码地址：https://github.com/ronwxy/springboot-demos/tree/master/springboot-aoplog我的个人博客地址：http://blog.jboost.cn我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy （欢迎关注，及时获取技术干货分享）—————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"},{"name":"logback","slug":"logback","permalink":"http://blog.jboost.cn/tags/logback/"}]},{"title":"案例解析：springboot自动配置未生效问题定位（条件断点）","slug":"issue-conditiontrack","date":"2019-06-25T13:33:00.000Z","updated":"2019-07-09T11:19:28.488Z","comments":true,"path":"2019/06/25/issue-conditiontrack.html","link":"","permalink":"http://blog.jboost.cn/2019/06/25/issue-conditiontrack.html","excerpt":"Spring Boot在为开发人员提供更高层次的封装，进而提高开发效率的同时，也为出现问题时如何进行定位带来了一定复杂性与难度。但Spring Boot同时又提供了一些诊断工具来辅助开发与分析，如spring-boot-starter-actuator。本文分享一个基于actuator与IDEA条件断点来定位自动配置未生效的案例。望对类似问题分析与处理提供参考。","text":"Spring Boot在为开发人员提供更高层次的封装，进而提高开发效率的同时，也为出现问题时如何进行定位带来了一定复杂性与难度。但Spring Boot同时又提供了一些诊断工具来辅助开发与分析，如spring-boot-starter-actuator。本文分享一个基于actuator与IDEA条件断点来定位自动配置未生效的案例。望对类似问题分析与处理提供参考。 问题确认在前文介绍的 Spring Boot从入门到实战：整合通用Mapper简化单表操作 中，我们对druid连接池做了自动配置，并且注入了druid的监控统计功能，如下 但本地运行后通过 http://localhost:8080/druid/index.html 访问时却出现错误，通过浏览器的开发者工具查看该请求返回404，推测上述代码中定义的StatViewServlet未注入成功。我们用actuator来确认下是否如此。在项目中加入spring-boot-starter-actuator，并且application.yml中添加如下配置123456789management: endpoints: web: exposure: include: \"*\" exclude: beans,trace endpoint: health: show-details: always 在spring-boot 2.x 版本当中，作为安全性考虑，将actuator 控件中的端口，只默认开放/health 和/info 两个端口，其他端口默认关闭， 因此需要添加如上配置。注意include的值 * 必须加引号，否则无法启动。 重启程序后访问 http://localhost:8080/actuator/conditions 确认上述两个实例化方法未满足@ConditionalOnProperty的条件，从而未执行生效，如图 条件断点从上面分析确认是因为条件注解 @ConditionalOnProperty(prefix = &quot;spring.datasource.druid&quot;, name = &quot;druidServletSettings&quot;) 未满足使方法未执行导致。那这个条件为什么没有满足呢，查看application.yml中也做了 spring.datasource.druid.druidServletSettings属性的配置。 当你无法理清头绪，确定问题原因时，那就Debug吧。查看注解@ConditionalOnProperty源码，找到其实现支持类OnPropertyCondition，如下123456789101112131415@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Documented@Conditional(&#123;OnPropertyCondition.class&#125;)public @interface ConditionalOnProperty &#123; String[] value() default &#123;&#125;; String prefix() default \"\"; String[] name() default &#123;&#125;; String havingValue() default \"\"; boolean matchIfMissing() default false;&#125; 查看OnPropertyCondition源码，了解它是通过getMatchOutcome方法来判断是否满足注解参数所指定的条件的，如下所示123456789101112131415161718@Overridepublic ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; List&lt;AnnotationAttributes&gt; allAnnotationAttributes = annotationAttributesFromMultiValueMap( metadata.getAllAnnotationAttributes( ConditionalOnProperty.class.getName())); List&lt;ConditionMessage&gt; noMatch = new ArrayList&lt;&gt;(); List&lt;ConditionMessage&gt; match = new ArrayList&lt;&gt;(); for (AnnotationAttributes annotationAttributes : allAnnotationAttributes) &#123; ConditionOutcome outcome = determineOutcome(annotationAttributes, context.getEnvironment()); (outcome.isMatch() ? match : noMatch).add(outcome.getConditionMessage()); &#125; if (!noMatch.isEmpty()) &#123; return ConditionOutcome.noMatch(ConditionMessage.of(noMatch)); &#125; return ConditionOutcome.match(ConditionMessage.of(match));&#125; 在调用determineOutcome处打断点，调试什么原因导致条件未满足，但是这里是一个for循环，如果for元素过多的话，将可能需要断点阻断很多次才能找到你想要查看的那个元素。所幸IDEA提供了不同类型的断点来处理这类问题，前面 案例解析：使用IDEA异常断点来定位java.lang.ArrayStoreException的问题 我们介绍了异常断点的使用。这里介绍用条件断点来处理这类循环块中的debug问题。 在上述代码for循环中调用determineOutcome行打断点，并在断点上右键，弹出如下窗口 图中Condition框即可输入你要指定的条件，可以直接写java判断表达式代码，并引用该行代码处能访问的变量，如这里我们输入 annotationAttributes.get(&quot;name&quot;).equals(&quot;druidServletSettings&quot;)，然后点击Debug窗口的“Resume Program (F9)”按钮，则在不满足指定条件时，断点处将不会被阻断，直到条件满足，这样就能很容易定位到我们想要查看的元素。（当然这里allAnnotationAttributes变量其实只有一个元素，仅仅是为了演示条件变量的使用，当集合元素很多时，使用条件断点就能体会到它的方便之处） 问题定位通过Debug的方式深入条件注解的判断逻辑（其中循环处可使用条件断点），最终来到如下代码片段 在这里是判断来自所有属性源配置的属性中，是否包含条件注解指定的属性，即spring.datasource.druid.druidServletSettings，由上图可见，spring.datasource.druid.druidServletSettings只是某些属性的前缀，并不存在完全匹配的属性，因此返回false，导致条件不满足。回看注解@ConditionOnProperty的javadoc，123456789* If the property is not contained in the &#123;@link Environment&#125; at all, the * &#123;@link #matchIfMissing()&#125; attribute is consulted. By default missing attributes do not * match. * &lt;p&gt; * This condition cannot be reliably used for matching collection properties. For example, * in the following configuration, the condition matches if &#123;@code spring.example.values&#125; * is present in the &#123;@link Environment&#125; but does not match if * &#123;@code spring.example.values[0]&#125; is present. * 当Environment中不包含该属性时，则看matchIfMissing的值，该值默认为false，如果包含该属性，则再对比属性值与havingValue的值，相等即满足，不等则不满足。并且该条件注解不能用于匹配集合类型属性。上述spring.datasource.druid.druidServletSettings实际上属于一个Map类型，因此不能想当然地认为该注解是只要属性集中某属性名称包含该值即满足。 总结当难以定位到问题原因时，可以进行Debug，跟踪程序运行的各个步骤，当要在循环中Debug定位到某个元素时，可以用条件断点来实现。@ConditionalOnProperty注解不是存在某属性就行，还需要值相等，并且不适用于集合类型属性。我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ——————————————————————————————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"案例解析","slug":"案例解析","permalink":"http://blog.jboost.cn/categories/案例解析/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"}]},{"title":"Spring Boot从入门到实战（七）：整合通用Mapper简化单表操作","slug":"springboot-tkmapper","date":"2019-06-24T11:32:15.000Z","updated":"2019-07-22T10:30:03.487Z","comments":true,"path":"2019/06/24/springboot-tkmapper.html","link":"","permalink":"http://blog.jboost.cn/2019/06/24/springboot-tkmapper.html","excerpt":"数据库访问是web应用必不可少的部分。现今最常用的数据库ORM框架有Hibernate与Mybatis，Hibernate貌似在传统IT企业用的较多，而Mybatis则在互联网企业应用较多。通用Mapper（https://github.com/abel533/Mapper） 是一个基于Mybatis，将单表的增删改查通过通用方法实现，来减少SQL编写的开源框架，且也有对应开源的mapper-spring-boot-starter提供。我们在此基础上加了一些定制化的内容，以便达到更大程度的复用。","text":"数据库访问是web应用必不可少的部分。现今最常用的数据库ORM框架有Hibernate与Mybatis，Hibernate貌似在传统IT企业用的较多，而Mybatis则在互联网企业应用较多。通用Mapper（https://github.com/abel533/Mapper） 是一个基于Mybatis，将单表的增删改查通过通用方法实现，来减少SQL编写的开源框架，且也有对应开源的mapper-spring-boot-starter提供。我们在此基础上加了一些定制化的内容，以便达到更大程度的复用。 框架源码地址：https://github.com/ronwxy/base-spring-boot （持续更新完善中，欢迎follow，star）Demo源码地址：https://github.com/ronwxy/springboot-demos/tree/master/springboot-tkmapper 在开源mapper-spring-boot-starter的基础上，增加了如下内容： 针对MySQL数据库与PostgreSQL数据库添加了一些Java类型与数据库类型的转换处理类，如将List、Map类型与MySQL数据库的json类型进行转换处理 对Domain、Mapper、Service、Controller各层进行了封装，将基本的增删改查功能在各层通用化 提供了基于druid连接池的自动配置 其它一些调整，如默认映射复杂类型属性（主要是List、Map类型，其它自定义类型需要自定义转换处理类），将枚举作为简单类型处理 提供了一个parent项目，将一些常用的框架进行集成，实际项目可继承parent简化依赖配置（持续更新完善） 该框架可用于实际基于springboot的项目，只需简单配置数据源，即可引入druid连接池及通用mapper的功能，以及各层基本的增删改查方法。 如何使用？下文给出使用步骤，可参考示例：https://github.com/ronwxy/springboot-demos/tree/master/springboot-tkmapper 1. 框架Maven部署安装下载框架源码后，在项目根路径下执行mvn clean install可安装到本地maven库。如果需要共享，且搭了Nexus私服，则在根路径pom.xml文件中添加distributionManagement配置，指定Nexus仓库分发地址，使用mvn clean deploy安装到远程maven仓库，如1234567891011121314&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;url&gt; http://ip:port/repository/maven-releases/ &lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;url&gt; http://ip:port/repository/maven-snapshots/ &lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; 上述指定的repository需要在maven的全部配置文件settings.xml中有对应账号配置(id需要一一对应)，如 123456789101112 &lt;servers&gt; &lt;server&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;xxx&lt;/password&gt; &lt;/server&gt;&lt;server&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;xxx&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; 2. pom.xml配置项目中引入该数据库框架有三种方式： 直接引入 cn.jboost.springboot:tkmapper-spring-boot-starter（没有连接池） 直接引入 cn.jboost.springboot:druid-spring-boot-starter（druid连接池支持） 项目继承 cn.jboost.springboot:spring-boot-parent（使用的是druid连接池） 三种方式的pom.xml配置如下 123456789101112131415161718192021#第一种方式&lt;dependency&gt; &lt;groupId&gt;cn.jboost.springboot&lt;/groupId&gt; &lt;artifactId&gt;tkmapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;#第二种方式&lt;dependency&gt; &lt;groupId&gt;cn.jboost.springboot&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;#第三种方式&lt;parent&gt; &lt;groupId&gt;cn.jboost.springboot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-parent&lt;/artifactId&gt; &lt;version&gt;1.2-SNAPSHOT&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt; 根据情况引入mysql或postgresql的驱动依赖（其它数据库暂未做类型转换支持，未作测试） 3. 配置数据源如果使用druid连接池，则在application.yml配置文件中，加入如下数据源配置（推荐）12345678910111213141516171819202122232425262728293031spring: datasource: druid: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/test?autoReconnect=true&amp;useUnicode=true&amp;characterEncoding=utf-8 username: root password: # 自定义配置 initialSize: 2 # 初始化大小 minIdle: 1 # 最小连接 maxActive: 5 # 最大连接 druidServletSettings: allow: 127.0.0.1 deny: loginUsername: admin loginPassword: Passw0rd resetEnable: true druidFilterSettings: exclusions: '*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*' maxWait: 60000 # 配置获取连接等待超时的时间 timeBetweenEvictionRunsMillis: 60000 # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 minEvictableIdleTimeMillis: 300000 # 配置一个连接在池中最小生存的时间，单位是毫秒 validationQuery: SELECT 'x' testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true # 打开PSCache，并且指定每个连接上PSCache的大小 maxPoolPreparedStatementPerConnectionSize: 20 filters: stat #,wall（添加wall代码里不能直接拼接sql，druid有sql注入校验） # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙 connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 # 通过connectProperties属性来打开mergeSql功能；慢SQL记录 useGlobalDataSourceStat: true # 合并多个DruidDataSource的监控数据 如果不使用连接池，则配置相对简单，如下123456spring: datasource: url: jdbc:mysql://localhost:3306/test?autoReconnect=true&amp;useUnicode=true&amp;characterEncoding=utf-8 username: root password: driver-class-name: com.mysql.jdbc.Driver 4. 定义相应domain，mapper，service，controller各层对象以demo为例（demo数据库脚本见resources/schema.sql），domain定义一个User类,12345678910111213141516@Table(name = \"user\")@Getter@Setter@ToStringpublic class User extends AutoIncrementKeyBaseDomain&lt;Integer&gt; &#123; private String name; @ColumnType(jdbcType = JdbcType.CHAR) private Gender gender; private List&lt;String&gt; favor; private Map&lt;String, String&gt; address; public enum Gender&#123; M, F &#125;&#125; 需要添加@Table注解指定数据库表名，可通过继承AutoIncrementKeyBaseDomain来实现自增主键，或UUIDKeyBaseDomain来实现UUID主键，如果自定义其它类型主键，则继承BaseDomain。 该框架Service层通用方法实现BaseService只支持单列主键，不支持组合主键（也不建议使用组合主键） 框架默认对List、Map等复杂类型属性会映射到mysql的json类型或postgresql的jsonb类型，如果某个属性不需要映射，可添加@Transient注解；枚举类型需添加@ColumnType指定jdbcType。 dao层定义UserMapper，123@Repositorypublic interface UserMapper extends BaseMapper&lt;User&gt; &#123;&#125; BaseMapper默认实现了单表的增删改查及批量插入等功能，如需定义复杂查询，可在该接口中定义，然后通过mapper xml文件编写实现。 service层定义 UserService，继承了BaseService的通用功能（具体可查看源码），同样可在该类中自定义方法12345678910@Servicepublic class UserService extends BaseService&lt;Integer, User&gt; &#123; @Transactional public void createWithTransaction(User user)&#123; create(user); //用于测试事务 throw new RuntimeException(\"抛出异常，让前面的数据库操作回滚\"); &#125;&#125; controller层定义 UserController，继承了BaseController的通用接口（具体可查看源码）1234@RestController@RequestMapping(\"/user\")public class UserController extends BaseController&lt;Integer, User&gt; &#123;&#125; 如上，只需要定义各层对应的接口或类，继承基础接口或类，便完成了用户基本的增删改查功能，不需要写一行具体的实现代码。 5. 测试、运行 示例中提供了两个新建用户的单元测试，参考SpringbootTkmapperApplicationTests类 运行，在主类上直接运行，然后浏览器里打开 http://localhost:8080/user 则可列出单元测试中创建的用户（其它接口参考BaseController实现） 6. 总结本文介绍框架基于tk.mybatis:mapper-spring-boot-starter做了一些自定义扩展，以更大程度地实现复用。可用于实际项目开发，使用过程中如果遇到问题，可关注公众号留言反馈。我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ———————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"案例解析：使用IDEA异常断点来定位java.lang.ArrayStoreException的问题","slug":"issue-errortrack","date":"2019-06-21T10:31:03.000Z","updated":"2019-07-09T11:19:28.656Z","comments":true,"path":"2019/06/21/issue-errortrack.html","link":"","permalink":"http://blog.jboost.cn/2019/06/21/issue-errortrack.html","excerpt":"最近对 base-spring-boot （https://github.com/ronwxy/base-spring-boot） 项目进行了升级。在将其用于应用开发中时遇到java.lang.ArrayStoreException的异常导致程序无法启动。平常开发过程中面对这种描述不够清楚，无法定位具体原因的问题该如何处理？本文分享通过使用IDEA异常断点来定位此类问题的方法。","text":"最近对 base-spring-boot （https://github.com/ronwxy/base-spring-boot） 项目进行了升级。在将其用于应用开发中时遇到java.lang.ArrayStoreException的异常导致程序无法启动。平常开发过程中面对这种描述不够清楚，无法定位具体原因的问题该如何处理？本文分享通过使用IDEA异常断点来定位此类问题的方法。 启动程序时抛出如下异常，导致启动失败 12345678910111213141516171819202122232425org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;devGlobalExceptionHandler&apos; defined in class path resource [cn/jboost/springboot/autoconfig/error/exception/ExceptionHandlerAutoConfiguration.class]: Post-processing of merged bean definition failed; nested exception is java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:570) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:843) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) ~[spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) [spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) [spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) [spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) [spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) [spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE] at com.cnbot.kindergarten.CnbotKindergartenApplication.main(CnbotKindergartenApplication.java:10) [classes/:na]Caused by: java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy at sun.reflect.annotation.AnnotationParser.parseClassArray(AnnotationParser.java:724) ~[na:1.8.0_201] at sun.reflect.annotation.AnnotationParser.parseArray(AnnotationParser.java:531) ~[na:1.8.0_201] at sun.reflect.annotation.AnnotationParser.parseMemberValue(AnnotationParser.java:355) ~[na:1.8.0_201] at sun.reflect.annotation.AnnotationParser.parseAnnotation2(AnnotationParser.java:286) ~[na:1.8.0_201] at sun.reflect.annotation.AnnotationParser.parseAnnotations2(AnnotationParser.java:120) ~[na:1.8.0_201] at sun.reflect.annotation.AnnotationParser.parseAnnotations(AnnotationParser.java:72) ~[na:1.8.0_201] ... 单纯看异常栈，无法定位问题原因，只能看到是在调用devGlobalExceptionHandler创建bean时出错，错误信息java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy。这属于框架内部抛出的异常，通常的设置断点Debug的方法很难定位到具体原因，可通过IDEA的异常断点来进行定位，它会在程序运行过程中出现指定异常时进行阻断。 1. 添加异常断点在IDEA的Debug面板中，点击“View Breakpoints”（两个重叠的红色圈按钮），如下 打开“Breakpoints”窗口，在该窗口中点击“+”按钮，选择“Java Exception Breakpoints”， 如下图 然后在弹出的“Enter Exception Class”窗口中输入ArrayStoreException选中对应异常，依次点击OK，Done按钮即完成异常断点添加。 2. 程序debug开始以Debug模式启动程序。 程序运行后，在前面配置的异常出现时，将会进行阻断，如图 可以看到程序阻断在上图高亮的那行代码处，异常便是从这里抛出的。查看parseClassValue方法，可看到这里有catchTypeNotPresentException异常，并且包装成我们在异常栈看到的TypeNotPresentExceptionProxy返回。离真相很近了。 我们可以在上述catch块中添加一个断点，查看异常包装前的状态，如图 重新Debug运行，将定位到上图代码处，查看异常，看到如下图所示信息 该信息表示org.springframework.security.access.AccessDeniedException这个类不存在，导致BaseWebApplicationExceptionHandler类型的bean实例化时出错。这时候问题基本已经定位到了。 查看源码，在BaseWebApplicationExceptionHandler中有对AccessDeniedException的统一处理，但是spring-boot-autoconfigure所有的依赖都是optional的（不会传递依赖），而在新开发的项目中，并没有引入spring-security，因此导致AccessDeniedException这个类找不到而报错。目前通过去掉该部分处理解决。 总结IDEA的Debug支持好几种断点类型，如前文介绍的异常断点，以及比较常用的条件断点等。当无法从异常栈信息找到问题所在时，借用这些类型的断点进行Debug，往往事情就变得简单了。 我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ———————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"案例解析","slug":"案例解析","permalink":"http://blog.jboost.cn/categories/案例解析/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"}]},{"title":"Spring Boot从入门到实战（六）：整合Web项目常用功能","slug":"springboot-base","date":"2019-06-20T14:17:22.000Z","updated":"2019-07-22T10:29:50.279Z","comments":true,"path":"2019/06/20/springboot-base.html","link":"","permalink":"http://blog.jboost.cn/2019/06/20/springboot-base.html","excerpt":"在Web应用开发过程中，一般都涵盖一些常用功能的实现，如数据库访问、异常处理、消息队列、缓存服务、OSS服务，以及接口日志配置，接口文档生成等。如果每个项目都来一套，则既费力又难以维护。可以通过Spring Boot的Starter来将这些常用功能进行整合与集中维护，以达到开箱即用的目的。","text":"在Web应用开发过程中，一般都涵盖一些常用功能的实现，如数据库访问、异常处理、消息队列、缓存服务、OSS服务，以及接口日志配置，接口文档生成等。如果每个项目都来一套，则既费力又难以维护。可以通过Spring Boot的Starter来将这些常用功能进行整合与集中维护，以达到开箱即用的目的。 项目基于Spring Boot 2.1.5.RELEASE 版。项目地址： https://github.com/ronwxy/base-spring-boot 整个项目分为如下几部分： spring-boot-autoconfigure： 具体的各功能实现，每个功能通过package的形式组织 spring-boot-commons： 一些公共的工具类或共享类 spring-boot-dependencies： 依赖的集中维护管理，集中管理各个依赖的版本号 spring-boot-parent： 提供一个基本的父项目，web服务项目可通过继承该项目创建 spring-boot-starters： 各功能的starter项目，引入相应starter即引入相应功能 spring-boot-dependencies 项目该项目主要是对所有依赖进行集中定义。通过 dependencyManagement 对依赖进行声明， 12345678910111213141516171819&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-boot.version&#125;&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.jboost.springboot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;base-spring-boot.version&#125;&lt;/version&gt; &lt;/dependency&gt; ... &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 这样，所有依赖的版本可以集中统一管理，在其它地方引用的时候可以省去版本的声明，如 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; spring-boot-autoconfigure 项目该项目是各功能自动配置的具体实现，以package的形式进行组织，如 tkmapper 包下实现了通用Mapper的自动配置，error 包下实现了错误处理的自动配置， 等等。 该项目继承了spring-boot-dependencies， 在项目的 pom.xml 中，依赖部分声明类似于 1234567891011121314&lt;dependencies&gt; &lt;!-- spring denpendencies --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; ...&lt;/dependencies&gt; 不需要再指定版本号，通过将optional设置为true，表示该依赖不会进行传递，即另外一个项目引用该项目时，optional的依赖不会被传递依赖过去。 在 resources/META-INF/spring.factories 文件中，声明了所有自动配置类， 如下 1234567891011org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\cn.jboost.springboot.autoconfig.tkmapper.MapperAutoConfiguration,\\cn.jboost.springboot.autoconfig.aoplog.AopLoggerAutoConfiguration,\\cn.jboost.springboot.autoconfig.alimq.config.AliMQAutoConfiguration,\\cn.jboost.springboot.autoconfig.qiniu.QiniuAutoConfiguration,\\cn.jboost.springboot.autoconfig.swagger.Swagger2AutoConfiguration,\\cn.jboost.springboot.autoconfig.druid.DruidAutoConfiguration,\\cn.jboost.springboot.autoconfig.error.exception.ExceptionHandlerAutoConfiguration,\\cn.jboost.springboot.autoconfig.alimns.MnsAutoConfiguration,\\cn.jboost.springboot.autoconfig.redis.RedisClientAutoConfiguration,\\cn.jboost.springboot.autoconfig.web.CORSAutoConfiguration spring-boot-starters 项目该项目包含按功能划分的多个子项目，主要用来引入依赖以达到自动配置的依赖条件，使引入对应starter时，能让自动配置生效。如通用Mapper集成的 tkmapper-spring-boot-starter 依赖如下 123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 同时在 resources/META-INF/spring.provides 里声明了该starter的用途，这里可随意编写。 spring-boot-commons 项目可将一些常用的工具类， 或共享类放到这个项目中。比如一些常量定义，加解密工具类等。 spring-boot-parent 项目该项目将Web应用需要的一些常见功能整合进来，应用项目可继承该项目进行构建，从而直接引入相应的功能。 在接下来的spring boot系列博文中，将一一详细介绍各功能的整合集成与应用。同时会不断更新与完善，以达到能直接用于生产项目的水平。 我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ——————————————————————————————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"研发团队如何借助Gitlab来做代码review","slug":"code-review","date":"2019-06-18T12:03:21.000Z","updated":"2019-07-09T11:19:28.710Z","comments":true,"path":"2019/06/18/code-review.html","link":"","permalink":"http://blog.jboost.cn/2019/06/18/code-review.html","excerpt":"代码review是代码质量保障的手段之一，同时开发成员之间代码review也是一种技术交流的方式，虽然会占用一些时间，但对团队而言，总体是个利大于弊的事情。如何借助现有工具在团队内部形成代码review的流程与规范，是team leader或技术管理者需要考虑的问题。本文分享一种基于Gitlab代码merge流程的code review方法，以供参考与探讨。如有更好的方法，欢迎交流。","text":"代码review是代码质量保障的手段之一，同时开发成员之间代码review也是一种技术交流的方式，虽然会占用一些时间，但对团队而言，总体是个利大于弊的事情。如何借助现有工具在团队内部形成代码review的流程与规范，是team leader或技术管理者需要考虑的问题。本文分享一种基于Gitlab代码merge流程的code review方法，以供参考与探讨。如有更好的方法，欢迎交流。 1. 设置成员角色首先需要对你团队的成员分配角色，在Gitlab groups里选择一个group，然后左边菜单栏点击 Members，可在 Members 页面添加或编辑成员角色，如下图所示。 其中角色包含如下几类： Guest：权限最小，基本查看功能 Reporter：只能查看，不能push Developer：能push，也能merge不受限制的分支 Master：除了项目的迁移、删除等管理权限没有，其它权限基本都有 Owner：权限最大，包括项目的迁移、删除等管理权限 详细权限参考： https://docs.gitlab.com/ee/user/permissions.html 确定团队中技术水平、经验较好的成员为Master，负责代码的review与分支的合并；其他成员为Developer，提交合并请求，接受review意见；Master之间可以互相review。 2. 配置分支保护在项目页面左侧菜单栏 Settings -&gt; Repository， 进入“Protected Branches”部分配置分支保护，如下图所示。 在这里可以针对每个分支，设置允许什么角色可以merge，允许什么角色可以push，选项包括三个：“Masters”， “Developers + Masters”， “No one”。这里设置成只允许master可以直接push与merge这几个常设分支的代码。（如果更严格一点，可以将“Allowed to push”设置成“No one”） 3. 代码review流程3.1. 开发（开发者负责） 本地切到develop分支， 拉取最新代码（相关命令如下，GUI工具操作自行查相关文档） 123git branch #查看当前位于哪个分支，前面打星号即为当前分支git checkout develop #切换到develop分支git pull #拉取最新代码 从develop分支切出子分支 1git checkout -b feature-1101 #从当前分支切出子分支，命名为\"feature-1101\" 编码、本地自测完之后，提交子分支到远程仓库 123git add * #加入暂存区git commit -m \"commit msg\" #提交到本地仓库git push origin feature-1101 #提交到远程仓库 3.2 发起Merge请求（开发者负责） 在项目主页面，依次点击左侧“Merge Requests”（下图1），“New merge request”（下图2），打开新建Merge请求页面 在新建Merge请求页面，选择merge的源分支，及目标分支，如下图源分支为“feature-1101”，目标分支为“develop”，点击“Compare branches and continue”按钮进入对比与提交页面 在对比与提交页面，可以点击“Changes” tab查看本次修改（这里我为了演示，只是加了两个换行），确认无误，点击“Submit merge request”按钮，提交merge请求 提交之后，将结果页面的浏览器地址发到团队即时通讯群（如钉钉），并@相应的同事申请review 3.3 代码Review（code reviewer负责） 负责代码Review的同事收到申请后，点击merge请求地址，打开页面，查看“Changes” 这里可通过“Inline”单边查看，也可以通过“Side-by-side”两个版本对比查看 review完成后，若无问题，则可点击”Merge”按钮完成merge，同时可删除对应的子分支“feature-1101”，若有问题，则可点击“Close merge request”按钮关闭该merge请求（也可以不关闭复用该merge请求），同时通知开发者进行相应调整，重新提交代码发起merge请求（如果之前没关闭merge请求，则刷新即可看到调整）。 3.4 冲突解决（开发者负责） merge的时候，可能存在代码冲突，这时，开发者可从develop分支重新拉取最新代码进行本地merge， 解决冲突后重新提交代码进行review 12345678git pull origin develop #在当前子分支拉取develop分支的最新代码进行本地merge# 解决冲突代码# 提交git add *git commit -m \"fix merge conflict\"git push origin feature-1101 自行解决不了时，寻求协助 4. 借助阿里钉钉机器人来改善体验前面流程中提醒code reviewer是需要开发者自己来发消息通知的，可不可以把这个流程自动化。我们可以借助Gitlab的webhook与钉钉机器人来实现。 在钉钉群右上角点击“…”，打开群设置，群机器人中点击添加机器人，会显示可以添加的机器人类型，如下图所示 选择Gitlab，点击添加，输入机器人名称，如“Gitlab”，点击完成即创建了一个Gitlab的钉钉机器人。回到“群机器人”窗口，将能看到刚刚创建的Gitlab机器人，如图 点击齿轮按钮，进入设置页，可看到webhook地址，点击复制，复制该机器人的webhook地址。如图 在Gitlab项目主页进入 Settings -&gt; Integrations， 将前面复制的webhook地址填入URL中，Trigger 部分选择“Merge request events”（不要勾太多，不然提醒太多就有点骚扰了），然后点击“Add webhook”就完成了。如图 当有开发人员提交merge请求时，钉钉机器人将在钉钉群里发出通知，code reviewer点击消息里的链接即可进入页面进行code review， review完成，将分支merge之后，钉钉机器人也会发出消息（所有merge相关的事件都会发出消息）。如图 5. 总结团队协作，流程、规范很重要，不同的团队可能有不同的适用流程与规范。此文分享了基于Gitlab与阿里钉钉群机器人的代码review流程，希望对团队研发协作有一定参考价值，也欢迎一起探讨、交流。 我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ———————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"teamwork","slug":"teamwork","permalink":"http://blog.jboost.cn/categories/teamwork/"}],"tags":[{"name":"git","slug":"git","permalink":"http://blog.jboost.cn/tags/git/"}]},{"title":"团队项目的Git分支如何管理","slug":"git-branch","date":"2019-06-17T05:28:19.000Z","updated":"2019-07-09T11:19:28.488Z","comments":true,"path":"2019/06/17/git-branch.html","link":"","permalink":"http://blog.jboost.cn/2019/06/17/git-branch.html","excerpt":"许多公司的开发团队都采用Git来做代码版本控制。如何有效地协同开发人员之间，以及开发、测试、上线各环节的工作，可能都有各自的流程与规范。本文分享的是作者一直沿用的团队项目Git分支管理规范，希望给有缘阅读的人以参考，如果有更好的实践，也欢迎指教、讨论。","text":"许多公司的开发团队都采用Git来做代码版本控制。如何有效地协同开发人员之间，以及开发、测试、上线各环节的工作，可能都有各自的流程与规范。本文分享的是作者一直沿用的团队项目Git分支管理规范，希望给有缘阅读的人以参考，如果有更好的实践，也欢迎指教、讨论。 分支管理创建项目时（一般是服务型项目，工具型或辅助型项目可以简单一些），会针对不同环境创建三个常设分支： develop：开发环境的稳定分支，公共开发环境基于该分支构建。 pre-release：测试环境的稳定分支，测试环境基于该分支构建。 master：生产环境的稳定分支，生产环境基于该分支构建。仅用来发布新版本，除了从pre-release或生产环境Bug修复分支进行merge，不接受任何其它修改 平时开发工作中，会根据需要由开发人员创建两类临时分支： 功能（feature）分支：为了开发某个特定功能，从develop分支上面分出来的。开发完成后，要merge到develop分支。功能分支的命名，可以采用feature-*的形式命名(*为任务单号) Bug修复（fixbug）分支：为了修复某个bug，从常设分支上面分出来的。修复完成后，再merge到对应的分支。Bug修复分支的命名，可以采用fixbug-*的形式命名（*为bug单号） 流程规范正常开发流程 从develop分支切出一个新分支，根据是功能还是bug，命名为feature-* 或 fixbug-*。 开发者完成开发，提交分支到远程仓库。 开发者发起merge请求（可在gitlab页面“New merge request”），将新分支请求merge到develop分支，并提醒code reviewer进行review code reviewer对代码review之后，若无问题，则接受merge请求，新分支merge到develop分支，同时可删除新建分支；若有问题，则不能进行merge，可close该请求，同时通知开发者在新分支上进行相应调整。调整完后提交代码重复review流程。 转测时，直接从当前develop分支merge到pre-release分支，重新构建测试环境完成转测。 测试完成后，从pre-release分支merge到master分支，基于master分支构建生产环境完成上线。并对master分支打tag，tag名可为v1.0.0_2019032115（即版本号_上线时间） 流程示意图如下所示 并行开发测试环境Bug修复流程并行开发（即前一个版本已经转测但未上线，后一个版本又已在开发中并部分合并到了develop分支）过程中，转测后测试环境发现的bug需要修复，但是develop分支此时又有新内容且该部分内容目前不计划转测，可以pre-release切出一个bug修复分支。完成之后需要同时merge到pre-release分支与develop分支。merge时参考“正常开发流程”。流程示意图如下 生产环境Bug修复流程生产环境的Bug分两种情况： 紧急Bug：严重影响用户使用的为紧急Bug，需立即进行修复。如关键业务流程存在问题，影响用户正常的业务行为。 非紧急Bug或优化：非关键业务流程问题，仅影响用户使用体验，或出现频率较小等，为非紧急Bug，可规划到后续版本进行修复。 非紧急Bug修复参考“正常开发流程”。 紧急Bug修复，需要从master分支切出一个bug修复分支，完成之后需要同时merge到master分支与develop分支（如果需要测试介入验证，则可先merge到pre-release分支，验证通过后再merge到master分支上线）。merge时参考“正常开发流程”。流程示意图如下 我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ———————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"teamwork","slug":"teamwork","permalink":"http://blog.jboost.cn/categories/teamwork/"}],"tags":[{"name":"git","slug":"git","permalink":"http://blog.jboost.cn/tags/git/"}]},{"title":"命令行高效操作Git，看这篇就够了","slug":"use-git","date":"2019-06-16T06:30:07.000Z","updated":"2019-07-09T11:19:28.676Z","comments":true,"path":"2019/06/16/use-git.html","link":"","permalink":"http://blog.jboost.cn/2019/06/16/use-git.html","excerpt":"对于软件开发人员来说，git几乎是每天都需要接触的工具。但对于相处如此亲密的工作伙伴，你对它的了解又有多少，是不是还在傻瓜式地打开一个GUI工具，点击提交按钮，然后“卧槽，又冲突了”，一脸懵逼到不知所措，责怪谁又在你前面提交了，谁又改了你的代码。","text":"对于软件开发人员来说，git几乎是每天都需要接触的工具。但对于相处如此亲密的工作伙伴，你对它的了解又有多少，是不是还在傻瓜式地打开一个GUI工具，点击提交按钮，然后“卧槽，又冲突了”，一脸懵逼到不知所措，责怪谁又在你前面提交了，谁又改了你的代码。 博主从一开始接触git，就没用过任何GUI工具，都是通过命令行进行操作，发现这种方式不仅对git的理解更深，效率也更高，遇到问题时一般都知道如何来处理，故做此分享。本文所有知识与操作只涉及日常使用场景，更多详细内容可自行查阅其它资料。本文Git版本为 windows-2.20.1版。 基础理论git的理论知识，对使用者来说只需要知道它是分布式版本控制系统，了解如下三个概念即可， 工作区：就是你直接操作的文件目录与内容 暂存区：暂时为你保存还没将内容提交到版本库的一个区域，对应.git目录下的stage或index文件 版本库：分本地版本库与远程版本库，本地版本库就理解为对应.git目录即可，远程版本库就是远程仓库，如gitlab或github的repository。 如下图，我们平时提交代码的过程基本都是从工作区add到暂存区，然后再commit到本地仓库，最后push到远程仓库。 基本命令对于日常工作，掌握如下几个基本命令一般就够了 git status 查看修改状态 git pull origin master 拉取远程仓库master分支合并到本地，master根据场景换成其它分支名 git add file 添加文件到暂存区，可用 * 添加所有 git commit -m &quot;commit message&quot; 提交到本地版本库，并添加注释，注释表明此次修改内容，要清晰准确 git push origin master 将本地版本提交到远程仓库的master分支，master根据场景换成其它分支名 对大部分日常工作来说， 上面几个命令基本就够用了。 新建项目1. 从本地到远程 项目开发的时候，有时候是先在本地建一个项目，再提交到远程仓库的。 创建项目目录（或通过IDE创建），命令行cd到项目目录 执行git init ， 将在项目目录创建.git目录 执行git add * ，将所有文件添加到暂存区，这里要先创建一个.gitignore文件，将不需要版本维护的文件添加进去忽略，不然各种IDE编译文件夹，环境相关文件都加到版本库去了。删除文件用git rm file_name 执行git commit -m &quot;upload project&quot; ，提交到本地仓库 在gitlab或github上创建一个仓库，并将仓库地址复制下来 执行git remote add origin git@server-name:path/repo-name.git ，关联远程仓库，仓库地址如果是http开头则要用户名密码，如果是git开头，则是走的ssh协议，需要将你本机的ssh公钥添加到远程仓库服务上。 执行git push -u origin master ，推送本地仓库内容到远程仓库 这样在远程仓库目录，就能看到你提交上去的文件内容了。 2. 从远程到本地更多的时候，是远程仓库已有项目了，需要下载到本地开发。 git clone git@server-name:path/repo-name.git ， 将远程仓库的内容下载到本地，这里仓库地址的处理同上 修改内容 git add * ，将修改的内容添加到暂存区 git commit -m &quot;fix xxx issue&quot; ，提交到本地仓库 git push -u origin master ， 推送本地仓库内容至远程仓库 版本回退有时候改了文件，想反悔怎么办，git给你“后悔药”。 单个文件的还原： git checkout file_name ，丢弃工作区的修改，还原到上次提交（commit）的版本， git reset HEAD file_name ，把暂存区的修改撤销掉（unstage），重新放回工作区。即还原到上次添加到暂存区（add）的版本 这里涉及几个场景 场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout file_name。 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时（执行了add，但没执行commit），想丢弃修改，分两步，第一步用命令git reset HEAD file_name，就回到了场景1，第二步按场景1操作。 场景3：已经提交了不合适的修改到版本库时，想要撤销本次的全部提交，参考下面的整个版本的还原，不过前提是没有推送到远程库。 整个版本的还原： git reset --hard HEAD^^， 回退到上上个版本 git reset --hard 3628164， 回退到具体某个版本 3628164 是具体某个commit_id缩写 找不到commit_id？ git reflog 可查看每一个命令的历史记录，获取对应操作的commit_id。git log [--pretty=oneline]， 可查看commit记录 上一个版本就是HEAD^，上上一个版本就是HEAD^^，往上100个版本写成HEAD~100。3628164 是具体某个commit_id，不需要写全，只需要唯一确定就行，可往前进也可往后退。（git windows2.20.1版貌似不支持对HEAD^的操作） 多人协作 首先，可以试图用 git push origin branch_name 推送自己的修改； 如果推送失败，则因为远程分支比你的本地更新，需要先用 git pull 试图合并； 如果合并有冲突，则手动解决冲突，并在本地提交； 没有冲突或者解决掉冲突后，再用 git push origin branch-name 推送就能成功！ 如果git pull提示“no tracking information”，则说明本地分支和远程分支的链接关系没有创建，用命令git branch –set-upstream branch-name origin/branch-name 在本地创建和远程分支对应的分支，使用git checkout -b branch-name origin/branch-name，本地和远程分支的名称最好一致 分支管理平时开发时需要创建子分支来实现你的功能模块，然后再合并到主分支中。 git checkout -b your_branch_name ， 创建并切换分支 git branch ， 查看分支，标有*号表示当前所在分支 git merge dev ， 合并指定dev分支到当前分支 git merge --no-ff -m &quot;merge with no-ff&quot; dev ， 合并分支并生成commit记录 git branch -d dev ， 删除分支 git checkout -b dev = git branch dev + git checkout dev Fast-forward合并，“快进模式”，也就是直接把master指向dev的当前提交，所以合并速度非常快。存在冲突的不能fast forward。git merge --no-ff -m &quot;merge with no-ff&quot; dev Fast forward模式下，删除分支后，会丢掉分支信息。如果强制禁用Fast forward模式，Git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息 标签管理当发布版本时，一般需要对当前版本进行标签记录，以便后续进行版本查看或回退。 git tag tag_name ， 对当前分支打标签 git tag ， 查看所有标签 git tag v0.9 6224937 ，针对某个具体commit id打标签 git show tag_name ， 查看标签信息 git tag -a v0.1 -m &quot;version 0.1 released&quot; 3628164 ， 带有说明的标签 git tag -d v0.1 ， 删除标签 git push origin tag_name ， 推送标签到远程 git push origin --tags ， 一次性推送所有标签 删除已经推送到远程的标签： git tag -d v0.9 ， 先本地删除 git push origin :refs/tags/v0.9 ， 然后从远程删除 提高效率的Tips 配置命令别名 123git config --global alias.st status # 后面可以用git st 来代替git status了git config --global alias.ck checkout # 后面可以用 git ck 来代替 git checkout了git config --global alias.cm 'commit -m' # 后面可以用git cm 来代替 git commit -m 了 git pull origin master 或 git push origin master， 可直接 git pull 或 git push， 如果出现“no tracking information”的提示，则说明本地分支和远程分支的链接关系没有创建，用命令 git branch --set-upstream-to=origin/master master 建立关联即可。 总结以上命令虽然看起来多，但平常用的最频繁的应该是“基本命令”与“分支管理”部分，只要多用几次，自然便能记住，应付日常工作完全没有问题，彻底脱离GUI操作，让工作更有效率。 我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ———————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"高效实践","slug":"高效实践","permalink":"http://blog.jboost.cn/categories/高效实践/"}],"tags":[{"name":"git","slug":"git","permalink":"http://blog.jboost.cn/tags/git/"}]},{"title":"案例解析：线程池使用不当导致系统崩溃","slug":"issue-threadpool","date":"2019-06-15T03:01:58.000Z","updated":"2019-07-09T11:19:28.488Z","comments":true,"path":"2019/06/15/issue-threadpool.html","link":"","permalink":"http://blog.jboost.cn/2019/06/15/issue-threadpool.html","excerpt":"前几天，发现一台阿里云服务器上的Web服务不可用。远程SSH登录不上，尝试几次登录上去之后，执行命令都显示1-bash: fork: Cannot allocate memory 一看以为是内存泄漏导致溢出。因为执行不了任何命令， 只能通过控制台重启服务器恢复服务。","text":"前几天，发现一台阿里云服务器上的Web服务不可用。远程SSH登录不上，尝试几次登录上去之后，执行命令都显示1-bash: fork: Cannot allocate memory 一看以为是内存泄漏导致溢出。因为执行不了任何命令， 只能通过控制台重启服务器恢复服务。 初步排查服务恢复后，查看系统日志，linux系统日志路径/var/log/messages，可通过journalctl命令查看，如12journalctl --since=\"2019-06-12 06:00:00\" --until=\"2019-06-12 10:00:00\"` 可查看since之后，until之前时间段的日志。除了发现crond[14954]: (CRON) CAN&#39;T FORK (do_command): Cannot allocate memory 这个错误日志，未见其它异常（下面的sshd[10764]: error: fork: Cannot allocate memory应是ssh登录执行命名失败的日志） 通过阿里云-云监控-主机监控查看内存使用率指标，这段时间内，内存使用率一直在40%以下，基本可排除内存溢出的可能。 通过搜索查阅到进程数超过操作系统限制可能导致bash: fork: Cannot allocate memory的报错(参考： https://blog.csdn.net/wangshuminjava/article/details/80603847 ）。通过ps -eLf|wc -l查看当前进程线程数(ps -ef只打印进程，ps -eLf会打印所有的线程), 只有1000多个，故障时刻系统到底运行了多少线程已无从得知，只能持续跟进监测。 问题定位几天后，再次通过ps -eLf|wc -l查看，发现线程数已达16000多个。直接执行ps -eLf可看到大量tomcat进程所产生的线程，猜测是不是线程死锁导致大量线程未完成一直hung在那里。 执行 jstack 进程号 &gt; ~/jstack.txt 命令将进程所运行线程情况打印出来分析，发现大量的WAITING状态的线程，如下1234567891011\"pool-19-thread-1\" #254 prio=5 os_prio=0 tid=0x00007f0b700a6000 nid=0x29a9 waiting on condition [0x00007f0b274df000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000006ce3d8790&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) 根据上述内容可看出线程在等一个条件，并且是在执行LinkedBlockingQueue.take方法的时候，查看该方法的java doc，当队列为空时，该方法将会一直等待直到有元素可用。12345678/** * Retrieves and removes the head of this queue, waiting if necessary * until an element becomes available. * * @return the head of this queue * @throws InterruptedException if interrupted while waiting */E take() throws InterruptedException; 询问同事在哪里用到了LinkedBlockingQueue，同事回忆起不久前用线程池实现往阿里云OSS服务通过追加的方式上传文件功能，查看代码后发现问题——线程池没有关闭。为了使文件片段保存不存在错乱，每次保存文件时，都new了一个线程池对象，1ThreadPoolExecutor saveImgThreadPool = new ThreadPoolExecutor(1, 1, 0, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;()); 但处理完后， 没有关闭这个线程池对象，这样线程池仍会通过take方法去取等待队列中是否还有未完成的线程任务，等待队列为空时将会一直等待，这样就导致大量的线程hung在这里了（基本是只要方法被调一次，就会产生一个hung住的线程）。 延伸 线程状态为“waiting for monitor entry”：意味着它 在等待进入一个临界区 ，所以它在”Entry Set“队列中等待。此时线程状态一般都是 Blocked：java.lang.Thread.State: BLOCKED (on object monitor) 线程状态为“waiting on condition”：说明它在等待另一个条件的发生，来把自己唤醒，或者干脆它是调用了 sleep(N)。此时线程状态大致为以下几种：java.lang.Thread.State: WAITING (parking)：一直等那个条件发生（本文案例即为此种场景）；java.lang.Thread.State: TIMED_WAITING (parking或sleeping)：定时的，那个条件不到来，也将定时唤醒自己。 如果大量线程在“waiting for monitor entry”：可能是一个全局锁阻塞住了大量线程。如果短时间内打印的thread dump 文件反映，随着时间流逝，waiting for monitor entry 的线程越来越多，没有减少的趋势，可能意味着某些线程在临界区里呆的时间太长了，以至于越来越多新线程迟迟无法进入临界区。 如果大量线程在“waiting on condition”：可能是它们又跑去获取第三方资源，尤其是第三方网络资源，迟迟获取不到Response，导致大量线程进入等待状态。所以如果你发现有大量的线程都处在 Wait on condition，从线程堆栈看，正等待网络读写，这可能是一个网络瓶颈的征兆，因为网络阻塞导致线程无法执行。也可能是如本文所提到的，由于程序编写不当所致。 参考： https://www.cnblogs.com/rainy-shurun/p/5732341.html 我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy —————————————————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"案例解析","slug":"案例解析","permalink":"http://blog.jboost.cn/categories/案例解析/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"}]},{"title":"Spring Boot从入门到实战（五）：写一个自己的starter","slug":"springboot-starter","date":"2019-06-14T07:19:43.000Z","updated":"2019-07-22T10:28:59.126Z","comments":true,"path":"2019/06/14/springboot-starter.html","link":"","permalink":"http://blog.jboost.cn/2019/06/14/springboot-starter.html","excerpt":"曾遇到几位面试者，简历上写着精通Spring Boot，当聊到自动配置及对starter的理解时，却说不出个所以然来。找工作时，简历一定要注重实际，精通这种字眼还是少用，不然面试官对你期望越高，失望也就越大。其实结合前一篇介绍的Spring Boot自动配置，对Spring Boot的Starter实现将很容易理解，不论是使用其官方提供的Starter，还是自定义自己的Starter，都变得很容易。","text":"曾遇到几位面试者，简历上写着精通Spring Boot，当聊到自动配置及对starter的理解时，却说不出个所以然来。找工作时，简历一定要注重实际，精通这种字眼还是少用，不然面试官对你期望越高，失望也就越大。其实结合前一篇介绍的Spring Boot自动配置，对Spring Boot的Starter实现将很容易理解，不论是使用其官方提供的Starter，还是自定义自己的Starter，都变得很容易。 根据前面介绍，Spring Boot自动配置的实现，主要由如下几部分完成： @EnableAutoConfiguration注解 SpringApplication类 spring-boot-autoconfigure jar包 spring.factories文件 项目结构官方提供的starter，大多包含两个jar包： 一个starter——没有任何实现，只用来管理依赖（即实现这个starter的功能需要依赖哪些jar），一个autoconfigure——包含所有具体实现，包括自动配置类，及META-INF/spring.factories文件。本文示例的自定义starter，为了方便，将两者合并写到了一个。 但是在实际项目中，还是建议像官方一样，定义一个spring-boot-dependencies声明所有依赖及其版本，做统一依赖版本管理，一个spring-boot-autoconfigure，实现所有自动配置类及相应的Bean，一个spring-boot-starters，针对每个模块引入必须的jar依赖，方便项目中引入。 官方提供的starter，命名遵循spring-boot-starter-xxx， 自定义starter，命名遵循xxx-spring-boot-starter。 示例的项目结构如下图 springboot-starter这里为了简单，将starter与autoconfigure整到一个项目，命名也为了与前面demo项目保持一致，没按规范来。 配置类 MyAutoConfig12345678910111213@Configuration@EnableConfigurationProperties(MyProperties.class)public class MyAutoConfig &#123; @Autowired private MyProperties myProperties; @Bean @ConditionalOnProperty(prefix = \"my\", name = \"disable\", havingValue = \"false\") public MyService myService()&#123; return new MyService(\"Hi \" + myProperties.getName() + \", welcome to visit \" + myProperties.getWebsite()); &#125;&#125; 该类中通过@EnableConfigurationProperties及@Autowired 引入了配置属性Bean MyProperties 以访问用户配置的属性，@Bean注解即向容器中注入方法返回值类型的Bean，这样在容器其它bean中通过@Autowired即可引用访问， @ConditionalOnProperty是条件注解，这里表明当配置属性my.disable=false时才实例化这个MyService bean。 配置属性类 MyProperties1234567@ConfigurationProperties(prefix = \"my\")public class MyProperties &#123; private String name; private String website; getter/setter;&#125; 配置属性类封装了用户在配置文件中定义的属性，该示例中将前缀为my的属性封装起来，访问name，website对应配置属性key就是my.name，my.website。 服务Bean MyService1234567891011public class MyService &#123; private String hiStr; public MyService(String hiStr)&#123; this.hiStr = hiStr; &#125; public String sayHi()&#123; return this.hiStr; &#125;&#125; 提供服务功能的bean，也即需要实例化注入到Spring上下文的bean。 spring.factories12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ cn.jboost.springboot.starter.MyAutoConfig 指定了自动配置类（带包名的全路径类名） springboot-usingstarter该项目引用springboot-starter，调用MyService服务的项目，主类没什么特别的1234567@SpringBootApplicationpublic class SpringbootUsingstarterApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootUsingstarterApplication.class, args); &#125;&#125; 配置文件application.properties123my.disable=falsemy.name=jboostmy.website=blog.jboost.cn 在测试类SpringbootUsingstarterApplicationTests中编写测试1234567@Autowiredprivate MyService myService;@Testpublic void testStarter()&#123; System.out.printf(myService.sayHi());&#125; pom.xml中引入springboot-starter依赖12345678910111213 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;cn.jboost.springboot&lt;/groupId&gt; &lt;artifactId&gt;springboot-starter&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 运行，控制台会打印出 Hi jboost, welcome to visit blog.jboost.cn将配置属性my.disable的值改为true或其它非false的值再运行测试代码试试，会报MyService bean找不到的错误，说明@ConditionalOnProperty注解生效了 本示例仅作实现自定义starter演示用，项目结构、命名都不够规范，仅供参考，项目实战starter在后面继续分享。 本文示例项目源码地址：https://github.com/ronwxy/springboot-demos/tree/master/springboot-starterhttps://github.com/ronwxy/springboot-demos/tree/master/springboot-usingstarter我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy —————————————————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"Spring Boot从入门到实战（四）：Spring Boot配置","slug":"springboot-config","date":"2019-06-11T07:46:02.000Z","updated":"2019-07-22T10:28:12.660Z","comments":true,"path":"2019/06/11/springboot-config.html","link":"","permalink":"http://blog.jboost.cn/2019/06/11/springboot-config.html","excerpt":"Spring Boot之所以受开发者欢迎， 其中最重要的一个因素就是其配置简单。传统的Spring应用需要手动配置各种.xml文件，为数据库访问，事务支持，缓存功能等提供各项繁杂且重复的配置。Spring Boot将这种繁杂且重复的工作通过预定义的启动器（starter）来实现，只要引入即可拥有相应的功能支持，从而将开发者从复杂的配置工作中解放出来，能够更专注于业务逻辑的开发。","text":"Spring Boot之所以受开发者欢迎， 其中最重要的一个因素就是其配置简单。传统的Spring应用需要手动配置各种.xml文件，为数据库访问，事务支持，缓存功能等提供各项繁杂且重复的配置。Spring Boot将这种繁杂且重复的工作通过预定义的启动器（starter）来实现，只要引入即可拥有相应的功能支持，从而将开发者从复杂的配置工作中解放出来，能够更专注于业务逻辑的开发。 配置方式在Spring Boot中，虽然仍然可以通过之前的.xml文件方式来进行配置，但最好还是通过基于java的配置来进行配置管理。在Spring Boot中，基于java的配置是通过注解@Configuration来实现的12345678@Configurationpublic class MyConfig &#123; @Bean public MyService myService()&#123; return new MyService(); &#125;&#125; 上述代码将一个MyService的Bean注入了容器，这样在其它地方就可以直接通过@Autowired来引用访问。与.xml文件中通过&lt;bean&gt;&lt;/bean&gt;实例化的效果是一样的。1234567@Autowiredprivate MyService myService;@RequestMapping(\"/hi\")public String sayHello(@RequestParam String name)&#123; return myService.sayHello(name);&#125; 实际项目开发中，有可能存在一些基于xml配置的旧服务，比如以jar包的形式发布，如果要复用该怎么引入呢？很简单，在@Configuration注解标注的类上，加入@ImportResource注解引用相应的xml文件即可，123456789@Configuration@ImportResource(\"spring.xml\")public class MyConfig &#123; @Bean public MyService myService()&#123; return new MyService(); &#125;&#125; 这样类路径下spring.xml配置文件中声明的内容都将生效。在一个应用中，可以定义多个@Configuration配置类，这些配置类可以被@ComponentScan自动扫描并注入容器。 如果应用中没有通过@ComponentScan进行自动扫描，则可在主配置类（一般为入口类）上通过@Import({MyConfig.class})的方式类引入其它配置类 自动配置个人认为，自动配置是Spring Boot非常基础但又核心的部分。曾经遇到几个面试者，简历写着精通Spring Boot，当问及自动配置时却支支吾吾不知所云。其实理解Spring Boot的自动配置也不难，基本了解如下几部分差不多就够了： @EnableAutoConfiguration注解 SpringApplication类 spring-boot-autoconfigure jar包 spring.factories文件 @EnableAutoConfiguration注解这个注解的作用是告诉Spring Boot基于添加的jar依赖来自动配置Spring，比如添加了spring-boot-starter-web依赖，则Spring Boot认为你在开发一个web应用，就会自动做好web相应配置。这个注解一般放在主类上。在前面的示例项目中， 我们在主类上都是使用@SpringBootApplication， 查看源码可以知道： @SpringBootApplication 这个注解实际上等效于 @SpringBootConfiguration（等效于@Configuration）， @EnableAutoConfiguration，启用自动配置 @ComponentScan 自动扫描@Component, @Service, @Controller等注解标注的各类组件 三者的组合。如果去掉@EnableAutoConfiguration注解，则Spring Boot将不会自动配置Spring（如实例化必要的Bean），将可能导致应用启动失败。 SpringApplication类在应用主类中，我们是通过SpringApplication的run方法来启动应用的，如：1234567@SpringBootApplicationpublic class SpringbootConfigApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootConfigApplication.class, args); &#125;&#125; 查看源码，SpringApplication的静态run方法，实际也是通过创建SpringApplication实例，调用实例方法执行，在SpringApplication构造器方法中，调用了getSpringFactoriesInstances 方法，12345678910public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources&#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, \"PrimarySources must not be null\"); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath(); setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass();&#125; 追溯下去，最终会调用到SpringFactoriesLoader的loadSpringFactories方法，123456789101112131415161718192021222324252627private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(@Nullable ClassLoader classLoader) &#123; ... try &#123; Enumeration&lt;URL&gt; urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) : ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION)); result = new LinkedMultiValueMap&lt;&gt;(); while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); Properties properties = PropertiesLoaderUtils.loadProperties(resource); for (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) &#123; String factoryClassName = ((String) entry.getKey()).trim(); for (String factoryName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) &#123; result.add(factoryClassName, factoryName.trim()); &#125; &#125; &#125; cache.put(classLoader, result); return result; &#125; catch (IOException ex) &#123; throw new IllegalArgumentException(\"Unable to load factories from location [\" + FACTORIES_RESOURCE_LOCATION + \"]\", ex); &#125;&#125; 在该方法中，会从所有的META-INF目录下加载spring.factories文件里配置的各类型的类名称（包括初始化器，监听器，自动配置类等）。然后上层方法中通过反射机制实例化这些初始化器、监听器，自动配置等，从而完成相应Bean的自动化配置与注入。 spring-boot-autoconfigure 官方提供的starter，如spring-boot-starter-web， 都依赖了spring-boot-starter， 而spring-boot-starter又依赖了spring-boot-autoconfigure。 在spring-boot-autoconfigure中提供了大量官方提供的自动配置类，并且包含META-INF/spring.factories文件，如下图 spring.factories 由上图可看出，spring.factories包含了 org.springframework.context.ApplicationContextInitializer 应用初始化器 org.springframework.context.ApplicationListener 应用监听器 org.springframework.boot.autoconfigure.AutoConfigurationImportListener 自动配置引入监听器 org.springframework.boot.autoconfigure.AutoConfigurationImportFilter 自动配置引入过滤器 org.springframework.boot.autoconfigure.EnableAutoConfiguration 自动配置类 org.springframework.boot.diagnostics.FailureAnalyzer 失败分析器 org.springframework.boot.autoconfigure.template.TemplateAvailabilityProvider 模板提供者 其中org.springframework.boot.autoconfigure.EnableAutoConfiguration即实现自动配置的@Configuration配置类列表。 Spring Boot就是通过这种自动配置机制，以starter依赖包的方式，使开发者非常方便地使用项目开发中的许多常用功能，如数据库访问、缓存、队列等。同时，用户也可以根据自身需求，自定义自己的starter（后面介绍）。 通过注解控制自动配置Spring Boot自动配置包含了许多条件类注解及顺序类注解，这些注解可方便地让自动配置按照某种条件或者顺序进行配置。 其中条件类注解包括： 类级别条件注解 @ConditionalOnClass： 类路径中存在指定的类才进行该配置；@ConditionalOnMissingClass： 类路径中不存在指定的类才进行该配置 实例级别条件注解 @ConditionalOnBean：只有在当前上下文中存在指定Bean时，才进行该配置@ConditionalOnMissingBean： 只有在当前上下文不存在指定Bean时，才进行该配置 属性级别条件注解 @ConditionalOnProperty：当存在某个指定属性，且值为指定值时，才进行该配置 资源级别条件注解 @ConditionalOnResource：在类路径下存在指定的Resource时，才进行配置 Web应用条件注解 @ConditionalOnWebApplication：该应用为Web应用时进行该配置@ConditionalOnNotWebApplication： 该应用不为Web应用时进行该配置 SpEL（ Spring Expression Language）表达式注解 @ConditionalOnExpression： 计算SpEL表达式值，值为true时才进行该配置 顺序类注解包括： @AutoConfigureAfter： 在指定的配置类初始化后再加载 @AutoConfigureBefore： 在指定的配置类初始化前加载 @AutoConfigureOrder： 数值越小越先初始化 注意：自动配置类不应该位于组件扫描路径（@ComponentScan注解指定的扫描路径）下，否则上述条件注解与顺序注解可能不会生效。建议只在自动配置的类上注解@ConditionalOnBean， @ConditionalOnMissingBean，因为这可以保证在用户定义bean已经添加到ApplicationContext之后才会加载。这两个注解放在class上，则相当于class里面每一个@Bean标注的方法都加上了。 自动配置是非侵入式的，你可以在任何地方自定义配置来覆盖自动配置中的某些内容，比如你在应用中通过@Configuration类注入一个自定义的DataSource，默认的基于内存的DataSource将被覆盖 禁用某个自动配置类有时候引入的自动配置可能包含我们不想让其生效的配置类，这时候可以通过@EnableAutoConfiguration注解的属性进行排除，使其不生效。1@EnableAutoConfiguration(exclude = &#123;XXAutoConfiguration.class&#125;) 其中XXAutoConfiguration为某个自动配置类，如果该类不在应用的类路径中，则可以通过属性excludeName指定完整类路径来排除。@SpringBootApplicationz注解同样支持1@SpringBootApplication(exclude = &#123;XXAutoConfiguration.class&#125;) 本文示例项目源码地址：https://github.com/ronwxy/springboot-demos/tree/master/springboot-config我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy —————————————————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"Spring Boot从入门到实战（三）：Spring Boot自定义属性","slug":"springboot-properties","date":"2019-06-10T10:47:51.000Z","updated":"2019-07-22T10:27:52.437Z","comments":true,"path":"2019/06/10/springboot-properties.html","link":"","permalink":"http://blog.jboost.cn/2019/06/10/springboot-properties.html","excerpt":"Web项目开发中，经常需要自定义一些属性，如数据库连接，第三方服务接口地址，第三方服务的appKey、appSecret等，以及针对不同环境，这些属性的值还需要有相应的调整，如开发环境、测试环境、生产环境所用数据库不同，则针对不同环境的同一属性需要配置不同的值。","text":"Web项目开发中，经常需要自定义一些属性，如数据库连接，第三方服务接口地址，第三方服务的appKey、appSecret等，以及针对不同环境，这些属性的值还需要有相应的调整，如开发环境、测试环境、生产环境所用数据库不同，则针对不同环境的同一属性需要配置不同的值。 传统自定义属性配置及访问（参考Github示例测试类）在传统的Spring Web应用中，自定义属性一般是通过在类路径中（如resources目录）添加一个类似my.properties配置文件（文件名自定义），然后在xml配置中通过 1&lt;util:properties id=\"myProps\" location=\"classpath:my.properties\"/&gt; 引入属性文件。再定义一个Bean来读取这些属性，Bean配置： 12345678&lt;bean class=\"org.springframework.beans.factory.config.MethodInvokingFactoryBean\"&gt; &lt;property name=\"staticMethod\" value=\"cn.jboost.springboot.properties.MyPropertiesUtil.init\"/&gt; &lt;property name=\"arguments\"&gt; &lt;list&gt; &lt;ref bean=\"myProps\"/&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; Bean定义：123456789101112public class MyPropertiesUtil &#123; private static Properties properties; public static void init(Properties props) &#123; properties = props; &#125; public static String getValue(String key) &#123; return properties.getProperty(key); &#125;&#125; 在其它需要访问的地方通过 MyPropertiesUtil.getValue() 方法来访问具体某个属性的值。 Spring Boot自定义属性配置及优先级在Spring Boot中，可以在多个地方配置属性，包括.properties文件，.yaml文件，环境变量， 系统属性，命令行参数等， 这些属性都会被Spring Boot加载到Environment中，可通过@Value注解，Environment实例，或 @ConfigurationProperties注解的类来访问。 属性加载优先级顺序： 如果有使用devtools，devtools 全局设置的属性（用户目录 ~/.spring-bootdevtools.properties） 测试类的注解@TestPropertySource 测试类注解 @SpringBootTest#properties 配置的属性 命令行参数 SPRING_APPLICATION_JSON里的属性（环境变量或系统属性） ServletConfig初始化参数 ServletContext初始化参数 JNDI参数 java:comp/env Java系统属性 System.getProperties() 操作系统环境变量 RandomValuePropertySource 配置的属性 random.* jar包外部的applictaion-{profile}.properties，applictaion-{profile}.yml配置文件 jar包内部的applictaion-{profile}.properties，applictaion-{profile}.yml配置文件 jar包外部的applictaion.properties，applictaion.yml配置文件 jar包内部的applictaion.properties，applictaion.yml配置文件 @Configuration类上的 @PropertySource注解指定的配置文件 默认属性： SpringApplication.setDefaultProperties 上述属性配置，除了粗体标注的外，其它一般应用较少。序号低的配置优先级高于序号高的配置，即如果存在相同属性配置 ，则序号低的配置会覆盖序号高的配置。applictaion-{profile}.properties 一般用于具体某个环境特有的属性配置，如application-dev.properties用于开发环境，可通过 spring.profiles.active=dev指定加载dev环境配置 常用属性配置方式 命令行参数启动Spring Boot应用时，可以指定命令行参数，如：1java -jar springboot-properties.jar --my.name=jboost@command_line 该参数值将会覆盖应用在其它地方配置的同名属性值。命令行参数放在xx.jar 的后面。 可以通过SpringApplication.setAddCommandLineProperties(false) 禁用命令行参数配置 Java系统属性同样在启动Spring Boot应用时，可以指定Java系统属性，一般见于自定义jvm参数，如：1java -Dmy.name=jboost@system_properties -jar springboot-properties.jar Java系统属性放在java命令之后。 操作系统环境变量（实际应用其实较少）配置过JAVA_HOME的应该理解何为环境变量。某些操作系统可能不支持.分隔的属性名，可以改为以下划线连接。Spring Boot将myName, my.name, MY_NAME视为等效。 应用属性配置文件（.properties文件或 .yml文件）.properties文件属性配置格式： 123my.name=jboostmy.list[0]=aaa //配置列表my.list[1]=bbb .yml文件属性配置格式： 12345my: name: devlink list: //配置列表 - aaa - bbb yml中，属性名与值之间冒号后面必须有空格。 应用属性配置文件位置： jar包所在当前目录下的子目录/config（外置属性文件） jar包所在当前目录（外置属性文件） classpath根目录下的子目录/config（内置属性文件） classpath根目录（内置属性文件） 序号低的优先级高于序号高的优先级，即jar包外的配置优先级高于jar包内的配置。同一目录下，.properties文件的优先级高于.yml文件。application-{profile}.properties的优先级高于application.properties。 Spring Boot自定义属性访问方式（参考Github示例测试类） 类中属性上添加 @Value(“${xx}”) 注解方式。如：12@Value(\"$&#123;my.name&#125;\")private String name; 可以指定默认值，如 @Value(“${my.name:jboost}”)， 当my.name未配置时，默认使用值”jboost” 通过@ConfigurationProperties注解的类来访问。如定义：12345678@Component@ConfigurationProperties(prefix = \"my\")public class MyConfigProperties &#123; private String name; private String website; //省略了getter、setter函数&#125; 然后在需要访问的Bean中，通过@Autowired 注入MyConfigProperties实例，通过getName()方法即可访问my.name属性值。123456789@Autowiredprivate MyConfigProperties myConfigProperties;@Testpublic void testConfigurationProperties()&#123; System.out.println(\"test @ConfigurationProperties ==========\"); System.out.println(myConfigProperties.getName()); System.out.println(myConfigProperties.getWebsite());&#125; 通过Environment 实例访问。如：123456789@Autowiredprivate Environment env;@Testpublic void testEnvironment()&#123; System.out.println(\"test Environment ==========\"); System.out.println(env.getProperty(\"my.name\")); System.out.println(env.getProperty(\"my.website\", \"default value\"));&#125; 另外也可以通过 spring-boot-starter-actuator 的接口来查看项目加载的属性配置，在pom.xml中加入 spring-boot-starter-actuator 依赖，因为 spring-boot-starter-actuator 在2.x版本中，出于安全性考虑，将actuator 控件中的端口，只默认开放/health 和/info 两个端口，其他端口默认关闭，因此需要添加配置management.endpoints.web.exposure.include= *，management.endpoints.web.exposure.exclude=beans,trace，management.endpoint.health.show-details=ALWAYS，启动项目后，访问 http://localhost:8080/actuator/env ，返回的 propertySources 即为加载的所有属性源，优先级从上往下依次降低，与上文所述优先级相符 本文示例项目源码地址：https://github.com/ronwxy/springboot-demos/tree/master/springboot-properties 我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ——————————————————————————————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"Spring Boot从入门到实战（二）：第一个Spring Boot应用","slug":"springboot-firstapp","date":"2019-06-06T12:46:50.000Z","updated":"2019-07-22T10:27:17.454Z","comments":true,"path":"2019/06/06/springboot-firstapp.html","link":"","permalink":"http://blog.jboost.cn/2019/06/06/springboot-firstapp.html","excerpt":"Spring Boot应用可以通过如下三种方法创建： 通过 https://start.spring.io/ 网站创建 通过 Spring Initializr 创建 自主创建","text":"Spring Boot应用可以通过如下三种方法创建： 通过 https://start.spring.io/ 网站创建 通过 Spring Initializr 创建 自主创建 推荐开发工具 JDK 1.8+ IntelliJ IDEA maven 3.3+ 在开始之前，先确认是否安装上述工具，在命令行输入 java -version 查看JDK是否正确安装， 输入 mvn -version 查看maven是否正确安装，如果未正确安装，请先查阅相关文档完成安装。12345678910111213PS D:\\&gt; java -versionjava version \"1.8.0_201\"Java(TM) SE Runtime Environment (build 1.8.0_201-b09)Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode)PS D:\\&gt;PS D:\\&gt;PS D:\\&gt; mvn -versionApache Maven 3.6.0 (97c98ec64a1fdfee7767ce5ffb20918da4f719f3; 2018-10-25T02:41:47+08:00)Maven home: D:\\tool\\apache-maven-3.6.0\\bin\\..Java version: 1.8.0_201, vendor: Oracle Corporation, runtime: C:\\Program Files\\Java\\jdk1.8.0_201\\jreDefault locale: zh_CN, platform encoding: GBKOS name: \"windows 10\", version: \"10.0\", arch: \"amd64\", family: \"windows\"PS D:\\&gt; 1. 通过 https://start.spring.io/ 网站创建进入 https://start.spring.io/，填写对应的信息，如下图所示其中project选 Maven Project， Spring Boot版本选 2.1.5 版， Project Metadata部分， Group一般用你域名的倒序字符串，Artifact即项目名称，选择Packaging类型为Jar，Java版本为8，在Dependencies部分输入Web，选中第一个Spring Web Starter，然后点击“Generate the project”按钮，下载生成的项目。解压项目，在IntelliJ IDEA中 File -&gt; Open 选中项目解压目录打开，即可看到生成的项目结构如下图具体各文件含义后面详述。 2. 通过Spring Initializr创建（推荐）IntelliJ IDEA中File -&gt; New -&gt; Project...打开新建项目窗口（这里也可以选择New Module, IDEA的Project类似于Eclipse的Workspace，Module则类似于Eclipse的Project，有时候为了将一些项目统一管理，可以建一个Project，然后在Project内部建立Module），如下图所示 选择Spring Initializr，点击Next，填写相应信息， 如下图所示 点击Next，选择Spring Boot版本以及相应依赖，如下图（这里选择2.1.5版本及Spring Web Starter依赖） 然后依次点击Next, Finish完成项目创建。可以看到创建的项目结构与第一种方法一致。 有的旧IDEA版本下项目可能不能编译，IDE未将其识别为maven项目，只需在pom.xml文件上右键，点击Add as Maven project即可。 3. 自主创建自主创建即像普通Java Maven项目一样，先创建maven项目，然后参考1、2方法中创建的项目结构与目录，手动进行添加。 上述三种创建方法，第1种需要网站生成再下载解压导入，第2种直接基于IDE创建，第3种完全自主手动创建。实际开发中推荐采用第2种创建初始项目原型，再根据具体需求删除或添加相应目录与文件。 4. 项目结构通过上述方法创建的项目，结构如下图所示 其中 SpringbootFirstappApplication 为项目入口类，通过SpringApplication.run()方法来启动项目 入口类上的注解 @SpringBootApplication 表明，这是一个Spring Boot项目，它会为你自动做一些Spring Boot项目的处理 resources 下的static目录为静态资源目录，可以放置js，css，img之类的资源，templates目录可放置模板文件，一般做前后端分离开发，这两个目录可删除 application.properties 文件为项目的配置文件，可在该文件中配置项目所需要的各项配置属性 SpringbootFirstappApplicationTests 生成的测试类，可基于此进行单元测试编写 pom.xml即为maven配置文档，可看到项目已继承spring-boot-starter-parent，并且引入了spring-boot-starter-web，spring-boot-starter-test两项依赖，以及spring-boot-maven-plugin 5. 运行 上述创建的项目可直接运行，大致有如下几种运行方式： 直接在项目入口类SpringbootFirstappApplication中右键，点击Run &#39;SpringbootFirstappAp...&#39;运行 在项目根目录下打开终端，或IDEA的Terminal中执行mvn spring-boot:run（前提是项目pom.xml文件中引入了spring-boot-maven-plugin） 使用mvn package打包，然后通过java -jar target\\springboot-firstapp-1.0.0-SNAPSHOT.jar 启动（一般用于远程环境的部署启动） 如果打包成war，将war包部署到tomcat等Servlet容器运行 项目启动后，从启动日志可看出默认端口为8080，但打开 http://localhost:8080 会显示一个404报错页面，这是因为我们还没有编写任何服务。下面我们添加一个非常简单的Rest服务接口，在项目的根包下（我这里是cn.jboost.springboot.firstapp，实际项目中一般会创建一个controller的子包）添加HelloController类，代码如下 1234567@RestController(\"/hello\")public class HelloController &#123; @GetMapping public String hello(@RequestParam(name = \"name\")String name)&#123; return \"您好，\" + name; &#125;&#125; 其中@RestController注解会将返回结果以字符串的方式解析，@GetMapping等效于@RequestMapping(method = {RequestMethod.GET})重启应用，然后浏览器地址栏中输入 http://localhost:8080/hello?name=jboost， 页面输出如下图： 至此，一个可运行的Web项目即已搭建完成，是不是非常简单。 本文示例项目源码地址：https://github.com/ronwxy/springboot-demos/tree/master/springboot-firstapp我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ——————————————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"Spring Boot从入门到实战（一）：Spring Boot简介","slug":"springboot-overview","date":"2019-06-06T06:29:02.000Z","updated":"2019-07-22T10:26:52.326Z","comments":true,"path":"2019/06/06/springboot-overview.html","link":"","permalink":"http://blog.jboost.cn/2019/06/06/springboot-overview.html","excerpt":"Spring Boot这几年非常流行，差不多是基于Spring框架应用开发的首选，同时在微服务架构领域，如Spring Cloud 框架中，Spring Boot也是基础，因此掌握Spring Boot，应成为Java开发人员必不可少的技能。","text":"Spring Boot这几年非常流行，差不多是基于Spring框架应用开发的首选，同时在微服务架构领域，如Spring Cloud 框架中，Spring Boot也是基础，因此掌握Spring Boot，应成为Java开发人员必不可少的技能。 简述传统的基于Spring的Java Web应用，需要配置 web.xml, applicationContext.xml 等大量xml配置信息，然后将应用打成war包放入web应用服务器(如Tomcat, Jetty等)中运行。有过实践经验的开发者应能体会到这个过程繁杂且重复。Spring Boot将这种繁杂且重复的工作通过自动化配置等手段实现，从而将开发者从复杂的配置工作中解放出来，能够更专注于业务逻辑的开发。因此，Spring Boot并不是Spring的替代解决方案，它本身并不提供Spring框架的核心特性以及扩展功能，而是和Spring框架紧密结合用于提升Spring开发者体验，提高开发效率的的工具框架。截至本文，Spring Boot最新GA版本为2.1.5。 特性Spring Boot框架大致包括如下特性： 自动化配置。Spring Boot 通过autoconfiguration的方式（后面会详细讨论何为autoconfiguration）来简化配置管理。比如如果需要访问数据库，则只需要引入相应的starter依赖包，Spring Boot便会自动为你配置访问数据库所需要的Bean，如 DataSource， JdbcTemplate等。使用Spring Boot，项目中几乎不需要任何 xml 配置文件。 内嵌的Web服务容器。Spring Boot内嵌了Tomcat、Jetty、Undertow。因此，Spring Boot应用可以像普通java应用一样打成jar包直接通过 java -jar 执行，而不需传统web应用一样需要打成war包部署到独立的web服务容器中。 简化依赖管理。Spring Boot官方提供了大量的starter依赖包，帮你管理了使用某个功能所需要的依赖，开发者只需要引入starter依赖，即可使用对应的功能。如spring-boot-starter-web，spring-boot-starter-jdbc等。同时自己也可以自定义starter，为某些通用功能提供模块化共享支持。 提供生产环境级的应用配置、度量指标、操作控制接口。Spring Boot的spring-boot-starter-actuator提供了查看应用配置信息，获取应用运行指标，以及控制应用（如关闭应用）三种类型的接口。通过这些接口，可以排查问题，监控服务运行情况等。 Spring Boot的这些特性，使得应用Spring Boot开发Web应用非常便捷、高效，因此在快速应用开发（Rapid Application Development）领域以及微服务架构方面，Spring Boot都是比较好的选择。 工具该序列涉及的开发工具包括但不限于： JDK 1.8+ , 一般用的是1.8 Maven 3.3+ , 我们用的是Maven3.6.0 IntelliJ IDEA Ultimate Edition， 需要激活，参考这里 MySQL，可选，数据库访问示例需要 Redis， 可选，缓存示例需要 我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ——————————————————————————————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"写在前面","slug":"ahead","date":"2019-06-05T08:48:37.000Z","updated":"2019-06-10T07:36:24.244Z","comments":true,"path":"2019/06/05/ahead.html","link":"","permalink":"http://blog.jboost.cn/2019/06/05/ahead.html","excerpt":"","text":"一点感悟在软件与互联网技术领域从业多年，从一个一知半解的职场菜鸟成长为行业“老司机”，也从一个邯郸学步的技术新手晋升成为能带领团队披荆斩棘，在技术范畴能掌握话语权的技术管理者。其间也与大多数同行一样，踩过不少坑，加过不少班，背过不少锅……，但同时，也为自己不断成长、进步——包括技术、能力层面，也包括薪酬、职位层面，而感到欣慰。但技术领域日新月异，接触的越多，越发现自己的无知，因此 Stay hungry，Stay foolish，保持持续学习的热情，永远不要满足于现状，才能保持自身竞争力，不至于在年龄增长时，出现所谓的“中年危机”。 一点初衷大学期间也曾玩过新浪博客，写过一些心路历程与人生感悟（^_^），随着年龄的增长，逐渐失去了用文字来抒发情感的激情。工作后，开始接触技术博客，也断断续续写过一些分享，但终因阶段性忙或懒惰，没能坚持下来。与之前抒发情感与感悟不同，技术博客更多的是一种经验的自我梳理总结与分享。一方面为那些踏入职场不久实践经验较缺乏的同行提供参考，另一方面也是对自我日常技术工作的整理，以达到“好记性不如烂笔头”的效果。因此，虽然现今从事一线编码工作相对较少，心中一直还是有一个将以往及现在所接触的实践经验记录与分享出来的想法。于是，花了点时间整了这个博客，希望能坚持下去。 一点期望凡事做了，总希望有所回报。整理文章其实需要花费不少时间与精力，因此也希望发出来的分享能为大家带来切实的收获，获得大家的肯定与良性反馈。有更好建议，也欢迎大家通过留言或其它方式与我交流。希望这是一个好的开始，加油！","categories":[],"tags":[]}]}