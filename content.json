{"meta":{"title":"空山新雨的技术空间","subtitle":"技术与管理兼修","description":"一个不只有技术干货的博客，技术与管理兼修，不断突破自我能力边界","author":"空山新雨","url":"http://blog.jboost.cn","root":"/"},"pages":[{"title":"关于我","date":"2019-06-05T08:11:27.000Z","updated":"2019-07-09T11:18:59.689Z","comments":true,"path":"about/index.html","permalink":"http://blog.jboost.cn/about/index.html","excerpt":"","text":"上海交通大学计算机应用技术硕士毕业，十多年软件技术研发经验 多年软件及互联网行业从业经验。从世界500强到国企，到民企，再到创业公司，经历过几百人参与的跨国大项目，也从0到1主管研发过多款互联网产品 以技术负责人身份主导过多个项目的微服务架构实践，负责过日均TB级大数据平台的研发与运维 多年技术团队管理经验，担任过技术主管，技术经理，技术总监等职务，目前在一公司担任技术总监、研发副总职位 曾利用空闲时间整理过一些技术分享，但终究由于阶段性太忙或其它原因未能坚持。 虽然现在较少写代码，但一直有意愿将多年企业产品与项目技术实践及团队管理的经验分享出来，一方面给有需求的软件与互联网行业技术人员（尤其是计算机相关专业，并有志于从事软件技术工作的高校学生）以参考，另一方面也是对自己技术与经验的梳理、总结。于是花了点时间整了这个博客，希望能坚持下来。 我的github地址，里面有文章涉及源码或其它项目，欢迎follow、打星 为了能及时收到更新的分享文章，欢迎关注我的微信公众号"}],"posts":[{"title":"微服务漫谈","slug":"micro-service","date":"2019-12-24T06:52:04.000Z","updated":"2019-12-26T07:38:58.727Z","comments":true,"path":"micro-service.html","link":"","permalink":"http://blog.jboost.cn/micro-service.html","excerpt":"微服务可以说是近几年技术圈异常火爆的概念，人人都在说微服务，人人都在致力于打造自己的“微服务”。甚至于某些压根不懂技术的项目招标方都在问你们公司用了微服务吗？“微服务”俨然成了衡量团队技术实力或技术逼格的代名词。 但是，微服务真是万能的吗？是不是来个项目就得微服务一下，不然就显得落伍，显得low了呢？ 本文一起聊聊“微服务”的那些事。","text":"微服务可以说是近几年技术圈异常火爆的概念，人人都在说微服务，人人都在致力于打造自己的“微服务”。甚至于某些压根不懂技术的项目招标方都在问你们公司用了微服务吗？“微服务”俨然成了衡量团队技术实力或技术逼格的代名词。 但是，微服务真是万能的吗？是不是来个项目就得微服务一下，不然就显得落伍，显得low了呢？ 本文一起聊聊“微服务”的那些事。 一. 什么是微服务？微服务是一种架构风格，由Martin Fowler（牛人，ThoughtWorks公司的首席科学家，同时也是敏捷开发方法的创始人之一）提出，是指将复杂应用通过拆分为一系列高内聚、低耦合、自治的小（微）服务，每个服务独立开发（可以使用不同的编程语言），独立部署（运行在不同的进程中），并通过轻量级的通信机制（Restful API）进行交互。微服务本质上还是SOA（Service-Oriented-Architecture, 面向服务的架构），但微服务不限定于特定的技术，通过Restful架构风格来完成系统的统一，因此比传统的SOA（一般基于较重的SOAP、WSDL、UDDI等协议技术，通过企业服务总线ESB进行连接集成）更为灵活，更具扩展性。 微服务的特征： 是一种应用于组件设计(服务如何拆分)和部署架构(服务如何部署和通信)的模式 适用于创建具有“一定功能复杂性”的分布式应用系统 各个服务必须小，只负责某个具体的业务功能，比如商品服务，订单服务，根据功能实现关注点分离 各个服务保持自治和相互解耦，进行独立开发、独立部署，及独立升级与伸缩 各个服务之间通过轻量级 API （Restful API）和异步通信（如消息队列）相结合的方式进行通信 二. 微服务的优缺点微服务的优缺点一般相对单体应用（就是所有功能、代码都整在一个工程项目中）而言 1. 微服务的优点：1.1 简化复杂的业务模型微服务将复杂的业务通过一系列的高内聚、低耦合的小型服务来实现，体现了分治的思想。每个服务的开发与维护都非常高效，可管理性更高，能快速响应需求。 1.2 不局限于某项特定的技术因为服务间是通过轻量级的Restful API交互，每一个服务可以独立开发，可选用不同的编程语言与技术框架（虽然实际中对于一般规模一般都是统一的）。 1.3 独立部署与升级，按需伸缩每个服务都是独立部署，运行在不同的进程中，因为加载内容相对较少，所以一般启动也比较快。单个服务的升级对系统整体的影响也较小。同时可以针对各个服务的负载情况，进行独立的按需伸缩。 2. 微服务的缺点：2.1 对“微”的粒度与服务的边界难以把握。微服务开发过程中，开发人员最常见的疑问就是这个接口应该放到哪个服务里。服务应该微到什么程度，服务边界与服务交互如何定义与规范，需要有对业务、技术充分了解的专业人员做上层设计（一般就是架构师），并且持续跟进实施落地，否则很有可能就会导致只是将一个单体应用拆成了多个单体应用，或编织了一张交互错综复杂的服务网络的尴尬局面。 2.2 引入了分布式的复杂性。微服务中某一个请求可能就涉及好几个服务间的调用，如果出现问题，则定位相对困难复杂；同时基于CAP（Consistency，Availability， Partition Tolerance）理论，分布式系统中一致性、可用性、分区容忍性只能同时满足两个，一般在满足可用性与分区容忍性的基础上，对系统提供最终一致性保障。 2.3 对技术栈的要求更高。团队需要对微服务基本理论与相关技术有一定了解，且需要搭建许多业务服务之外的基础设施服务，比如服务注册发现、配置管理、链路监控等。目前微服务技术最热的就是Spring Cloud，也有部分团队选择Dubbo。 2.4 对运维的要求更高。微服务将一个复杂应用拆分为几十个甚至上百个小型服务，迭代升级部署的频率比单体应用更高，采用传统的运维手段很难满足需求，一般需引进DevOps的相关技术手段，如CI（持续集成）、CD（持续部署）、自动化测试、容器化与服务编排，及丰富的监控告警机制等。 三. 如何抉择？如之前文章说到的，技术人员的能力在于解决问题的能力（当然解决问题也分临时性的解决问题与前瞻性的解决问题——解决方案能在较长一段时间内适用）。技术管理者或技术决策者最基本的修为就是在过火过热的各种技术概念与技术框架面前保持冷静，选择最适合业务场景与自身团队的技术方案。 要不要用微服务，什么时候不该用微服务？结合自身理解，总结整理如下： 业务简单，应用规模很小不该用微服务杀鸡不能用牛刀，微服务旨在将复杂业务拆分，简化业务规模， 如果业务本身很简单，一个单体应用就能处理的场景不该用微服务。 业务领域不够清晰、明确不该用微服务业务领域不清晰、不明确，意味着整个业务定义、业务框架都可能朝令夕改，如果采用微服务，则可能导致牵一发而动全身的痛苦局面。 团队技术储备不够不该硬上微服务微服务的分布式特性对团队的技术要求比单体应用高， 如果团队大部分成员之前都没接触过微服务，对微服务缺乏基本的了解，不该硬上微服务。 小型创业公司不适合用微服务该条其实是前面几条的汇总，因为小型创业公司一般就意味着业务相对简单，并且业务领域、设计不够清晰、明确，以及团队技术实力相对较弱，并且人员流动性大等特点，任何一点都不利于微服务的构建。 对于业务较为明确且复杂的系统，如果你团队的技术储备达到一定水平（如对Spring Boot，Spring Cloud，CI/CD，Docker/K8s等有一定掌握），并且有一个对业务与技术都有充分了解且具备决策权的master，微服务无疑是一个很好的选择。否则，慎重！ 四. 总结任何技术与框架都有其适用场景，微服务不是万能钥匙。应结合具体的业务场景，团队组成，技术储备等因素综合考虑，选择最适合自身的技术方案。 —————————————————————————————作者：空山新雨欢迎关注我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号）","categories":[{"name":"Architecture","slug":"Architecture","permalink":"http://blog.jboost.cn/categories/Architecture/"}],"tags":[{"name":"arch","slug":"arch","permalink":"http://blog.jboost.cn/tags/arch/"}]},{"title":"Spring Cloud（一）：服务注册中心Eureka","slug":"springcloud-1","date":"2019-12-24T05:56:55.000Z","updated":"2020-01-13T11:34:24.509Z","comments":true,"path":"springcloud-1.html","link":"","permalink":"http://blog.jboost.cn/springcloud-1.html","excerpt":"Spring Cloud 基于 Netflix 的几个开源项目进行了封装，提供包括服务注册与发现（Eureka），智能路由（Zuul），熔断器（Hystrix），客户端负载均衡（Ribbon）等在内的核心组件。 在微服务系统中，服务少则十几、几十个，多则上百、几百个（据悉 Netflix 的云平台上运行了500多个微服务），这些微服务通过相互调用来为用户提供功能。那么一个服务调用另一个服务是如何进行的，如何定位到另一个服务的地址？代码中写死，还是配置文件中配置？显然对于服务数量较多的系统，这两种方式先不说后续维护，光写起来就很痛苦。于是，对于微服务架构来说，服务的自动注册与发现就成为非常核心的功能，Eureka就是来负责实现这个功能的。 本系列文章与示例均基于最新的Spring Cloud Hoxton版编写。","text":"Spring Cloud 基于 Netflix 的几个开源项目进行了封装，提供包括服务注册与发现（Eureka），智能路由（Zuul），熔断器（Hystrix），客户端负载均衡（Ribbon）等在内的核心组件。 在微服务系统中，服务少则十几、几十个，多则上百、几百个（据悉 Netflix 的云平台上运行了500多个微服务），这些微服务通过相互调用来为用户提供功能。那么一个服务调用另一个服务是如何进行的，如何定位到另一个服务的地址？代码中写死，还是配置文件中配置？显然对于服务数量较多的系统，这两种方式先不说后续维护，光写起来就很痛苦。于是，对于微服务架构来说，服务的自动注册与发现就成为非常核心的功能，Eureka就是来负责实现这个功能的。 本系列文章与示例均基于最新的Spring Cloud Hoxton版编写。 Eureka Eureka是一个基于REST的服务，包括Eureka Server与Eureka Client两个端。Eureka Server作为服务注册中心接受Eureka Client的注册及获取其它服务的地址信息。基本架构如下图所示： 其中 Eureka Server： 作为服务注册中心，提供服务注册与发现功能接口 Service Provider： 服务提供者，将自身服务注册到服务注册中心，供其它服务消费者发现与调用 Service Consumer： 服务消费者，从服务注册中心发现服务，并通过一些负载均衡客户端来调用（比如Ribbon或Feign） 很多时候同一个应用可能既是服务提供者，也是服务消费者——自己作为服务方，为其它服务提供接口，同时也调用其它服务的接口来完成自身的业务逻辑。 Eureka Server Eureka Server的搭建非常简单，其部署可分为单实例部署与多实例集群部署，一般开发测试环境可以使用单实例部署，但生产环境出于高可用要求，可进行多实例集群部署。 在pom.xml中添加依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 为了方便版本引入，可以在pom中添加依赖管理，这样spring cloud相关的starter依赖就不需要指定版本了（如上省略了version）1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 在启动类上添加注解 @EnableEurekaServer 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaApplication.class, args); &#125;&#125; 在application.yml 或 application.properties配置文件中添加配置（个人比较倾向于yml，两者区别可自行百度） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354spring: application: name: spring-cloud-eureka profiles: active: singleserver: port: 8761---spring: profiles: singleeureka: instance: hostname: localhost client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ ---spring: profiles: peer1server: port: 8761eureka: instance: hostname: peer1 client: serviceUrl: defaultZone: http://peer2:8762/eureka/,http://peer3:8763/eureka/---spring: profiles: peer2server: port: 8762eureka: instance: hostname: peer2 client: serviceUrl: defaultZone: http://peer1:8761/eureka/,http://peer3:8763/eureka/---spring: profiles: peer3server: port: 8763eureka: instance: hostname: peer3 client: serviceUrl: defaultZone: http://peer1:8761/eureka/,http://peer2:8762/eureka/ 在该配置文件中，实际上是定义了两种模式，其中默认的profile single是单实例模式， peer1， peer2， peer3组成多实例模式。 eureka.client.registerWithEureka：表示是否将自身注册到Eureka Server，默认为true，单实例模式下一般设置为false，否则会在启动时报连接不到服务器的错误 eureka.client.fetchRegistry：表示是否从Eureka Server获取注册服务列表，默认为true，同样在单实例模式下设置为false eureka.client.serviceUrl.defaultZone：Eureka Server的地址，多实例模式下多个地址以“,”隔开，多个实例之间只要有一条路线连通，则总会将注册信息进行同步 启动 对于单实例模式，如果按如上配置，则直接启动程序即可。启动完成后，访问 http://localhost:8761，即可查看Eureka Server的相关信息，如 上图所示，当前没有Eureka Server的副本也没有任何服务注册。 对于多实例集群模式，则需要根据不同的profile启动多个实例， 12345mvn clean packagecd targetjava -jar springcloud-eureka-1.0-SNAPSHOT.jar --spring.profiles.active=peer1java -jar springcloud-eureka-1.0-SNAPSHOT.jar --spring.profiles.active=peer2java -jar springcloud-eureka-1.0-SNAPSHOT.jar --spring.profiles.active=peer3 启动完成后，打开 http://localhost:8761， 可以看到Eureka Server已经存在副本与注册的服务了（Eureka将自身作为一个服务完成了注册） 上述操作如果是在单机进行，则需要在hosts文件中添加映射，linux下是/etc/hosts，windows10 下是C:\\Windows\\System32\\drivers\\etc\\hosts， 123127.0.0.1 peer1127.0.0.1 peer2127.0.0.1 peer3 Eureka Client Eureka Client一般集成在各个微服务中，集成也非常简单。 pom.xml中添加依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; application.yml配置文件中添加配置 1234567eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;random.uuid&#125; 如果是多实例集群模式，则 eureka.client.serviceUrl.defaultZone 可以配置多个地址，“，”号分隔。 eureka.client.*： 发现服务的配置参数 eureka.instance.*： 注册服务的配置参数， 如上 eureka.instance.prefer-ip-address 设置为true表示服务注册时使用IP，而不是hostname； eureka.instance.instance-id 配置服务实例的ID，默认为 ${spring.cloud.client.hostname}:${spring.application.name}:${spring.application.instance_id:${server.port}}} 添加了依赖就能集成Eureka Client，主类上添加 @EnableDiscoveryClient 注解不是必须。 启动程序后，进入Eureka Server页面即可看到注册的服务 一些知识点（建议掌握） Eureka Client在注册服务时，提供包括hostname，IP地址， port， health indicator url，status page， home page 等在内的meta-data，其它客户端可通过这些信息来直接与服务进行交互，我们也可以通过 eureka.instance.metadataMap 来添加自定义的meta-data，供客户端访问 Eureka Server通过接收Eureka Client的心跳消息来判断服务实例是否存活，如果某一个实例的心跳在特定时间（可配置）内没收到，则将其从注册表中移除。心跳默认间隔为30s，一个服务被其它客户端发现，可能需要经过3次心跳，这也是有时候服务注册比较慢的原因。可通过eureka.instance.leaseRenewalIntervalInSeconds配置，但生产环境建议最好保持默认 Eureka Client默认不会传播当前应用的健康检查状态，一旦注册成功，只要心跳存在，Eureka总是认为应用处于UP状态。可以启用Eureka的健康检查，将状态传播给Eureka，其它应用只会将请求发给UP状态的服务实例 eureka.client.healthcheck.enabled=true。注意这个配置只能配置在application.yml中，配置在bootstrap.yml中可能导致注册服务时，服务以状态为UNKOWN进行注册 Eureka Server是没有后端存储的，服务实例需要通过心跳来更新注册信息，注册信息存于内存中，Eureka Client也有一个基于内存的缓存，不需要每次请求服务都要访问注册中心获取服务地址信息 Eureka的自我保护机制：Eureka Server在短时间内丢失比较多的客户端时，会进入自我保护模式，在该模式下，Eureka Server即使发现服务实例已经不再发送心跳了，也不会从服务注册表中删除。这样，当发生网络故障时，服务注册信息仍然存于Eureka中，当网络故障恢复后，会自动退出自我保护模式。自我保护模式是一种应对网络异常的安全保护机制。相关配置： eureka.server.renewal-percent-threshold， 触发自我保护机制的阈值，默认为0.85； eureka.server.enable-self-preservation， 自我保护开启，默认为true，如果设置为false，则关闭客户端程序后，可直观地从Eureka Server的页面发现服务实例被注销删除了。 本文示例代码","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://blog.jboost.cn/categories/SpringCloud/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://blog.jboost.cn/tags/SpringCloud/"}]},{"title":"Docker笔记（十二）：Docker Compose入门","slug":"docker-12","date":"2019-11-20T11:09:23.000Z","updated":"2019-11-20T04:11:18.335Z","comments":true,"path":"docker-12.html","link":"","permalink":"http://blog.jboost.cn/docker-12.html","excerpt":"","text":"1. Compose简介Docker Compose是Docker官方的用于对Docker容器集群实现编排，快速部署分布式应用的开源项目。Docker Compose通过docker-compose.yml文件来定义一组相关联的应用容器的编排，这组相关联的应用容器一般通过互相交互作为一个整体项目提供服务，比如一个Web项目，既包含业务服务容器，也包含数据库服务容器与缓存服务容器等。 Compose中两个重要的概念： 服务（service）： 包含多个运行相同镜像的容器实例 项目（project）： 由一组关联的应用容器（服务）组成一个完整的业务服务单元，在docker-compose.yml（即Compose的模板文件）中定义 Copmpose项目由Python编写，通过调用Docker服务提供的API来对容器进行管理。Compose默认的管理对象是项目，可以通过子命令对项目中的一组容器进行生命周期管理。 2. Compose安装在macOS与Win10下，Docker安装自带了docker-compose的二进制文件，可以直接使用。Linux下，123[root@iZwz ~]# curl -L \"https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose[root@iZwz ~]# chmod +x /usr/local/bin/docker-compose 验证12345[root@iZwz ~]# docker-compose versiondocker-compose version 1.24.1, build 4667896bdocker-py version: 3.7.3CPython version: 3.6.8OpenSSL version: OpenSSL 1.1.0j 20 Nov 2018 3. Compose模板文件模板文件是使用Compose的核心，定义了一组相关联的应用容器，使之构成一个项目，里面大部分指令跟docker run相关参数的含义是类似的。默认的模板文件名称为docker-compose.yml，为YAML格式，如12345678910111213version: '3'services: web: build: . depends_on: - db - redis redis: image: redis db: image: mysql Compose模板文件可以动态读取主机的系统环境变量与当前目录下.env文件中的变量，通过${xx}引用。 模板文件中的常用指令说明 build指定Dockerfile所在文件夹的路径，可以是绝对路径或相对模板文件的路径。Compose将会自动构建镜像，然后使用该镜像。也可以通过如下方式详细指定。cache_from指定构建镜像的缓存 12345678build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1 cache_from: - alpine:latest - corp/web_app:3.14 command覆盖容器启动后默认执行的命令。 container_nameCompose默认会使用 项目名称服务名称序号的格式作为容器名称。一般不需要特别指定，因为指定具体名称后，服务将无法进行扩展（scale），因为不允许多个容器具有相同的名称。 depends_on解决容器的依赖、启动先后顺序的问题，但是服务不会等待依赖的服务“完全启动”之后才启动。 env_file指定环境变量定义文件，可以为单独文件路径或列表，当与environment中有同名冲突时，以environment为准。 environment设置环境变量，支持数组或字典两种格式。只有名称的变量会自动获取运行Compose主机上的对应变量的值，以防止信息泄露 1234567environment: RACK_ENV: development SESSION_SECRET:environment: - RACK_ENV=development - SESSION_SECRET expose暴露端口，不映射到宿主机，只被连接的服务访问 healthcheck通过命令检查容器是否健康运行，如 12345healthcheck: test: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"] interval: 1m30s timeout: 10s retries: 3 image指定镜像名称或镜像ID，所有服务都必要要么通过build，要么通过image来指定镜像。 labels为容器添加Docker元数据信息 network_mode设置网络模式，与docker run的–network一样，如bridge，host，none等，也可以是如下形式 12network_mode: \"service:[service name]\"network_mode: \"container:[container name/id]\" networks配置容器连接的网络，如 12345678services: service1: networks: - some-network - other-networknetworks: some-network: other-network: ports暴露端口信息，遵循端口映射规则。 secrets存储敏感数据，如密码等信息 12345678910111213mysql: image: mysql environment: MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password secrets: - db_root_password - my_other_secretsecrets: my_secret: file: ./my_secret.txt my_other_secret: external: true volumes容器的数据卷挂在路径设置，可以设置多个，与docker -v类似，如 1234volumes: - /var/lib/mysql - cache/:/tmp/cache - ~/configs:/etc/configs/:ro 4. Compose命令Compose命令默认是针对项目本身，也可以指定为项目中的服务或容器。docker-compose 命令的基本使用格式为1docker-compose [-f=&lt;arg&gt;...] [options] [COMMAND] [ARGS...] 命令选项 -f, –file 指定模板文件，默认为docker-compose.yml，可多次指定 -p, –project-name 指定项目名称，默认为所在目录名称 –x-networking 使用Docker的可插拔网络特性 –x-networking-driver 指定网络驱动，默认为bridge –verbose 输出更多调试信息 -v, –version 打印版本信息 命令使用说明 build 格式为docker-compose build [options] [SERVICE...]，构建项目中的服务容器，选项包括 –force-rm（删除构建过程中的临时容器），–no-cache（构建镜像过程不使用cache），–pull（始终尝试通过pull来获取最新版本镜像） config 验证模板文件格式是否正确 down 停止up命令启动的容器，并移除网络 exec 进入指定的容器 images 列出compose文件中包含的镜像 kill 格式为docker-compose kill [options] [SERVICE...]，强制停止服务容器 logs 格式为docker-compose logs [options] [SERVICE...]，查看服务容器的输出 pause 格式为docker-compose pause [SERVICE...]， 暂停一个服务容器 port 格式为docker-compose port [options] SERVICE PRIVATE_PORT，打印容器端口所映射的公共端口，–index=index（指定容器序号，默认为1） ps 格式为docker-compose ps [options] [SERVICE...]，列出项目中目前的所有容器 pull 格式为docker-compose pull [options] [SERVICE...]，拉去服务依赖的镜像 push 推送服务依赖的镜像到Docker镜像仓库 restart 重启项目中服务，格式为docker-compose restart [options] [SERVICE...] rm 删除所有停止的服务容器，格式docker-compose rm [options] [SERVICE...]， -f（强制直接删除） run 在指定服务上执行一个命令，不会自动创建端口，以避免冲突 scale 格式docker-compose scale [options] [SERVICE=NUM...]，设置指定服务运行的容器个数，少则新建，多则删除 start 格式docker-compose start [SERVICE...]，启动已经存在的服务容器 stop 停止运行中的容器 top 查看各个服务容器内运行的进程 unpause 格式docker-compose unpause [SERVICE...]，恢复处于暂停状态的服务 up 格式docker-compose up [options] [SERVICE...]，尝试自动完成包括构建镜像，创建服务，启动服务，关联服务相关容器的一系列操作，大部分时候都可以通过该命令来启动一个项目，-d（在后台启动所有容器）。docker-compose up --no-recreate只启动处于停止状态的容器，忽略已经运行的服务，docker-compose up --no-deps -d &lt;SERVICE_NAME&gt;重新创建服务，但不影响到它所依赖的服务 5. 总结Compose是Docker官方的服务容器编排工具，对一些简单的但包含多个组件的服务可以借助Compose来快速搭建环境，如开源的错误监控系统sentry，包括sentry服务本身，redis，postgres。对于业务生产环境，则一般使用功能更为丰富的第三方编排系统如Kubernetes来部署。 欢迎关注我的微信公众号：jboost-ksxy———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"}]},{"title":"软件系统的非功能要素与设计思路","slug":"arch-1","date":"2019-11-15T10:56:54.000Z","updated":"2019-11-15T02:04:14.490Z","comments":true,"path":"arch-1.html","link":"","permalink":"http://blog.jboost.cn/arch-1.html","excerpt":"对于具备一定复杂度的软件系统，我们一般都会进行架构设计。架构设计中涉及功能要素与非功能要素，功能要素对应业务需求，关注需要实现的业务模块与功能，非功能要素对应系统本身的运行需求，一般包括性能、可用性、可伸缩性、可扩展性、安全等几个方面，软件系统的非功能架构设计，就是通过一些技术手段来满足这几个方面的运行需求。","text":"对于具备一定复杂度的软件系统，我们一般都会进行架构设计。架构设计中涉及功能要素与非功能要素，功能要素对应业务需求，关注需要实现的业务模块与功能，非功能要素对应系统本身的运行需求，一般包括性能、可用性、可伸缩性、可扩展性、安全等几个方面，软件系统的非功能架构设计，就是通过一些技术手段来满足这几个方面的运行需求。 一. 性能性能直观表现就是用户使用系统时响应的快慢程度。一般有响应时间（如用户点击一个按钮经服务端处理后，收到反馈的时长）、吞吐量（系统单位时间内能处理事务的个数，TPS —— Transaction-Per-Second）、支持并发数（能支持同时处理多少个并发在线用户）等衡量指标。 系统性能可通过相应的测试进行评估，一般包括： 性能测试：验证系统在资源可接受范围内，是否能达到性能预期。比如2核8G的服务器配置，在CPU负载不超过指定值的情况下，系统的吞吐量能否达到1k。 负载测试：不断给系统增加并发请求以增加对系统的压力，直到系统的某项或多项性能指标达到安全临界值。这时候，继续增加压力，系统的处理能力如吞吐量不增反降。 压力测试：在超过安全负载的情况下，继续对系统施加压力，直到系统崩溃或不能再处理任何请求，即系统在达到崩溃临界点时最大能承受多大的压力。 稳定测试：在模拟生产环境的场景下，包括软硬件配置、网络环境等条件，加载一定的业务压力（业务压力也尽量模拟生产环境下的情况），运行一段比较长的时间，看系统是否能稳定地运行。 测试报告形如下表 并发数 响应时间（ms） TPS 错误率（%） CPU负载 内存使用（GB） 性能测试 10 500 20 0 5 8 性能测试 30 1000 40 2 15 14 负载测试 40 1200 45 20 30 16 压力测试 60 2000 30 40 50 16 压力测试 80 超时 0 100 - - 系统高性能的设计思路： 客户端优化，包括浏览器缓存（App本地缓存）、静态资源压缩、减少Cookie传输，减少HTTP请求（合并接口）等。 缓存，包括CDN缓存与服务端缓存。CDN将静态内容分发至离用户最近的网络服务商机房，通过反向代理服务器，缓存热点资源，从而加快用户请求的响应速度，减轻后端服务的负载压力；服务端缓存通过本地缓存与分布式缓存，缓存热点数据，从而加快数据请求过程，减轻数据库的负载压力。 异步，对不需要立即获取结果的操作异步化，减少用户响应时间，改善系统的可扩展性与性能。异步一般通过消息队列实现。 集群，将同一个服务使用多个实例通过负载均衡来提高服务的整体处理能力。集群需要服务实现无状态化，即对每一个请求的处理在服务本地不保留任何数据与状态。 代码优化，多线程，资源服用（数据库连接池、线程池、HTTP连接池等），减少HTTP及数据库访问次数（如避免在循环中调用数据库访问，可优化成一次获取数据到本地再处理）。 数据库访问，索引的使用，读写分离，分库分表，NoSQL的引入，存储结构优化等。 二. 可用性系统的高可用就是当系统的某个服务器宕机时，系统服务或系统的核心服务依然可用。 对于互联网服务，一般要求7*24小时提供不间断的服务能力。系统的可用性一般就通过服务可用时间比来衡量，如三个9的可用性，就是在一段考核时间内，99.9%的时间服务可用。 系统高可用的设计主要通过冗余与失效转移的手段来实现： 冗余，在系统的每一层，都通过部署多台服务器以负载均衡的形式提供访问（集群的形式），避免单点问题。关系型数据库无法通过集群部署，可提供多台互相备份，在主服务挂掉时，从服务能快速切换。 失效转移，在集群中其中一台服务器出现故障时，负载均衡能实时监测到并且不再往这台服务器分发请求，已失败的请求能重新调度到其它可用服务器。 提高系统高可用也需要在开发测试阶段尽可能地进行质量保证，通过代码review，多维度测试，预发布验证，灰度发布等手段，来减少生产环境的bug引入率，提高系统的可用性。同时，在各环节添加必要的监控与告警，包括服务器资源、网络、应用等多个维度，当问题发生时能及时获得告警通知。即一方面通过多种途径规避问题的发生，另一方面当问题真正发生时，能快速响应尽可能减少影响。 三. 可伸缩性可伸缩性是从提升系统服务能力的角度衡量的一个因素，如果能通过不断向集群中加入服务器就能提高系统的处理能力，来应对不断增长的用户并发访问，则系统是具有可伸缩性的。 系统可伸缩性的设计思路： 应用服务无状态化，对任何一个请求集群中任何一台服务器处理都能做到无差异化。 缓存服务器的伸缩可能导致缓存路由失效，可通过一致性Hash算法来降低缓存路由失效的比率。 关系型数据库很难通过集群实现可伸缩性，需要在数据库之外实现，如分库分表（不到万不得已不要使用分表）。 NoSQL，本身就具备良好的伸缩性，如HDFS。 四. 可扩展性系统的可扩展性关注功能性需求，衡量系统能否快速响应需求变化，即增加一个功能基本不需要修改现有系统或调整很少。 系统可扩展性的设计思路： 解耦，事件驱动架构，生产者、消费者模式，如基于消息队列 拆分，将复杂业务拆分成简单的职责单一的，高内聚、低耦合的服务单元，新增服务对现有服务影响不大 复用，将比较固定的不常变动的服务下沉作为基础服务，新的业务功能基于基础服务的复用实现 开放服务，将平台服务能力通过开放接口的形式提供给第三方，拓展平台业务服务能力 五. 安全攻击无处不在，衡量系统安全性的标准是系统针对现有的与潜在的各种攻击与窃密手段，是否有相应的可靠的应对策略。 系统的安全保障设计思路： 信息加密，包括单项散列加密（如密码加密，MD5，SHA）、对称加密、非对称加密（公钥私钥，https传输） 信息过滤，如敏感词过滤，黑名单机制等 风险控制，通过规则引擎控制访问，或基于统计模型进行监控告警 限流，限制单位时间内的访问量，如手机验证码 安全是相对的，没有绝对安全的系统，只能通过一些保障手段使攻击成本大于其获利成本来保障系统免受攻击。 六. 总结本文主要参考《大型网站技术架构》，对软件系统的几个核心的非功能性要素及其设计思路进行了介绍与总结，为软件系统的设计提供参考。 ———————————————————————————————————————————————欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"Architecture","slug":"Architecture","permalink":"http://blog.jboost.cn/categories/Architecture/"}],"tags":[{"name":"arch","slug":"arch","permalink":"http://blog.jboost.cn/tags/arch/"}]},{"title":"Spring Boot（十二）：LocalDateTime格式化处理","slug":"springboot-localdatetime","date":"2019-11-01T09:37:24.000Z","updated":"2019-11-01T10:08:21.753Z","comments":true,"path":"springboot-localdatetime.html","link":"","permalink":"http://blog.jboost.cn/springboot-localdatetime.html","excerpt":"Java 8之后，日期类的处理建议使用java.time包中对应的LocalDateTime, LocalDate, LocalTime类。（参考Java8新特性）","text":"Java 8之后，日期类的处理建议使用java.time包中对应的LocalDateTime, LocalDate, LocalTime类。（参考Java8新特性） 在Spring Boot中（验证版本：2.1.5.RELEASE），日期类的序列化格式可能不是自己所希望的，需要定义为自己的格式。有两种方式实现。 1. 注解方式分别使用 @JsonFormat， @DateTimeFormat 来定义序列化（bean转json）与反序列（json转bean）时的格式，如 123@JsonFormat(pattern = \"yyyy-MM-dd HH:mm:ss\")@DateTimeFormat(pattern = \"yyyy-MM-dd HH:mm:ss\")private LocalDateTime dateTime; 2. 统一配置方式定义一个配置类，对ObjectMapper对象进行定制，指定日期类对应的序列化与反序列化处理对象，如 123456789101112131415161718192021@Configurationpublic class LocalDateTimeFormatConfig &#123; private static final String DEFAULT_DATE_TIME_PATTERN = \"yyyy-MM-dd HH:mm:ss\"; private static final String DEFAULT_DATE_PATTERN = \"yyyy-MM-dd\"; private static final String DEFAULT_TIME_PATTERN = \"HH:mm:ss\"; @Bean @Primary public ObjectMapper objectMapper()&#123; ObjectMapper objectMapper = new ObjectMapper(); JavaTimeModule javaTimeModule = new JavaTimeModule(); javaTimeModule.addSerializer(LocalDateTime.class, new LocalDateTimeSerializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_TIME_PATTERN))); javaTimeModule.addSerializer(LocalDate.class, new LocalDateSerializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_PATTERN))); javaTimeModule.addSerializer(LocalTime.class, new LocalTimeSerializer(DateTimeFormatter.ofPattern(DEFAULT_TIME_PATTERN))); javaTimeModule.addDeserializer(LocalDateTime.class, new LocalDateTimeDeserializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_TIME_PATTERN))); javaTimeModule.addDeserializer(LocalDate.class, new LocalDateDeserializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_PATTERN))); javaTimeModule.addDeserializer(LocalTime.class, new LocalTimeDeserializer(DateTimeFormatter.ofPattern(DEFAULT_TIME_PATTERN))); objectMapper.registerModule(javaTimeModule); return objectMapper; &#125;&#125; 3. 总结注解的方式需要在每个属性上进行标注，如果日期类属性较多则较为繁琐，自定义配置类方式可以对日期进行统一的格式化处理。两者都存在的情况下，以注解为准，即注解方式会覆盖统一配置方式。 ——————————————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"nginx（一）：基本用途与用法","slug":"nginx-1","date":"2019-10-07T05:34:02.000Z","updated":"2019-11-01T07:45:53.758Z","comments":true,"path":"nginx-1.html","link":"","permalink":"http://blog.jboost.cn/nginx-1.html","excerpt":"最近由于事情较多，加上个人的懈怠，有一段时间没更新了。习惯的养成很难，但一旦养成，从中的受益也常会超乎意料，还是得坚持。接下来准备对一些开发维护过程中常用的工具软件与服务进行整理，如本系列的nginx，后续的redis，消息队列，jenkins等，欢迎关注。 nginx是一个轻量级的高性能的HTTP服务器，在Web应用部署中很常见。也正因为很常见，所以掌握其基本原理与用法显得很有必要，本系列文章对nginx的相关内容进行梳理，以供初学者参考、熟悉者回顾。","text":"最近由于事情较多，加上个人的懈怠，有一段时间没更新了。习惯的养成很难，但一旦养成，从中的受益也常会超乎意料，还是得坚持。接下来准备对一些开发维护过程中常用的工具软件与服务进行整理，如本系列的nginx，后续的redis，消息队列，jenkins等，欢迎关注。 nginx是一个轻量级的高性能的HTTP服务器，在Web应用部署中很常见。也正因为很常见，所以掌握其基本原理与用法显得很有必要，本系列文章对nginx的相关内容进行梳理，以供初学者参考、熟悉者回顾。 1. 简介在nginx以前，比较流行的HTTP服务器应属Apache（LAMP中A就是指Apache）。但根据netcraft的调查显示，近两年nginx已经超越Apache，成为市场占有率第一的HTTP服务器。如下图 nginx能战胜Apache有几个主要原因，一是其足够轻量，不管是安装与维护，还是资源的占用都非常简单与轻量；二是其高性能，nginx基于事件驱动机制，具备非常好的性能，据称能支持高达50000个并发连接数；三是其具有很高的稳定性，相对其它HTTP服务器在访问负载很高时会导致内存耗尽进而可能失去响应，nginx采用分阶段资源分配技术，CPU与内存占有率都很低，在高并发场景下，稳定性更高。 在日常使用中，nginx主要在三个方面为我们提供服务： 作为静态服务器提供静态资源的访问，如html网站，文件等 为后端服务提供反向代理 为反向代理的后端服务集群提供负载均衡 2. 静态服务器静态服务器一般就是提供Web前端的一些静态资源，如html页面，js、css文件的访问，用法配置示例如下 123456789server &#123; listen 80; server_name localhost; location /static/ &#123; index index.html index.htm; alias /usr/local/nginx/html/garten-web/dist/; &#125;&#125; 其中 index指定网站的初始页，可以跟多个文件，空格隔开，nginx根据顺序检查文件是否存在，如上例如果用户直接输入/static则会访问/usr/local/nginx/html/garten-web/dist/index.html（如果不存在则再看index.htm是否存在） alias是与root对应的用法，都用于访问本地文件系统的资源，在匹配到location配置的url路径后，在alias或root配置的目录寻找对应的资源，区别在于：alias就在配置的目录下寻找对应的资源，而root则会将location配置路径附加到root路径后，在拼接后的目录下寻找对应的资源。如上例中访问 /static/hello.html，使用alias则会访问到/usr/local/nginx/html/garten-web/dist/hello.html，使用root则会访问到/usr/local/nginx/html/garten-web/dist/static/hello.html alias配置的目录后有没有“/”要与location后面的路径是否有“/”保持一致，否则找不到资源 3. 反向代理了解反向代理之前先看看什么是正向代理。 举个不那么和谐的例子，当你需要访问某些国外网站的时候，直接输入域名是打不开的，这时可以找一台能访问这些网站的服务器来做代理（这台服务器能访问你访问不了的网站，你能访问这台服务器），你访问网站时，实际是通过代理来中转访问。这种情况，你是知道目标网站的地址的，但是服务器只知道请求来自于代理服务器，而不知道是你（真正的客户端）在访问，所以正向代理代理的是客户端，是对服务端隐藏了真实的客户端信息。 而对于反向代理，客户端是明确的，但具体在后端请求了哪个服务却不明确了，比如你请求的是 www.abc.com， 在反向代理端，它可能是 www.cba.com 的代理，也可能是 www.ccc.com 的代理， 不看配置你是不知道它到底代理的谁。因此，反向代理代理的是服务器端，隐藏了服务端的信息。 nginx中配置反向代理很简单，如下12345678server &#123; listen 80; server_name localhost; location /api/ &#123; proxy_pass http://192.168.0.120:8080/; &#125;&#125; 使用nginx的反向代理，可以解决两个问题： 跨域问题：前后端分离情况下，前端网页访问后端接口存在跨域问题，对后端接口的访问统一通过前端网站域名访问，在nginx中通过对接口的路径进行匹配后反向代理到后端接口服务。如上例中访问接口login可通过 http://localhost/api/login 访问，nginx将会反向代理到 http://192.168.0.120:8080/login 后端接口地址 负载均衡：如果后端服务部署的是服务器集群，则对服务的访问需要做负载均衡，nginx通过反向代理结合upstream来实现负载均衡 反向代理的路径路由规则：如果proxy_pass配置的路径最后带“/”，则类似于alias，不会在proxy_pass的uri后面拼接location的路径，如果没带“/”，则会进行拼接，类似于root。比如我们按上例配置访问 http://localhost/api/login 则代理到 http://192.168.0.120:8080/login 但如果是按以下配置（proxy_pass配置路径不带子路径，且后面没带“/”），123location /api/ &#123; proxy_pass http://192.168.0.120:8080;&#125; 则会被代理到 http://192.168.0.120:8080/api/login， 将location的路径拼接了。 如果proxy_pass配置的路径带子路径，如123location /api/ &#123; proxy_pass http://192.168.0.120:8080/api/;&#125; 则不管后面带不带“/”，都不会拼接location的路径，只是与/api/后面的部分进行拼接。 注意：如果是不带“/” proxy_pass http://192.168.0.120:8080/api/login 则会被代理到 proxy_pass http://192.168.0.120:8080/apilogin 了， 这时，可通过将location与proxy_pass配置路径保持一致即可——要么都带“/”，要么都不带。 4. 负载均衡nginx通过反向代理proxy_pass结合upstream来对后端服务器集群实现负载均衡，在nginx配置的http节点下定义upstream，如1234upstream backend &#123; server 192.168.0.120:8080; server 192.168.0.121:8080;&#125; 然后在server节点下的location里配置反向代理，如123location /api/ &#123; proxy_pass http://backend/api/;&#125; 这样就会将接收到的请求顺序循环分配到后端的服务器上，如果某个服务器宕机，也能自动将其剔除，不再分配请求，直到其恢复。这是默认的负载均衡策略，即轮询策略。 nginx负载均衡的策略包括: 权重轮询，权重轮询在上述轮询策略的基础上加了服务器的请求分配权重，以根据服务器配置的不同，将更多的请求分配到配置更高的服务器上。如1234upstream backend &#123; server 192.168.0.120:8080 weight=10; server 192.168.0.121:8080 weight=20;&#125; 分配给121的请求将比分配给120的请求多一倍。 ip_hash，通过对请求来源ip求hash值，将相同ip的请求分配到相同的服务器上，此种策略可以解决分布式session的问题。配置如 12345upstream backend &#123; ip_hash; server 192.168.0.120:8080; server 192.168.0.121:8080;&#125; url_hash，对访问url求hash值，将同一个url的请求分配到相同的服务器上，对有本地缓存的场景比较适用。配置如 123456upstream backend &#123; server 192.168.0.120:8080; server 192.168.0.121:8080; hash $request_uri; hash_method crc32;&#125; hash_method指定hash算法 fair，根据后端服务器的响应时间来合理分配请求，响应时间短的优先分配。配置如12345upstream backend &#123; server 192.168.0.120:8080; server 192.168.0.121:8080; fair;&#125; 5. 总结nginx以其轻量级、高性能、高稳定性的特性成为HTTP服务器的主流，是不论开发者还是运维人员都必须了解掌握的服务软件。本文从静态服务器，反向代理，负载均衡三个日常使用场景的角度对nginx进行了简单介绍。 欢迎关注我的微信公众号：jboost-ksxy———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://blog.jboost.cn/tags/nginx/"}]},{"title":"Docker笔记（十一）：Dockerfile详解与最佳实践","slug":"docker-11","date":"2019-09-21T10:55:26.000Z","updated":"2019-09-23T07:54:04.498Z","comments":true,"path":"docker-11.html","link":"","permalink":"http://blog.jboost.cn/docker-11.html","excerpt":"Dockerfile是一个文本文件，包含了一条条指令，每条指令对应构建一层镜像，Docker基于它来构建一个完整镜像。本文介绍Dockerfile的常用指令及相应的最佳实践建议。","text":"Dockerfile是一个文本文件，包含了一条条指令，每条指令对应构建一层镜像，Docker基于它来构建一个完整镜像。本文介绍Dockerfile的常用指令及相应的最佳实践建议。 1. 理解构建上下文（build context）Docker镜像通过docker build指令构建，该指令执行时当前的工作目录就是docker构建的上下文，即build context，上下文中的文件及目录都会作为构建上下文内容发送给Docker Daemon。 1docker build --no-cache -t helloapp:v2 -f dockerfiles/Dockerfile context 如上 –no-cache 表示镜像构建时不使用缓存，-f 指定Dockerfile文件位置， context 指定build context目录。 将一些非必要的文件包含到build context中，会导致build context过大，从而导致镜像过大，会增加镜像构建、推送及拉取的时间，以及容器运行时的大小。 执行docker build时会显示build context的大小，1Sending build context to Docker daemon 187.8MB 最佳实践建议 使用.dockerignore来排除不需要加入到build context中的文件，类似于.gitignore 不要安装不必要的包，所有包含的东西都是镜像必须的，非必须的不要包含。 解耦应用，如果应用有分层，解耦应用到多个容器，便于横向扩展，如web应用程序栈包含web服务应用，数据库，缓存等。 最少化镜像层数：只有RUN、COPY、ADD指令会创建镜像层，其它指令创建临时的中间镜像，不会增大镜像构建的大小 如果可能，尽可能使用多阶段构建，只复制你需要的组件到最终镜像，这使得你可以在中间构建阶段包含工具与debug信息，同时又不会增大最终镜像的大小。 排序多行参数：将参数按字母排序，有利于避免包重复，及后续的维护与提高易读性 2. FROM作用FROM指定基础镜像，每一个定制镜像，必须以一个现有镜像为基础。因此一个Dockerfile中FROM是必须的指令，并且必须是第一条。使用格式， 123FROM &lt;image&gt;:&lt;tag&gt;# 注释以#开头。基础镜像的tag可不指定，默认使用latest# 示例：FROM mysql:5.7 最佳实践建议 如果不想以任何镜像为基础，则可以使用FROM scratch 尽量使用官方镜像作为基础镜像 推荐使用Alpine镜像，因为它足够轻量级（小于5MB），但麻雀虽小五脏俱全，基本具有Linux的基础功能 3. RUN作用用来执行命令行命令，是最常用的指令之一。使用格式， 123456# shell格式，跟直接在命令行输入命令一行RUN &lt;命令&gt;# 示例：RUN mkdir -p /usr/src/redis # exec格式，类似于函数调用RUN [\"可执行文件\", \"参数1\", \"参数2\"] RUN指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像，可以在构建指令中指定–no-cache参数，如：docker build --no-cache 最佳实践建议 将比较长的复杂的指令通过 \\ 分为多行，让Dockerfile文件可读性、可理解性、可维护性更高，将多个指令通过 &amp;&amp; 连接，减少镜像的层数 确保每一层只添加必需的东西，任何无关的东西都应该清理掉，如所有下载、展开的文件，apt 缓存文件等，以尽可能减少镜像各层的大小 将RUN apt-get update 与 RUN apt-get install 组合成一条RUN指令（将apt-get update单独作为一条指令会因为缓存问题导致后续的apt-get install 指令失败） 比如先按如下Dockerfile创建了一个镜像 123FROM ubuntu:18.04RUN apt-get updateRUN apt-get install -y curl 一段时间后，再按以下Dockerfile创建另一个镜像 123FROM ubuntu:18.04RUN apt-get updateRUN apt-get install -y curl nginx 因为RUN指令创建的镜像层会被缓存，所以下面镜像的RUN apt-get update并不会执行，直接使用了前面构建的镜像层，这样，curl、nginx就可能安装已经过时的版本。 因此 在 apt-get update 之后立即接 &amp;&amp; apt-get install -y ，这叫做“ cache busting”（缓存破坏），也可以通过指定包的版本，来达到同样的目的，这叫“ version pinning” （版本指定）示例：123456RUN apt-get update &amp;&amp; apt-get install -y \\ reprepro \\ ruby1.9.1 \\ ruby1.9.1-dev \\ #删除apt 缓存减少镜像层的大小 &amp;&amp; rm -rf /var/lib/apt/lists/* 使用管道（pipes）。一些RUN指令依赖于从一个指令管道输出到另一个，如1RUN wget -O - https://some.site | wc -l &gt; /number Docker使用/bin/sh -c 解释器来执行这些指令，只会评估管道最后一条命令的退出码来确定是否成功，如上例中只要wc -l成功了就算wget失败，也会认为是成功的。如果要使管道命令的任何一步报错都导致指令失败，则可通过加 set -o pipefile &amp;&amp; 来实现，如1RUN set -o pipefail &amp;&amp; wget -O - https://some.site | wc -l &gt; /number 不是所有的shell都支持-o pipefail选项，如果不支持的话可以使用如下形式，显式地指定一个支持的shell1RUN [\"/bin/bash\", \"-c\", \"set -o pipefail &amp;&amp; wget -O - https://some.site | wc -l &gt; /number\"] 4. COPY | ADD作用COPY从构建上下文的目录中复制文件/目录到镜像层的目标路径。使用格式， 12COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;源路径&gt;... &lt;目标路径&gt; COPY [--chown=&lt;user&gt;:&lt;group&gt;] [\"&lt;源路径1&gt;\",... \"&lt;目标路径&gt;\"] 同RUN一样，也有两种格式。源文件可以多个，甚至可以是通配符，目标路径是容器的绝对路径，可以是相对工作目录（WORKDIR指定）的相对路径，目标路径不存在时会自动创建。使用--chown=&lt;user&gt;:&lt;group&gt;来改变文件的所属用户与组。ADD与COPY的使用格式与性质差不多，但功能更丰富，如源路径可以是URL（下载后放到目标路径下，文件权限为600），也可以为tar压缩包，压缩格式为gzip，bzip2及xz的情况下，ADD 指令将会自动解压缩这个压缩文件到目标路径去 最佳实践建议 如果在Dockerfile中有多处需要使用不同的文件，分别使用COPY，而不是一次性COPY所有的，这可以保证每一步的构建缓存只会在对应文件改变时，才会失效。比如123COPY requirements.txt /tmp/RUN pip install --requirement /tmp/requirements.txtCOPY . /tmp/ 如果把COPY . /tmp/ 放在RUN上面，将使RUN层镜像缓存失效的场景更多——因为 . 目录（当前目录）中任何一个文件的改变都会导致缓存失效。 因为镜像大小的原因， 使用ADD来获取远程包是非常不推荐的，应该使用curl或wget，这种方式可以在不再需要使用时删除对应文件，而不需要增加额外的层，如，应避免如下用法123ADD http://example.com/big.tar.xz /usr/src/things/RUN tar -xJf /usr/src/things/big.tar.xz -C /usr/src/thingsRUN make -C /usr/src/things all 而应使用1234RUN mkdir -p /usr/src/things \\ &amp;&amp; curl -SL http://example.com/big.tar.xz \\ | tar -xJC /usr/src/things \\ &amp;&amp; make -C /usr/src/things all 如果不需要使用ADD的自动解压特性，尽量使用COPY（语义更清晰） 5. CMD作用CMD指定容器的启动命令。容器实质就是进程，进程就需要启动命令及参数，CMD指令就是用于指定默认的容器主进程的启动命令的。使用格式123456# shell格式 CMD &lt;命令&gt;# exec格式CMD [\"可执行文件\", \"参数1\", \"参数2\"...]# 参数列表格式，在指定了ENTRYPOINT指令后，用CMD来指定具体的参数CMD [\"参数1\", \"参数2\"...] 在容器运行时可以指定新的命令来覆盖Dockerfile中设置的这个默认命令 最佳实践建议 服务类镜像建议：CMD [&quot;apache2&quot;,&quot;-DFOREGROUND&quot;]，CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] 容器进程都应以前台运行，不能以后台服务的形式运行，否则启动就退出了。 其它镜像，建议给一个交互式的shell，如bash，python，perl等：CMD [&quot;python&quot;], CMD [&quot;php&quot;, &quot;-a&quot;] 6. ENTRYPOINT作用ENTRYPOINT的目的和CMD一样，都是在指定容器启动是要运行的程序及参数。 ENTRYPOINT在运行时也可以替代，不过比CMD要略显繁琐，需要通过docker run的参数 –entrypoint 来指定。如果指定了ENTRYPOINT，则CMD将只是提供参数，传递给ENTRYPOINT。使用ENTRYPOINT可以在容器运行时直接为默认启动程序添加参数。 与RUN指令格式一样，ENTRYPOINT也分为exec格式和shell格式。 最佳实践建议 ENTRYPOINT可用来指定镜像的主命令，允许镜像能像命令一样运行，可以使用CMD来作为默认的标志（参数），如12ENTRYPOINT [\"s3cmd\"]CMD [\"--help\"] 直接run时，相当于执行了s3cmd --help。也可以使用shell脚本，在脚本中做一些预处理的工作，如123COPY ./docker-entrypoint.sh /ENTRYPOINT [\"/docker-entrypoint.sh\"]CMD [\"postgres\"] 7. LABEL作用为镜像添加label以方便组织镜像，记录licensce信息，帮助自动化实现等等。字符串中包含空格需要转义或包含在引号中， 如 123456789101112131415# Set one or more individual labelsLABEL com.example.version=\"0.0.1-beta\"LABEL vendor1=\"ACME Incorporated\"LABEL com.example.release-date=\"2019-09-12\"LABEL com.example.version.is-production=\"\"# Set multiple labels on one lineLABEL com.example.version=\"0.0.1-beta\" com.example.release-date=\"2019-09-12\"# Set multiple labels at once, using line-continuation characters to break long linesLABEL vendor=ACME\\ Incorporated \\ com.example.is-beta= \\ com.example.is-production=\"\" \\ com.example.version=\"0.0.1-beta\" \\ com.example.release-date=\"2019-09-12\" 8. ENV作用ENV设置环境变量，无论是后面的其它指令，如 RUN（使用 $环境变量key 的形式） ，还是运行时的应用，都可以直接使用这里定义的环境变量。 使用格式有两种，1234#只能设置一个key valueENV &lt;key&gt; &lt;value&gt;#可以设置多个，value中如果包含空格可以使用\\来进行转义，也可以通过\"\"括起来；也可以用反斜线来续行ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 除了RUN，还有这些指令可以引用环境变量：ADD 、 COPY 、 ENV 、 EXPOSE 、 LABEL 、 USER 、 WORKDIR 、 VOLUME 、STOPSIGNAL 、 ONBUILD 最佳实践建议 定义环境变量，更新PATH环境变量，如要使 CMD [“nginx”] 运行，可设置环境变量 ENV PATH /usr/local/nginx/bin:$PATH ENV也可以用于定义常量，便于维护 9. ARG作用ARG设置构建参数，即docker build命令时传入的参数。和ENV的效果差不多，都是设置环境变量，不同的是，ARG设置的是构建环境的环境变量，在容器运行时是不会存在这些环境变量的。Dockerfile中的ARG指令是定义参数名称，以及默认值（可选）。该默认值可以在执行构建命令docker build时用 –build-arg &lt;参数名&gt;=&lt;值&gt; 来覆盖。使用格式， 1ARG &lt;参数名&gt;[=&lt;默认值&gt;] 最佳实践建议 不要使用ARG来保存密码之类的信息，因为通过docker history还是可以看到docker build执行时的所有值 使用ARG，对于使用CI系统（持续集成），用同样的构建流程构建不同的 Dockerfile 的时候比较有帮助，避免构建命令必须根据每个 Dockerfile 的内容修改 10. WORKDIR作用WORKDIR用于指定工作目录（或当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，会自动创建。使用格式， 123456789101112131415WORKDIR &lt;工作目录路径&gt;``` **最佳实践建议**1. WORKDIR应该使用绝对路径，显得更为清楚、可靠2. 使用WORKDIR，避免使用`RUN cd … &amp;&amp; do-something`，可读性差，难以维护## 11. VOLUME**作用**VOLUME用于定义匿名卷。容器运行时应该尽量保持容器存储层不发生写操作，应该将数据写入存储卷。VOLUME就是为了防止运行时用户忘记将动态文件所保存的目录挂载为卷，我们事先在Dockerfile中指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会向容器存储层写入大量数据。使用格式，```shellVOLUME [\"&lt;路径1&gt;\", \"&lt;路径2&gt;\"...]VOLUME &lt;路径&gt; 如 VOLUME /data， 任何向/data目录写入的数据都会写入匿名卷。可以运行容器时覆盖这个挂载设置 docker run -d -v host-path:/data xxxx 最佳实践建议 VOLUME应该被用来暴露所有的数据存储，配置存储，或者被容器创建的文件、目录。 如果数据动态变化，强烈建议使用VOLUME。 12. EXPOSE作用EXPOSE指令是声明运行时容器提供的服务端口，也只是一个声明，在容器运行时并不会因为这个声明应用就一定会开启这个端口的服务,容器启动时，还是需要通过 -p host-port:container-port来实现映射。EXPOSE主要是帮助镜像使用者了解这个镜像服务的监听端口，以方便进行映射配置，另一个用处是在运行时如果是使用随机端口映射，也就是通过 docker run -P的形式时，会自动随机映射EXPOSE声明的端口。使用格式， 1234567891011121314EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...] ``` **最佳实践建议**1. 应该使用常用的惯用的端口，如nginx 80，mongoDB 27017## 13. USER**作用**USER指令和WORKDIR相似，都是改变环境状态并影响以后的层。 WORKDIR是改变工作目录， USER则是改变之后的层在执行RUN , CMD以及ENTRYPOINT这类命令时的身份。USER帮助你切换到指定的用户，这个用户必须是事先建立好的，否则无法切换。使用格式```shellUSER &lt;用户名&gt;[:&lt;用户组&gt;] 最佳实践建议 如果一个服务不需要权限也能运行，则使用USER来切换到非root用户，如RUN groupadd -r postgres &amp;&amp; useradd --no-log-init -r -g postgres postgres 避免使用sudo，因为可能存在一些不可预见的TTY与信号转发行为导致问题，如果实在需要，考虑使用“gosu”。为了减少镜像层数，应避免不断切换USER使用gosu示例 123456789# 建立 redis 用户，并使用 gosu 换另一个用户执行命令RUN groupadd -r redis &amp;&amp; useradd -r -g redis redis# 下载 gosuRUN wget -O /usr/local/bin/gosu \"https://github.com/tianon/gosu/releases/download/1.7/gosu-amd64\" \\&amp;&amp; chmod +x /usr/local/bin/gosu \\&amp;&amp; gosu nobody true# 设置 CMD，并以另外的用户执行CMD [ \"exec\", \"gosu\", \"redis\", \"redis-server\" ] 14. HEALTHCHECK作用HEALTHCHECK用于检查容器的健康状态，Docker可通过健康状态来决定是否对容器进行重新调度。使用格式 1HEALTHCHECK [选项] CMD &lt;命令&gt; 支持的选项为 –interval=&lt;间隔&gt; ：两次健康检查的间隔，默认为30秒 –timeout=&lt;时长&gt; ：执行健康检查命令的超时时间，如果超时，则本次健康检查就被视为失败，默认30秒 –retries=&lt;次数&gt; ：当连续失败指定的次数后，将容器状态置为unhealthy ，默认3次 命令的返回值决定了该次健康检查的成功与否—— 0 ：成功； 1 ：失败； 2 ：保留（不要使用这个值），如： 123456789101112131415161718192021FROM nginxRUN apt-get update &amp;&amp; apt-get install -y curl &amp;&amp; rm -rf /var/lib/apt/lists/*HEALTHCHECK --interval=5s --timeout=3s \\ CMD curl -fs http://localhost/ || exit 1``` 可以使用docker ps 或docker inspect来查看容器的健康状态。**最佳实践建议**1. 如果基础镜像有健康检查指令，想要屏蔽掉其健康检查，可以使用`HEALTHCHECK NONE`2. 对一些可能造成假死（进程还在， 但提供不了服务了）的服务建议提供健康检查，以便及时重新调度恢复服务## 15. ONBUILD**作用**ONBUILD后跟的指令，只有当以当前镜像为基础镜像，去构建下一级镜像的时候才会被执行。使用格式```shellONBUILD &lt;其它指令&gt; 它后面跟的是其它指令，比如 RUN , COPY 等，这些指令在当前镜像构建时并不会被执行。ONBUILD命令在本镜像的子镜像中执行，把ONBUILD想象为父镜像为子镜像声明的一条指令，Docker会在子镜像所有命令之前执行ONBUILD指令。 最佳实践建议 当在ONBUILD指令中使用ADD或COPY时要注意，如果build context中没有指定的资源，可能导致灾难性的错误。 16. 用缓存镜像提高效率Docker在构建镜像时会复用缓存中已经存在的镜像，如果明确不使用缓存，则可加参数docker build --no-cache=true使用缓存镜像的规则 从一个已存在于缓存的父镜像开始构建，则会将当前镜像的下一行指令与所有继承于那个父镜像的子镜像比较，如果其中没有一个是使用相同的指令构建的，则缓存失效 大部分情况下，将Dockerfile中的指令与其中一个子镜像简单比较就够了，但是某些指令需要更多的检查与说明：对于ADD，COPY指令，文件内容会被检查，会计算每一个文件的checksum，checksum中不会考虑最后修改及最后访问时间，在缓存中查找时，checksum会与已经存在的镜像进行比较，如果文件中有修改，则缓存失效。除了ADD，COPY命令，缓存检查不会查看容器中的文件来决定缓存匹配，如处理RUN apt-get -y update命令时，容器中文件的更新不会进行检查来确定缓存是否命中， 这种情况下， 只会检查指令字符串本身是否匹配。 一旦缓存失效，所有后续的指令都会产生新的镜像，不会再使用缓存。 17. 其它镜像构建方式 通过标准输入来生成Dockerfile构建，不会发送build context（从stdin读取build context，只包含Dockerfile），适用于一次性构建，不需要写Dockerfile12345678910111213# 将会构建一个名称与tag均为none的镜像echo -e 'FROM busybox\\nRUN echo \"hello world\"' | docker build -#或 docker build - &lt;&lt;EOFFROM busyboxRUN echo \"hello world\"EOF# 构建一个命名的镜像docker build -t myimage:latest - &lt;&lt;EOFFROM busyboxRUN echo \"hello world\"EOF 连字符 - 作为文件名告诉Docker从stdin读取Dockerfile 使用stdin来生成Dockerfile， 但是使用当前目录作为build context 123456# build an image using the current directory as context, and a Dockerfile passed through stdindocker build -t myimage:latest -f- . &lt;&lt;EOFFROM busyboxCOPY somefile.txt .RUN cat /somefile.txtEOF 使用远程git仓库构建镜像，从stdin生成Dockerfile 1234docker build -t myimage:latest -f - https://github.com/docker-library/hello-world.git &lt;&lt;EOFFROM busyboxCOPY hello.c .EOF 欢迎关注我的微信公众号：jboost-ksxy———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"}]},{"title":"JDK13，不如温习下Java8","slug":"jdk8","date":"2019-09-18T11:24:09.000Z","updated":"2019-09-18T11:36:40.834Z","comments":true,"path":"jdk8.html","link":"","permalink":"http://blog.jboost.cn/jdk8.html","excerpt":"JDK13于昨天正式GA，版本新特性可参考： https://www.oschina.net/news/109934/jdk-13-released","text":"JDK13于昨天正式GA，版本新特性可参考： https://www.oschina.net/news/109934/jdk-13-released 虽然JDK更新迅速，但开发者貌似并不买账，据统计，目前仍以JDK8使用最多，预计可能还会延续好长一段时间。虽然JDK版本已至13，但对Java8的新特性，掌握程度如何呢？本文对Java8的主要特性进行了梳理。供温习参考。 1. 接口默认方法以前的接口只允许有抽象方法（没有实现体），java8中提供了接口默认方法支持，即可以提供方法的默认实现，实现类可以直接继承，也可以覆盖。默认方法主要解决接口的修改导致现有实现类不兼容的问题。123456789101112131415161718192021222324252627282930@RunWith(SpringRunner.class)@SpringBootTestpublic class InterfaceDefaultFunctionTest &#123; public interface MyFunction&lt;T&gt; &#123; T func(T t); //默认方法 default int func2(T t)&#123; return t.hashCode(); &#125; //静态方法 static&lt;T&gt; void print(T t) &#123; System.out.println(t); &#125; &#125; @Test public void testInterface()&#123; MyFunction&lt;String&gt; myFunction = new MyFunction&lt;String&gt;()&#123; @Override public String func(String s) &#123; return s.toUpperCase(); &#125; &#125;; System.out.println(myFunction.func(\"abc\")); System.out.println(myFunction.func2(\"abc\")); LambdaTest.MyFunction.print(\"efg\"); &#125;&#125; 默认方法通过关键字 default 声明。同时也可以在接口中定义静态方法。 2. 函数式接口函数式接口就是有且仅有一个抽象方法的接口（可以有其它非抽象方法），如1所示代码中 MyFunction 就是一个函数式接口，只有一个抽象方法 func， 其它非抽象方法如默认方法 func2， 静态方法 print 不影响其函数式接口的特性。 函数式接口可以使用注解 @FunctionalInterface 标注，该注解会去检查接口是否符合函数式接口的规范要求，不符合的话IDE会给出提示。 java中内置了一些函数式接口， 函数式接口 描述 Consumer 包含方法 void accept(T t)， 对类型为T的对象t进行操作 Supplier 包含方法 T get()，返回类型为T的对象 Function&lt;T,R&gt; 包含方法 R apply(T t)，对类型为T的对象进行操作，返回类型R的对象 Predicat 包含方法 boolean test(T t)， 判断类型为T的对象是否满足条件 以及基于这些接口的其它变种或子接口，如BiConsumer&lt;T,U&gt;，BiFunction&lt;T,U,R&gt;等。还有如Runnable，Callable等接口，也属于函数式接口 —— 都只有一个抽象方法。 12345678910111213@FunctionalInterfacepublic interface BiConsumer&lt;T, U&gt; &#123; void accept(T t, U u); default BiConsumer&lt;T, U&gt; andThen(BiConsumer&lt;? super T, ? super U&gt; after) &#123; Objects.requireNonNull(after); return (l, r) -&gt; &#123; accept(l, r); after.accept(l, r); &#125;; &#125;&#125; 3. Lambda表达式lambda表达式实质就是一个匿名函数，在python中很常见，java到了jdk8提供了支持。lambda表达式的格式形如： (参数) -&gt; {方法体语句}，当参数只有一个时，左边小括号可以省略，当方法体语句只有一条时，右边大括号可以省略。 Java的lambda表达式基本上是对函数式接口实现的一种简化 —— 用lambda表达式直接代替一个函数式接口的具体实现（抽象方法的实现）。当我们使用jdk8在IDE中编写1中代码时，IDE会给出提示， 匿名实现类可以用lambda表达式替换。上述代码使用lambda表达式替换可调整为， 123456@Testpublic void testInterface()&#123; MyFunction&lt;String&gt; myFunction = s -&gt; s.toUpperCase(); System.out.println(myFunction.func(\"abc\")); System.out.println(myFunction.func2(\"abc\"));&#125; lambda表达式甚至可作为方法参数传入（实质也是作为一个函数式接口的实现类实例）1234567891011121314@FunctionalInterfacepublic interface MyFunction&lt;T&gt; &#123; T func(T t);&#125;public void print(MyFunction&lt;String&gt; function, String s)&#123; System.out.println(function.func(s));&#125;@Testpublic void testInterface()&#123; //将lambda表达式作为方法参数传入 print((String s) -&gt; s.toUpperCase(), \"abc\");&#125; 局部变量在lambda表达式中是只读的，虽可不声明为final，但无法修改。如123456@Testpublic void testInterface()&#123; int i = 1; //lambda表达式中无法修改局部变量i，将报编译错误 print((String s) -&gt; &#123;i = i+10; return s.toUpperCase();&#125;, \"abc\");&#125; 4. 方法引用当需要使用lambda表达式时，如果已经有了相同的实现方法，则可以使用方法引用来替代lambda表达式，几种场景示例如下。12345678910111213141516171819202122232425262728293031323334353637@RunWith(SpringRunner.class)@SpringBootTestpublic class FunctionReferenceTest &#123; @Test public void testFunctionReference() &#123; // 实例::实例方法 Consumer&lt;String&gt; consumer = s -&gt; System.out.println(s); //lambda表达式 Consumer&lt;String&gt; consumer2 = System.out::println; //方法引用 consumer.accept(\"abc\"); consumer2.accept(\"abc\"); //类::静态方法 Comparator&lt;Integer&gt; comparator = (x, y) -&gt; Integer.compare(x, y); //lambda表达式 Comparator&lt;Integer&gt; comparator2 = Integer::compare; //方法引用 System.out.println(comparator.compare(10, 8)); System.out.println(comparator2.compare(10, 8)); //类::实例方法， 当引用方法是形如 a.func(b)时，用类::实例方法的形式 BiPredicate&lt;String, String&gt; biPredicate = (a, b) -&gt; a.equals(b); //lambda表达式 BiPredicate&lt;String, String&gt; biPredicate2 = String::equals; //方法引用 System.out.println(biPredicate.test(\"abc\", \"abb\")); System.out.println(biPredicate2.test(\"abc\",\"abb\")); //type[]::new 数组引用 Function&lt;Integer,Integer[]&gt; fun= n-&gt; new Integer[n]; //lambda表达式 Function&lt;Integer,Integer[]&gt; fun2=Integer[]::new; //方法引用 System.out.println(fun.apply(10)); System.out.println(fun2.apply(10)); //构造器引用 Function&lt;String,String&gt; func = n-&gt; new String(n); //lambda表达式 Function&lt;String,String&gt; func2 = String::new; //方法引用 System.out.println(func.apply(\"aaa\")); System.out.println(func2.apply(\"aaa\")); &#125;&#125; 5. Stream APIStream与lambda应该是java8最重要的两大特性。Stream 对集合的处理进行了抽象，可以对集合进行非常复杂的查找、过滤和映射等操作。提供了一种高效的且易于使用的处理数据的方式。Stream的三个特性： Stream本身不会存储元素 Stream不会改变操作对象（即集合），会返回一个新的Stream Stream的中间操作不会立刻执行，而是会等到需要结果的时候才执行 Java8 的Collection接口包含了两个方法 stream(), parallelStream()， 分别返回一个顺序流与一个并行流，所有Collection类型（如List， ）的对象可以调用这两个方法生成流。Java8 的Arrays类也提供了 stream(T[] array)等方法用以生成流。也可以使用静态方法 Stream.iterate() 和 Stream.generate() 来创建无限流。 Stream的中间操作包括 操作 描述 filter(Predicate p) 接收 Lambda ， 从流中过滤出满足条件的元素 distinct() 通过hashCode() 和 equals() 去除重复元素 limit(long maxSize) 截断流，使元素的个数不超过给定数量 skip(long n) 跳过前面的n个元素，若流中元素不足n个，则返回一个空流 map(Function f) 将每个元素使用函数f执行，将其映射成一个新的元素 mapToDouble(ToDoubleFunction f) 将每个元素使用f执行，产生一个新的DoubleStream流 mapToInt(ToIntFunction f) 将每个元素使用f执行，产生一个新的IntStream流 mapToLong(ToLongFunction f) 将每个元素使用f执行，产生一个新的LongStream流 flatMap(Function f) 将流中的每个值都通过f转换成另一个流，然后把所有流连接成一个流 sorted() 按自然顺序排序，产生一个新流 sorted(Comparator comp) 根据比较器排序，产生一个新流 allMatch(Predicate p) 判断是否匹配所有元素 anyMatch(Predicate p) 判断是否匹配至少一个元素 noneMatch(Predicate p) 判断是否没有匹配任意元素 findFirst() 返回第一个元素 findAny() 返回任意一个元素 reduce(T iden, BinaryOperator b) 对流中的元素进行reduce操作，返回T类型对象 reduce(BinaryOperator b) 对流中的元素进行reduce操作，返回Optional对象 Stream的终止操作包括 操作 描述 count() 返回元素总数 max(Comparator c) 返回最大值 min(Comparator c) 返回最小值 forEach(Consumer c) 内部迭代调用Consumer操作 collect(Collector c) 将流转换为其他形式，一般通过Collectors来实现 Stream使用示例123456789101112131415161718192021222324252627282930313233@Testpublic void testStream() &#123; List&lt;User&gt; list = new ArrayList&lt;&gt;(); //转换为List，这里没啥意义，仅做示范 List&lt;User&gt; users = list.stream().collect(Collectors.toList()); //转换为Set Set&lt;User&gt; users1 = list.stream().collect(Collectors.toSet()); //转换为Collection Collection&lt;User&gt; users2 = list.stream().collect(Collectors.toCollection(ArrayList::new)); //计数 long count = list.stream().collect(Collectors.counting()); //求和 int total = list.stream().collect(Collectors.summingInt(User::getAge)); //求平均值 double avg= list.stream().collect(Collectors.averagingInt(User::getAge)); //获取统计对象，通过该统计对象可获取最大值，最小值之类的数据 IntSummaryStatistics iss= list.stream().collect(Collectors.summarizingInt(User::getAge)); //将值通过\",\"拼接 String str= list.stream().map(User::getName).collect(Collectors.joining(\",\")); //最大值 Optional&lt;User&gt; max= list.stream().collect(Collectors.maxBy(Comparator.comparingInt(User::getAge))); //最小值 Optional&lt;User&gt; min = list.stream().collect(Collectors.minBy(Comparator.comparingInt(User::getAge))); //从累加器开始，对指定的值，这里是年龄，进行sum的reduce操作 int t =list.stream().collect(Collectors.reducing(0, User::getAge, Integer::sum)); //对转换的结果再进行处理 int how = list.stream().collect(Collectors.collectingAndThen(Collectors.toList(), List::size)); //分组 Map&lt;String, List&lt;User&gt;&gt; map= list.stream().collect(Collectors.groupingBy(User::getName)); //根据条件进行分区 Map&lt;Boolean,List&lt;User&gt;&gt; vd= list.stream().collect(Collectors.partitioningBy(u -&gt; u.getName().startsWith(\"W\")));&#125; 6. Optional类Optional是一个容器类，可以避免显式的null判断，基本使用示例如下1234567891011121314151617181920212223242526272829303132@RunWith(SpringRunner.class)@SpringBootTestpublic class OptionalTest &#123; @Test public void testOptional()&#123; // of 不允许传入null值，否则抛出NPE Optional&lt;Integer&gt; optional = Optional.of(new Integer(10)); System.out.println(optional.get()); // ofNullable 允许传入null，但是直接调用get会抛出NoSuchElementException异常， // 可通过isPresent判断是否存在值 Optional&lt;Integer&gt; optional1 = Optional.ofNullable(null); if(optional1.isPresent()) &#123; System.out.println(optional1.get()); &#125;else&#123; System.out.println(\"optional1 is empty\"); &#125; // orElse 判断是否存在值，存在则返回，不存在则返回参数里的值 Integer value = optional1.orElse(new Integer(0)); // map方法，如果optional有值，则对值进行处理返回新的Optional， // 如果没有值则返回Optional.empty() optional = optional.map(x -&gt; x*x); System.out.println(optional.get()); // 与map类似，只是要求返回值必须是Optional，进一步避免空指针 optional = optional.flatMap(x -&gt;Optional.of(x*x)); System.out.println(optional.get()); &#125;&#125; 7. Base64在java8中，Base64成为了java类库的标准，可直接使用123456789101112131415import java.util.Base64;@RunWith(SpringRunner.class)@SpringBootTestpublic class Base64Test &#123; @Test public void testBase64()&#123; //base64编码 String encode = Base64.getEncoder().encodeToString(\"abc\".getBytes()); System.out.println(encode); //base64解码 System.out.println(new String(Base64.getDecoder().decode(encode))); &#125;&#125; 8. 日期时间类以前的Date类是非线程安全的，并且一些常用的日期时间运算需要自己编写util工具类。java8推出了java.time包，里面包含了如 LocalDate, LocalTime, LocalDateTime等类，可方便地进行日期时间的运算，如日期间隔、时间间隔，日期时间的加减，格式化等等。 —————————————————————————————作者：空山新雨欢迎关注我的微信公众号：jboost-ksxy","categories":[{"name":"Java","slug":"Java","permalink":"http://blog.jboost.cn/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"}]},{"title":"Docker笔记（十）：使用Docker来搭建一套ELK日志分析系统","slug":"docker-elk","date":"2019-09-07T05:43:37.000Z","updated":"2019-09-07T03:59:50.839Z","comments":true,"path":"docker-elk.html","link":"","permalink":"http://blog.jboost.cn/docker-elk.html","excerpt":"一段时间没关注ELK（elasticsearch —— 搜索引擎，可用于存储、索引日志, logstash —— 可用于日志传输、转换，Kibana —— WebUI，将日志可视化），发现最新版已到7.4了。所以别问程序员为什么这么忙？因为不是在加班就是在学习新框架中。本文整理了使用Docker来快速搭建一套ELK日志分析系统的方法。","text":"一段时间没关注ELK（elasticsearch —— 搜索引擎，可用于存储、索引日志, logstash —— 可用于日志传输、转换，Kibana —— WebUI，将日志可视化），发现最新版已到7.4了。所以别问程序员为什么这么忙？因为不是在加班就是在学习新框架中。本文整理了使用Docker来快速搭建一套ELK日志分析系统的方法。 1. 部署elkgithub上有人整理了一套使用docker compose来部署elk的配置，可直接下载使用。1git clone https://github.com/deviantony/docker-elk.git 如果没有git，那就安装一下（yum install git），或者直接下载github仓库的源码包。 当前是基于7.2.1版（docker-elk目录下.env文件中定义，可修改）。 调整一下相应的配置。 修改docker-compose，设置es密码等，12345678910111213141516171819vim docker-compose.yml # 在elasticsearch部分设置环境变量，将jvm堆内存增大到了1g，设置es elastic用户的密码 environment: ES_JAVA_OPTS: \"-Xmx1g -Xms1g\" ELASTIC_PASSWORD: Passw0rd # 将logstash的端口映射从默认的5000改为5044，因为后面会用filebeat，不改也可以，对应就行 ports: - \"5044:5044\" - \"9600:9600\" # 将jvm内存也增大一点 environment: LS_JAVA_OPTS: \"-Xmx512m -Xms512m\" # 在volumes部分增加es数据目录的挂载，对es数据持久化，避免容器销毁数据丢失 volumes: - /mnt/elk/esdata:/usr/share/elasticsearch/data 注意： 因为es容器内部是以elasticsearch用户启动进程的，所以在做持久化数据目录挂载的时候，需要将目录权限进行设置，否则会因为没有访问权限而启动失败。elasticsearch的uid是1000，可以建一个uid为1000的用户，然后将目录所有者赋予该用户。 修改es配置文件，将xpack从trial改为basic，禁用付费功能1234vim elasticsearch/config/elasticsearch.yml #xpack.license.self_generated.type: trial xpack.license.self_generated.type: basic 修改logstash配置文件，设置es的用户名密码1234vim logstash/config/logstash.yml xpack.monitoring.elasticsearch.username: elastic xpack.monitoring.elasticsearch.password: Passw0rd 修改logstash的pipeline配置123456789101112131415161718vim logstash/pipeline/logstash.conf # 这里codec根据具体情况配置 input &#123; beats &#123; port =&gt; 5044 codec =&gt; \"json\" &#125; &#125; ## Add your filters / logstash plugins configuration here output &#123; elasticsearch &#123; hosts =&gt; \"elasticsearch:9200\" index =&gt; \"%&#123;[@metadata][beat]&#125;-%&#123;[@metadata][version]&#125;-%&#123;+YYYY.MM.dd&#125;\" user =&gt; \"elastic\" password =&gt; \"Passw0rd\" &#125; &#125; 修改kibana配置，设置es密码12345vim kibana/config/kibana.yml ## X-Pack security credentials elasticsearch.username: elastic elasticsearch.password: Passw0rd 配置调整后，使用 docker-compose up -d 即可启动es，logstash，kibana三个容器。第一次启动需要下载所有镜像，会比较慢，启动完后，访问 elk所在服务器IP:5601即可进入kibana页面。 这里默认是起一个es容器，如果想起多个，参考： https://github.com/deviantony/docker-elk/wiki/Elasticsearch-cluster 2. 部署filebeatfilebeat部署在产生日志的服务器上。先下载镜像，1docker pull docker.elastic.co/kibana/kibana:7.3.1 下载一个示例配置文件1curl -L -O https://raw.githubusercontent.com/elastic/beats/7.3/deploy/docker/filebeat.docker.yml 修改配置文件123456789101112131415161718192021222324vim filebeat.docker.ymlfilebeat.config: modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: false#filebeat.autodiscover:# providers:# - type: docker# hints.enabled: true#processors:#- add_cloud_metadata: ~#- add_host_metadata: ~filebeat.inputs:- type: log enabled: true paths: - /var/log/elk/*.logoutput.logstash: hosts: [\"你的elk服务器IP:5044\"] 去掉了一些不必要的配置，基本就是一个input, 一个output。input paths部分配置你日志所在目录，注意这里是容器内的目录，真正服务器的日志目录需要在启动容器时挂载到这里配置的目录。 启动容器12docker run -d --name filebeat --user=root -v $(pwd)/filebeat.docker.yml:/usr/share/filebeat/filebeat.yml:ro \\ -v /mnt/logs/elk/:/var/log/elk/ docker.elastic.co/beats/filebeat:7.3.1 filebeat -e -strict.perms=false 对配置文件及实际日志目录与容器日志目录进行了挂载。 启动成功后，对应目录下的日志就会通过filebeat，logstash传输到es，进入kibana对日志数据建立索引进行查询了。 3. 总结前面用elk来搭建日志分析系统还是5.1版，两年时间已到7.4，配置方式，包括UI风格都做了很大的调整，很有一种人间一年，技术圈十载的感觉。本文整理了基于Docker来搭建ELK框架的整个过程，供参考。—————————————————————————————作者：空山新雨欢迎关注我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号）","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"},{"name":"elk","slug":"elk","permalink":"http://blog.jboost.cn/tags/elk/"}]},{"title":"Docker笔记（九）：网络管理","slug":"docker-9","date":"2019-08-30T05:14:57.000Z","updated":"2019-08-30T05:35:24.478Z","comments":true,"path":"docker-9.html","link":"","permalink":"http://blog.jboost.cn/docker-9.html","excerpt":"Docker的应用运行在容器中，其相互之间或与外部之间是如何通信的，涉及到哪些知识点，本文对相关内容进行整理。因网络这块牵涉的面较多，因此只从日常使用或理解的角度出发，过于专业的就不深入探讨了。","text":"Docker的应用运行在容器中，其相互之间或与外部之间是如何通信的，涉及到哪些知识点，本文对相关内容进行整理。因网络这块牵涉的面较多，因此只从日常使用或理解的角度出发，过于专业的就不深入探讨了。 1. Docker默认的网络拓扑在Docker笔记（二）：Docker管理的对象中，介绍了Docker通过一些驱动程序来实现容器之间或容器与外部的互联，包括bridge（默认的虚拟网桥形式），host（与主机共享网络栈），overlay（跨Docker Daemon容器间的互联），macvlan（为容器分配mac地址），none（禁用所有网络）等。 默认情况下，Docker启动时会创建一个虚拟网桥 docker0，可以理解为一个软件交换机。当创建一个 Docker 容器的时候，会创建一对 veth pair 接口（当数据包发送到一个接口时，另外一个接口也可以收到相同的数据包）。这对接口一端在容器内，即 eth0 ；另一端在宿主机本地并被挂载到 docker0 网桥，名称以veth 开头，如 veth340c305，docker0会在挂载到它上面的网口之间进行转发，从而实现主机与容器之间及容器与容器之间的相互通信。Docker默认的网络拓扑图如下： 我们可以在宿主机上通过ifconfig查看相关的网络接口，12345678910111213141516171819202122232425~$ ifconfigdocker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255 inet6 fe80::42:46ff:fe26:ce0b prefixlen 64 scopeid 0x20&lt;link&gt; ether 02:42:46:26:ce:0b txqueuelen 0 (Ethernet) RX packets 16868344 bytes 127838098551 (127.8 GB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 17929275 bytes 137867853738 (137.8 GB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0veth340c305: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet6 fe80::50f7:7ff:fe8f:6e72 prefixlen 64 scopeid 0x20&lt;link&gt; ether 52:f7:07:8f:6e:72 txqueuelen 0 (Ethernet) RX packets 8093606 bytes 126893792744 (126.8 GB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 8795102 bytes 10834735399 (10.8 GB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0veth6c803b7: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet6 fe80::1045:4cff:fe66:7f5a prefixlen 64 scopeid 0x20&lt;link&gt; ether 12:45:4c:66:7f:5a txqueuelen 0 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 140 bytes 9832 (9.8 KB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 通过brctl show可查看网络接口的挂载情况，1234~$ brctl showbridge name bridge id STP enabled interfacesdocker0 8000.02424626ce0b no veth340c305 veth6c803b7 由上可看出网络接口veth340c305，veth6c803b7都挂在虚拟网桥docker0上。 2. 容器与外部的互联我们前面的许多容器启动命令都有添加类似 -p 8080:8080 的参数，以指定将宿主机端口映射到容器端口，从而通过访问 宿主机IP：宿主机端口 的地址来访问对应端口的容器服务。端口映射的完整格式为 宿主机IP：宿主机端口：容器端口，其中前两个是可以两者都取，或只取其一 宿主机IP：宿主机端口：容器端口：将指定宿主机IP的一个指定端口映射到容器端口，如192.168.40.205:8090:8080 宿主机IP::容器端口：将指定宿主机IP的一个随机端口映射到容器端口上，如果宿主机有多个IP，则可以通过这种格式指定绑定其中一个宿主机IP，随机端口范围为49000~49900 宿主机端口：容器端口：将宿主机所有网络接口IP的指定端口映射到容器端口上，8090:8080等效于0.0.0.0:8090:8080（0.0.0.0即表示所有网络接口地址） 可以使用 docker port 容器ID或名称 容器端口或docker ps命令来查看端口映射情况，如123456~$ docker port test-dev 80800.0.0.0:32768~$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES696a76944e72 cnbots:dev \"/bin/sh -c '/usr/lo…\" 23 minutes ago Up 23 minutes 0.0.0.0:32768-&gt;8080/tcp test-dev 在容器启动时，可以多次使用 -p 来指定映射多个端口。 如果不指定具体的宿主机端口，则可以使用 -P（大写）来分配一个宿主机的随机端口（范围为49000~49900）， 如docker run -d -P --name test-dev test:dev，然后通过docker port 容器ID或名称 容器端口或docker ps命令来查看具体映射到了哪个端口。 3. 容器之间的互联同一个Docker Daemon下的容器，彼此之间是可以通过容器IP互相访问的（如何查看容器IP？用docker inspect 容器ID或名称命令），如果要实现两个容器之间可以通过容器名直接访问，则可以通过自建一个docker网络。1234567891011121314151617181920212223# 创建一个自定义网络，-d 表示网络类型，可以为bridge（网桥，软件交换机），或overlay（跨Docker Daemon容器间的互联）~$ docker network create -d bridge my-net0c97fc265ed1cab67d84b9376d6914c9558419c73bb5abc040e75c945cd99f0a# 启动一个centos容器centos1，通过 --network 指定自定义网络~$ docker run -it --name centos1 --network my-net centos:7.3.1611 bash[root@3dcf507bd12a /]# # 再启动一个centos容器centos2（打开另一个窗口），指定同一个自定义网络~$ docker run -it --name centos2 --network my-net centos:7.3.1611 bash[root@16dcce660a89 /]# # 在centos1容器中直接ping centos2[root@3dcf507bd12a /]# ping centos2PING centos2 (172.19.0.2) 56(84) bytes of data.64 bytes from centos2.my-net (172.19.0.2): icmp_seq=1 ttl=64 time=0.111 ms64 bytes from centos2.my-net (172.19.0.2): icmp_seq=2 ttl=64 time=0.058 ms# 在centos2容器中直接ping centos1[root@16dcce660a89 /]# ping centos1PING centos1 (172.19.0.3) 56(84) bytes of data.64 bytes from centos1.my-net (172.19.0.3): icmp_seq=1 ttl=64 time=0.061 ms64 bytes from centos1.my-net (172.19.0.3): icmp_seq=2 ttl=64 time=0.054 ms 由上可见通过自定义网桥连接的容器可以通过容器名称互相访问。如果需要多个容器之间互联，则可以使用Docker Compose。 4. 配置容器的DNS如果要自定义所有容器的DNS，则可以在 /etc/docker/daemon.json 中增加123456&#123; \"dns\" : [ \"114.114.114.114\", \"8.8.8.8\" ]&#125; 也可以在启动容器时通过参数指定单个容器的DNS配置，--dns=IP_ADDRESS，这会将指定DNS的地址添加到容器的 /etc/resolv.conf 文件中，让容器用这个DNS服务器来解析所有不在 /etc/hosts 中的主机名。 5. Docker网络的底层实现容器的网络访问控制，主要是通过Linux上的iptables防火墙来实现与管理的。 容器访问外部网络容器访问外部网络，需要通过本地系统的转发，可以通过如下命令查看转发是否打开12345$sysctl net.ipv4.ip_forwardnet.ipv4.ip_forward = 1# 为1为打开，为0则未打开，可通过如下命令打开，也可以在Docker服务启动时通过参数--ip-forward=true打开$sysctl -w net.ipv4.ip_forward=1 容器所有到外部网络的访问，源地址都会被 NAT 成本地系统的 IP 地址。这是使用 iptables 的源地址伪装操作实现的， 1234~# iptables -t nat -nLChain POSTROUTING (policy ACCEPT)target prot opt source destination MASQUERADE all -- 172.17.0.0/16 0.0.0.0/0 上述规则将所有源地址在 172.17.0.0/16 的网段（容器IP所在网段），目标地址为任意网段（包括外部网络）的流量动态伪装为从系统网卡发出。MASQUERADE 跟传统 SNAT 的好处是它能动态从网卡获取地址。 外部访问容器 通过 -p 或 -P 指定端口映射，允许外部访问容器端口，实质也是在本地的 iptable 的 nat 表中添加相应的规则，如12345~# iptables -t nat -nLChain DOCKER (2 references)target prot opt source destination DNAT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:3306 to:172.17.0.2:3306DNAT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:11090 to:172.17.0.3:11090 这里的规则映射了 0.0.0.0 ，意味着将接受主机来自所有网络接口的流量。 容器之间的访问容器之间能互相访问，需要满足两个条件：1）容器的网络拓扑是否已经互联，默认情况下容器都连接到docker0网桥上，默认是互联的。2）本地系统的防火墙iptables是否允许通过。当容器启动时通过–link互联时，也是在iptables中创建对应规则来实现。 6. 总结本文整理了Docker网络相关知识，对容器之间及容器与外部之间的通信机制应该有了一定的了解。除了默认的网络实现，Docker还提供了网络的配置及自定义网络，出于篇幅，本文介绍到这，后续再补充。我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"}]},{"title":"开发人员需要掌握的日常Linux命令集","slug":"linux-cmd","date":"2019-08-27T02:58:43.000Z","updated":"2019-08-27T10:46:50.460Z","comments":true,"path":"linux-cmd.html","link":"","permalink":"http://blog.jboost.cn/linux-cmd.html","excerpt":"不会运维的开发不是好测试。","text":"不会运维的开发不是好测试。 本文整理了开发人员日常用到的linux相关命令，供参考。 文件相关cd # 进入某个目录，不接参数进入当前用户目录（等同于cd ~），如/home/devuser，可接绝对路径或相对路径（../..表示上上级目录），也可以接 “-” 回到上次所在目录 pwd # 显示当前所在目录 ls -la # 列出当前目录所有对象，-a表示包含以.开头的隐藏文件或目录ll -h # ll 等同于 ls -l， -h表示按K M G 显示文件大小 df -h # 显示系统各盘符的空间使用情况du -h --max-depth=1 # 显示当前目录下各文件大小，–max-depth=1只列出当前目录下的文件或目录，不会列出子目录下的文件 mv test.log /home/devuser/ # 移动文件（夹） 或重命名 cp [-r] test test.bak # 复制文件，如果是文件夹则加 -r，表示复制文件夹下所有子文件夹内容rm -[r]f /home/devuser/ # 删除文件，如果删除文件夹则加 -r find / -name test.log # 在根目录下查找文件名为test.log的文件find /var/log/ -size +50M -exec rm -f {} \\; # 在/var/log/目录下查找大于50M的文件并删除，建议先将rm改为ls确认find /var/log/ -type f -atime +10 # 搜索在过去10天内未被使用过的文件find /var/log/ -type f -mtime -10 # 搜索在10天内被创建或者修改过的文件find /var/log/ -type f -atime +10|xargs rm -f # |xargs 作用与 -exec类似find ./ -name &quot;*.log&quot; -exec &#39;cat&#39; {} \\; &gt; test.log # 将当前目录下所有.log文件内容合并到一个文件test.log which java # 在系统PATH路径下查找java可执行文件whereis java # 查找二进制、源文件、man文件，从文件索引中查找，而不仅仅从PATH路径下查找 zip test.zip test.log test2.log # 创建一个zip格式的压缩包，可以接多个文件或文件夹zip -r file.zip file1 file2 dir1 # 将几个文件和目录同时压缩成一个zip格式的压缩包unzip test.zip # 解压一个zip格式压缩包 tar -zcvf test.tar.gz 要被压缩的文件名或目录 # 以gzip进行压缩 -z 按gzip，-c 压缩，-v 显示内容 -f 指定文件名tar -zxvf test.tar.gz -C 解压缩到的目录 # 解压到指定目录 -x 解压tar -ztvf test.tar.gz # 不解压，只查看内容 tar -jcvf test.tar.bz2 要被压缩的文件名或目录 # 以bzip2进行压缩tar -jxvf test.tar.bz2 -C 解压缩到的目录 # 解压到指定目录 文本相关touch test.log # 创建空文件echo -e &#39;abc\\ncba&#39;&gt; test.log # 覆盖的形式往文件写入内容 -e 解析转移字符，不然当成字符串echo &#39;aaa&#39; &gt;&gt; test.log # 追加的形式往文件写入内容 cat [-n] test.log |grep [-v] abc # 过滤文件中包含 abc 的行， 加-v表示不包含， -n表示打印行号cat test.log |grep abc|wc -l # 计算文件中包含 abc 的行数 head -n 2 test.log # 查看一个文件的前两行tail -n 2 test.log # 查看一个文件的最后两行tail -n +1000 test.log # 从1000行开始显示，显示1000行以后的cat test.log | head -n 2000 | tail -n +1000 # 显示1000行到2000行的cat test.log | tail -n +1000 | head -n 1000 # 从第1000行开始，显示1000行 more test.log # 一页一页地查看文件内容，空格键往后一页，B键往前一页，不能通过上下键控制翻滚，会一次加载整个文件less test.log # 一页一页地显示文件内容，可以通过上下键控制往前往后翻，可以向上向下搜，不需一次加载整个文件，所以速度比more快，“less is more”， less比more更强大 tail -200f test.log # 查看最后200行，根据文件描述符进行追踪，当文件改名或被删除，追踪停止tail -F test.log # 查看最后10行，只要对应文件名存在，就保持监视，即使文件被删除或改名后，如果再次创建相同的文件名，也会继续追踪 grep abc test.log # 在文件中查找关键词”abc”，类似于 cat test.log|grep abcgrep ^abc test.log # 在文件中查找以”abc”开始的词汇grep [0-9] test.log # 选择文件中所有包含数字的行grep abc -R /var/log/* # 在目录 ‘/var/log’ 及随后的目录中搜索字符串”abc” sed &#39;s/abc/ccc/g&#39; test.log # 将test.log文件中的 “abc” 替换成 “ccc”并打印，不改变原有文件sed &#39;/^$/d&#39; test.log # 从文件中删除所有空白行并打印，不改变原有文件 paste test.log test2.log # 按两列合并两个文件每行的内容并打印，test.log在左边，test2.log在右边paste -d &#39;+&#39; file1 file2 # 合并两个文件每行的内容并打印，中间用”+”拼接 sort test.log # 对文件内容进行排序，每行首字母排序sort test.log test2.log # 排序两个文件的内容sort test.log test2.log | uniq # 取出两个文件的并集(重复的行只保留一份)sort test.log test2.log | uniq -u # 删除交集，留下其他的行sort test.log test2.log | uniq -d # 取出两个文件的交集(同时存在于两个文件中的行) # comm 类似于集合的差集运算，需要两个文件都是排序的comm -1 test.log test2.log # 比较两个文件的内容只删除test.log所包含的内容comm -2 test.log test2.log # 比较两个文件的内容只删除test2.log所包含的内容comm -3 test.log test2.log # 比较两个文件的内容删除两个文件共有的内容 权限相关chmod +x test.sh # 为一个文件增加可执行权限chmod ugo+rwx test.sh # 设置文件的所有者(u)、群组(g)以及其他人(o)读（r，4 ）、写(w，2)和执行(x，1)的权限，+ 改为 - 即删除权限chmod 755 test.sh # 对文件所有者，群组，其他人分别设置7（rwx=4+2+1），5（rx=4+1）,5（rx=4+1）的权限 chown [-R] 用户名:群组名 test.log #改变一个文件的所有者和群组，如果是作用于文件夹下所有文件或目录，则加 -Rchgrp 群组名 test.log # 改变文件的群组 进程相关top # 实时显示系统中各个进程的资源占用状况top -H -p 进程号 # 列出进程的所有线程，按1键根据CPU占有率排序ps -ef|grep 进程名称 # 查看某个进程，一般用户找进程IDkill -9 进程ID # 停止某个进程jps # 查看所有java进程 网络相关ifconfig # 查看系统各网卡信息（IP，mac地址，子网掩码等）ss -s # 查看当前系统tcp、udp连接数 netstat -ano|grep 端口号 # 查看某个端口是否起来lsof -i:端口号 # 查看某个端口对应的进程信息，lsof可能需要额外安装 （sudo yum install lsof） ssh devuser@192.168.40.206 # 远程连接另一台linux主机 curl http://www.baidu.com # get方式请求某个地址curl -i -X POST -H &quot;Content-type:application/json&quot; -d &#39;{&quot;a&quot;:&quot;x&quot;,&quot;b&quot;:[&quot;y&quot;]}&#39; http://xxx # POST方式请求某个接口 wget http://xxx.zip # 下载文件 scp test.log devuser@192.168.40.206:/home/devuser/# 传输文件到另一台主机的目录下，如果是文件夹则加 -r# nc 传输，可用于文件传输（scp需要密码，nc不需要密码），需要安装 sudo yum install ncnc -l 1234 &gt; test.log # 接收方，监听1234端口，将接收内容存于test.lognc 192.168.40.205 1234 &lt; test.log # 发送方，向接收方(ip为192.168.40.205)发送test.log的内容 系统相关top # 查看CPU、内存使用情况，即各进程使用情况free -g # 查看内存使用情况date # 查看系统当前时间uptime # 查看当前CPU使用负载情况，及系统已运行时间，相当于top的第一行su # 切换到root用户su devuser # 切换到devuser用户欢迎关注我的微信公众号：jboost-ksxy （一个不只有实战干货的技术公众号，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://blog.jboost.cn/tags/linux/"}]},{"title":"k8s云集群混搭模式，可能帮你节省50%的服务成本","slug":"mix-eci","date":"2019-08-21T07:32:30.000Z","updated":"2019-08-22T03:49:19.484Z","comments":true,"path":"mix-eci.html","link":"","permalink":"http://blog.jboost.cn/mix-eci.html","excerpt":"","text":"现在大部分中小企业或团队都是使用云平台来部署自己的服务，如阿里云，亚马逊云等。一般来说，业务的负载都具备一定的规律，比如每天集中在某几个小时，或呈现时间段周期性波峰、波谷交替的现象，如下图 如果使用ECS来部署服务，则可能大部分时间ECS的资源没有得到充分利用，造成成本浪费，尤其对于像GPU之类成本较高的资源就更加了。这个时候，我们可以考虑使用云集群的混搭模式来节约成本。 业务场景假设有一个这样的业务场景，包括如下特点及要求： 整个系统包括业务服务与两层视觉服务 各层服务之间调用需做负载均衡 每天的业务量主要集中在上午几个小时 平时业务量较低时仍要保证服务可用 尽可能降低成本，尤其是GPU服务器成本（GPU贵啊） k8s云集群混搭模式现在各大云平台都已经提供容器云服务，如阿里云有基于ECI（弹性容器实例）的Serverless Kubernetes集群服务，基于ECS节点不需要提供master的Kubernetes托管版集群服务，及自己提供master的Kubernetes专有版集群服务等。为了迎合类似上述业务场景的需求，也提供了Kubernetes + virtual node（虚拟节点）的混合集群服务，如下图所示 其中的虚拟节点基于ECI支持多种功能，如GPU容器实例、大规格容器实例等，增强了Kubernetes集群的弹性，使集群不局限于ECS节点的资源，做到弹性无限扩容。 部署方案结合前面的业务场景，我们可以采用k8s的混合集群服务来部署我们的项目，如下图 实现步骤： 创建Kubernetes托管版集群 加入已有ECS节点 添加一个虚拟节点，通过添加应用 ack-virtual-node 来实现 分别创建无状态的业务Deployment、AI-1 Deployment、AI-2 Deployment（对应三层服务） 分别在业务Deployment上创建公网SLB，AI-1 Deployment、AI-2 Deployment上创建内网SLB 分别在各Deployment上根据CPU或内存使用阈值配置弹性水平伸缩HPA 根据需要可以在某个或某些Deployment上配置定时伸缩，通过添加应用 ack-kubernetes-cronhpa-controller 来实现 因为水平伸缩一般需要一定时间，延迟可能会对业务造成影响，所以在业务负载比较规律的时候，可以通过定时伸缩（就是定时扩展到多少个容器，再定时收缩到多少个容器）来改善；目前定时伸缩配置的查看与更新只能通过kubectl命令行进行。 总结按照官方文档的计费方式，一个普通的2核8G的ECS一年大概费用是2600左右，如果通过容器服务的方式（按秒计费），假设每天起8小时，则一年大概费用1550左右，如果业务负载再集中到几个小时，费用会更低，对于比较稀缺又昂贵的GPU服务就更加了。但是如果服务全部按容器24小时租赁，其成本就又比ECS贵了（一年约4600），所以在平时业务负载较低的时候，可以将容器调度到ECS上保障服务的提供，业务负载高时，通过HPA或cronHPA的方式动态伸缩到虚拟节点上。对于业务负载具有一定规律的服务来说，采用这种混搭的部署方式将极大地降低你的云服务成本。不过目前k8s云集群服务应该推出时间不久，产品的易用性还比较低，对不具备一定容器与编排基础的人使用门槛相对较高。 欢迎关注我的微信公众号：jboost-ksxy （一个不只有实战干货的技术公众号，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"},{"name":"k8s","slug":"k8s","permalink":"http://blog.jboost.cn/tags/k8s/"}]},{"title":"小技巧：如何自定义logback日志文件的名称","slug":"trick-logback-prop","date":"2019-08-20T09:42:28.000Z","updated":"2019-08-20T11:04:34.498Z","comments":true,"path":"trick-logback-prop.html","link":"","permalink":"http://blog.jboost.cn/trick-logback-prop.html","excerpt":"在logback.xml中获取自定义变量值。","text":"在logback.xml中获取自定义变量值。 我们可以通过在logback.xml中配置appender来指定日志输出格式及输出文件路径，这在一台主机或一个文件系统上部署单个实例没有问题，但是如果部署多个实例（比如通过容器的方式），多个实例同时往同一文件写日志可能就会引起问题。这时可以将每个实例的日志文件加以区分，如IP或UUID，或两者结合的形式。 可以有4种方式来实现logback.xml中获取自定义变量值： 通过设置环境变量或传递系统属性（比如在程序启动时通过-D传递）的方式，两者是可以直接在logback.xml中通过 ${变量名} 获取的。 自定义logback.xml的加载时机，在其加载前将需要设置的属性注入到logback的context中，这种方式相对复杂，本文不讨论。 通过实现PropertyDefiner接口来提供属性值设置 通过实现LoggerContextListener接口来设置属性值 第一种方式简单，但不能通过程序生成属性值，第二种方式稍显复杂，本文主要介绍后两种方式。 PropertyDefiner方式首先定义一个类，实现PropertyDefiner接口，可以通过继承PropertyDefinerBase会更方便 123456789101112131415161718192021222324252627282930313233343536import ch.qos.logback.core.PropertyDefinerBase;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.net.InetAddress;import java.net.UnknownHostException;import java.util.UUID;/*** * 将本地IP拼接到日志文件名中，以区分不同实例，避免存储到同一位置时的覆盖冲突问题 * @Author ronwxy * @Date 2019/8/20 16:17 */public class IPLogDefiner extends PropertyDefinerBase &#123; private static final Logger LOG = LoggerFactory.getLogger(IPLogDefiner.class); private String getUniqName() &#123; String localIp = null; try &#123; localIp = InetAddress.getLocalHost().getHostAddress(); &#125; catch (UnknownHostException e) &#123; LOG.error(\"fail to get ip...\", e); &#125; String uniqName = UUID.randomUUID().toString().replace(\"-\", \"\"); if (localIp != null) &#123; uniqName = localIp + \"-\" + uniqName; &#125; return uniqName; &#125; @Override public String getPropertyValue() &#123; return getUniqName(); &#125;&#125; 在实现方法 getPropertyValue 中返回你需要生成的值，本例中是返回 本地IP-UUID 的形式。 然后在logback.xml中，添加 &lt;define&gt; 配置，指定属性名（本例中为localIP）及获取属性值的实现类，这样就可以在配置中通过 ${localIP}来引用该属性值了。12345678910&lt;configuration&gt; &lt;define name=\"localIP\" class=\"com.cnbot.common.IPLogDefiner\"/&gt; &lt;appender name=\"interfaceLogFile\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;File&gt;D:\\\\logs\\\\elk\\\\interface-$&#123;localIP&#125;.log&lt;/File&gt; &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;/filter&gt;# 省略了其它配置 LoggerContextListener方式定义一个实现LoggerContextListener接口的类，在start方法中，将需要设置的属性设置到logback的Context中， 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import ch.qos.logback.classic.Level;import ch.qos.logback.classic.Logger;import ch.qos.logback.classic.LoggerContext;import ch.qos.logback.classic.spi.LoggerContextListener;import ch.qos.logback.core.Context;import ch.qos.logback.core.spi.ContextAwareBase;import ch.qos.logback.core.spi.LifeCycle;import java.net.InetAddress;import java.net.UnknownHostException;import java.util.UUID;/*** * 第二种实现方式 * @Author ronwxy * @Date 2019/8/20 18:45 */public class LoggerStartupListener extends ContextAwareBase implements LoggerContextListener, LifeCycle &#123; private boolean started = false; @Override public void start() &#123; if (started) &#123; return; &#125; Context context = getContext(); context.putProperty(\"localIP\", getUniqName()); started = true; &#125; private String getUniqName() &#123; String localIp = null; try &#123; localIp = InetAddress.getLocalHost().getHostAddress(); &#125; catch (UnknownHostException e) &#123; //LOG.error(\"fail to get ip...\", e); &#125; String uniqName = UUID.randomUUID().toString().replace(\"-\", \"\"); if (localIp != null) &#123; uniqName = localIp + \"-\" + uniqName; &#125; return uniqName; &#125;//省略了其它函数 然后在logback.xml中，配置如上监听器类，这样就可以通过 ${localIP} 获取到上面 context.putProperty(&quot;localIP&quot;, getUniqName()); 设置的值了。12345678910111213&lt;configuration&gt; &lt;!--&lt;define name=\"localIP\" class=\"com.cnbot.common.IPLogDefiner\"/&gt;--&gt; &lt;contextListener class=\"com.cnbot.common.LoggerStartupListener\"/&gt; &lt;define name=\"localIP\" class=\"com.cnbot.common.IPLogDefiner\"/&gt; &lt;appender name=\"interfaceLogFile\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;File&gt;D:\\\\logs\\\\elk\\\\interface-$&#123;localIP&#125;.log&lt;/File&gt; &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;/filter&gt;# 省略了其它配置 这种方式能设置任意个数的属性值，比前一种方式灵活。 总结在logback.xml中获取自定义属性值，主要是需要在加载前将对应的属性值进行设置，这样加载时才能有效获取。本文虽是自定义日志文件名称，但不局限于此，所有需要动态获取的变量都可以按这种方式实现。 欢迎关注我的微信公众号：jboost-ksxy———————————————————————————————————————————————————————————————","categories":[{"name":"Java","slug":"Java","permalink":"http://blog.jboost.cn/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"}]},{"title":"Docker笔记（八）：数据管理","slug":"docker-8","date":"2019-08-12T08:50:37.000Z","updated":"2019-08-12T13:01:44.281Z","comments":true,"path":"docker-8.html","link":"","permalink":"http://blog.jboost.cn/docker-8.html","excerpt":"前面（哪个前面我也忘了）有说过，如果我们需要对数据进行持久化保存，不应使其存储在容器中，因为容器中的数据会随着容器的删除而丢失，而因通过将数据存储于宿主机文件系统的形式来持久化。在Docker容器中管理数据主要有数据卷、宿主机目录挂载两种方式","text":"前面（哪个前面我也忘了）有说过，如果我们需要对数据进行持久化保存，不应使其存储在容器中，因为容器中的数据会随着容器的删除而丢失，而因通过将数据存储于宿主机文件系统的形式来持久化。在Docker容器中管理数据主要有数据卷、宿主机目录挂载两种方式 1. 数据卷的方式数据卷是一个特殊的文件目录（或文件），具备如下特性： 可以在容器之间共享和重用 对数据卷的修改会立马生效 数据卷的更新，不会影响到镜像 数据卷默认会一直存在，不会随容器的删除而消亡 1.1 创建数据卷可以使用docker volume create 数据卷名称的命令来创建一个数据卷，12[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker volume create volume1volume1 1.2 查看数据卷创建完后，这个数据卷具体对应宿主机哪个文件目录在上面是没法得知的，可以通过docker volume inspect 数据卷名称来查看，123456789101112[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker volume inspect volume1[ &#123; \"CreatedAt\": \"2019-08-12T19:43:47+08:00\", \"Driver\": \"local\", \"Labels\": &#123;&#125;, \"Mountpoint\": \"/var/lib/docker/volumes/volume1/_data\", \"Name\": \"volume1\", \"Options\": &#123;&#125;, \"Scope\": \"local\" &#125;] 可以看到数据卷volume1对应的文件目录是“/var/lib/docker/volumes/volume1/_data”。 docker inspect xxx这个命令挺有用的，不论是查看镜像相关信息（docker image inspect 镜像名/镜像ID），还是查看容器相关信息（docker container inspect 容器名/容器ID），都可以使用，其中的image,container,volume是可以省略的，只要xxx部分不冲突就行。 可以通过docker volume ls 命令来查看所有数据卷，123[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker volume lsDRIVER VOLUME NAMElocal volume1 1.3 使用数据卷可以在启动容器时通过 -v 或 –mount 的方式将一个数据卷挂载到容器的某个目录12[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker run -dit --name ubuntu1 -v volume1:/vol1 ubuntu:18.04b060e793d44de2ca871da257b47598334658952943a13d1c478df5c3ae91a01c 按照 -v 数据卷名:容器目录 的格式，也可以使用 –mount 按照 --mount source=数据卷名,target=容器目录 的格式，如我们再启动一个挂载相同数据卷的容器 ubuntu2，12[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker run -dit --name ubuntu2 --mount source=volume1,target=/vol2 ubuntu:18.04b30971f8a4bbadee10774fce0b4568b5b7b1c9cde36f4bf84ac911a4cdaf6c8d 可以在数据卷所在目录中创建一个文件来看看效果，先创建文件 hello.txt1234[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# cd /var/lib/docker/volumes/volume1/_data[root@iZwz9dbodbaqxj1gxhpnjxZ _data]# touch hello.txt[root@iZwz9dbodbaqxj1gxhpnjxZ _data]# lshello.txt 然后通过docker exec来查看容器ubuntu1目录/vol1，及容器ubuntu2目录/vol2的内容1234[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker exec -it ubuntu1 ls /vol1hello.txt[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker exec -it ubuntu2 ls /vol2hello.txt 可以看到通过挂载目录 /vol1， /vol2 都可以访问到数据卷volume1对应目录下的内容。这就像linux的软链接一样，将容器目录链接到了数据卷目录。并且上述示例也说明，同一个数据卷是可以在被多个容器共享的。 数据卷的共享也可以通过 volumes-from 容器名称/容器ID 参数来实现，如1234[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker run -dit --name ubuntu3 --volumes-from ubuntu2 ubuntu:18.04bb5c6d61a1e6eeb18ba8c889e471b2f3215f97efca79b311eeca5968b2700df8[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker exec -it ubuntu3 ls /vol2hello.txt 通过--volumes-from ubuntu2来直接使用ubuntu2挂载的容器配置。 1.4 删除数据卷数据卷不会随着容器的删除而自动删除。如果一个数据卷还被某个容器使用，则不能删除；如果一个数据卷只被一个容器使用，则可在删除容器时通过指定 -v 参数同时删除其挂载的数据卷；12[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker rm -v ubuntu3ubuntu3 可以通过 docker volume rm 数据卷名称 来删除某个数据卷；可以通过 docker volume prune 清理掉所有未被任何容器使用的数据卷。 2. 宿主机目录挂载方式在容器启动时，使用 -v 宿主机目录:容器目录 或 --mount type=bind,source=宿主机目录,target=容器目录的参数格式指定将宿主机目录挂载到容器目录上。宿主机目录必须是绝对路径。两者之间的区别是 -v 如果在宿主机目录不存在时会自动创建目录，而--mount不会。如，12345678[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker run -dit --name ubuntu1 -v /root/v1:/vol1 ubuntu:18.0425c91911709eebc9290b47b483666f7b7be840df947117f7cad323583905b9f1[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker run -dit --name ubuntu2 --mount type=bind,source=/root/v2,target=/vol1 ubuntu:18.04docker: Error response from daemon: invalid mount config for type \"bind\": bind source path does not exist: /root/v2.See 'docker run --help'.[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# mkdir /root/v2[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker run -dit --name ubuntu2 --mount type=bind,source=/root/v2,target=/vol1 ubuntu:18.045a57285e9261d048dc71cf0476055a290f80538afff2cefd2a24f8b4468b5171 /root/v1,/root/v2都没有事先创建，用 -v 不会报错，会自动创建； --mount则会报错，目录必须先存在。 docker不仅支持目录的挂载，也支持文件的挂载，如，1234[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker run --rm -it -v $HOME/.bash_history:/root/.bash_history ubuntu:18.04 bash root@3ae4ed4e687d:/# history 1 ll webapps/ 2 ll confluence/images/ 通过将宿主机当前用户的历史操作文件挂载到容器的root用户下的历史操作文件，可在容器中通过history命令查看到宿主机的操作历史。 可通过 docker inspect来查看容器的挂载情况12345678910111213[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker inspect ubuntu1--省略了其它信息--\"Mounts\": [ &#123; \"Type\": \"bind\", \"Source\": \"/root/v1\", \"Destination\": \"/vol1\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"rprivate\" &#125; ],--省略了其它信息-- 可在“Mounts”部分看到挂载信息。 3. 只读控制有时候，为了数据安全，我们不允许容器对挂载目录的内容进行修改，即对容器来说，挂载目录是只读的，这可以通过在挂载参数后面加限制实现。12345[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker run -dit --name ubuntu3 -v /root/v1:/vol1:ro ubuntu:18.0425eca348ed307afcbef92bc03f0a1304b31b52e6db1fa07772b5dbd1040ff7b6[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker exec -it ubuntu3 bashroot@25eca348ed30:/# touch /vol1/hello.txttouch: cannot touch '/vol1/hello.txt': Read-only file system -v是在后面加ro（read-only），--mount则是形如--mount type=bind,source=宿主机目录,target=容器目录,read only的格式，可自行试验。加了read only的挂载我们再通过docker inspect命令查看，可看到两者之间的差异 —— Mode与RW的值。12345678910\"Mounts\": [ &#123; \"Type\": \"bind\", \"Source\": \"/root/v1\", \"Destination\": \"/vol1\", \"Mode\": \"ro\", \"RW\": false, \"Propagation\": \"rprivate\" &#125; ], 4. 总结如果要对数据进行持久化管理或在容器之间共享数据，则需要将数据通过数据卷或宿主机目录（或文件）挂载的方式来将数据存储于宿主机上，使得数据的生命周期独立于容器的生命周期。这类似于我们不要把重要文件放在系统盘，而应放在其它数据盘一样，因为系统盘会由于重装系统或系统故障导致文件丢失。本文对Docker的数据管理进行了整理，后续对Docker的网络配置管理部分进行整理，欢迎持续关注。 我的微信公众号：jboost-ksxy （一个不只有实战干货的技术公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"}]},{"title":"就业，该去小公司还是大公司？","slug":"company-choice","date":"2019-08-09T05:29:58.000Z","updated":"2019-08-12T04:00:24.375Z","comments":true,"path":"company-choice.html","link":"","permalink":"http://blog.jboost.cn/company-choice.html","excerpt":"前几天跟一朋友交流，他说一个表弟明年就要毕业了，马上面临找工作，是去一线城市找大公司的工作好，还是留在二线城市中小公司发展好。我说，去大公司好。为什么会有这个结论，这篇文章结合自己的经历说说我的一些感受。","text":"前几天跟一朋友交流，他说一个表弟明年就要毕业了，马上面临找工作，是去一线城市找大公司的工作好，还是留在二线城市中小公司发展好。我说，去大公司好。为什么会有这个结论，这篇文章结合自己的经历说说我的一些感受。 我的第一份工作是在一家外企，当时抱着“逃离”上海的想法去了二线城市的分公司，但是管理文化氛围跟总部几乎都是一样的，这份工作经历对我后面的工作不论是做事风格、习惯上还是思考问题的方式方法上都有很大的影响。后面陆续进入国企，民企，再进入初创公司，从公司规模上可以说各种类型的都有过体验。下面从环境因素，平台效应因素等几个角度说说自己的感受。 环境因素环境对一个人的影响还是很重要的，不论是大家熟知的“近朱者赤近墨者黑”的说法，还是令我们中国人挤破脑袋的“学区房”现象，都说明环境对一个人的成长起着至关重要的作用。 小公司与大公司的环境差异首先体现在人员的素养、水平上。大公司的准入门槛相对高一些，所以人员的素质、水平也相对要高一些，如果你周围牛人比较多的话，跟牛人待久了，你也可能慢慢就步入牛人之列了——“近朱者赤”。而小公司，尤其是初创公司，为了尽快招人干活，往往人员的素质、水平会良莠不齐，你可能很难找到一个各方面让你信服，想跟着他学的真正的“牛人”。 其次在制度、流程规范上。大公司在制度、流程、规范方面相对健全完善，不论是人事管理还是日常合作分工都比较明确，你知道什么时候应该干什么（因为都给你安排好了），处理什么事情应该找谁，都有章可循，有人可找。而在小公司，可能很多人感觉的就一个字——“乱”，人员职责、分工、权限没有明确定义，没有人引导，不知道在什么阶段应该干什么，或者怎么干，明明是个小兵，老板却恨不得你是个全才，啥事都希望你能搞定。有人把在大公司工作比喻是做一颗螺丝钉，而觉得在小公司才能锻炼综合能力，但我觉得在一定的阶段，螺丝钉似的工作才能让你在专业能力上面得到更大的提升，而小公司所谓的综合能力，往往演变的是“打杂”能力，老板为了节约成本，充分发挥（压榨）每个人的能力（价值），往往一人要分饰多角，比如做人事的既要管招聘，又要管行政，甚至还可能被拉去监督项目进度，很难让你在一个专业的领域深度成长。 再次在产品规模上，大公司产品的日活规模可能少则上百万，多则上亿，不论是在技术实现还是产品运营上，都需要较高的要求与水准，你在其中能学习的技能与套路是小公司日活几千或几万的产品规模无法比拟的。 最后在文化氛围上，一般大公司都有形成自己的企业文化，包括周围人的工作风格、习惯，都会对你产生潜移默化的影响。比如我现在的不论是写代码，还是写文字，都会反复检查好几遍的习惯就是在第一家公司工作时养成的。因为你的每一行代码你的leader可能都会仔细帮你review，找出有问题的地方让你反复修正直到合格，你的每一封邮件都会被别人（在外企很多时候还包括美国人、印度人）认真查看，所以促使你在发出前会仔细核查是否有遗漏的点，是否存在错别字或语法错误，久而久之，就养成了这种反复检查的比较严谨的做事风格。而在小公司，一般很难在短时间内形成自己的企业文化，很多事情的处理都比较粗放，缺乏对细节的把握，你很难从企业文化氛围上受益。 如果用游泳来比喻大公司与小公司的差异，我觉得大公司就像是一个掌握各项泳姿、动作标准的游泳运动员，有规范有节奏，从而游得更远；而小公司则更像一个会“狗爬式”的乡下野孩子，虽然路子野，但有效——尽管比较费力，但是能游起来，但能游多远，得看方向对不对，人能不能坚持。 平台效应因素现在有些企业招聘，都明确要求毕业院校必须是985、211，甚至有些岗位直接面向BAT。前不久看到一个案例，上海交大硕博毕业因本科不是211，而被招聘企业直接拒绝。 现实就是这样，看背景，看出身。名企工作与名校毕业一样，对后面的跳槽都会有较大的加分与优势。从小公司跳大公司难，但从大公司跳小公司就容易很多，见过许多阿里系的普通技术人员跳到中小企业做技术管理者的情况。 名企光环，除了对后面的就业与跳槽方面具备优势，在社会活动上也具备一定的优势，比如现在很多技术书籍，相当一部分出自阿里系，不是说非阿里系的人不具备这个能力，而是因为有着阿里这个名企光环，出的东西更容易被人接受与认可，尽管不一定水平有多好。 什么人适合去小公司毕竟不是每个人都能去大公司，那么什么人适合去小公司呢？我觉得可能主要包括两类，一类是自己在某个领域已经取得了较好的成长，具备了独当一面或者懂得如何带领他人来做事情的能力，这种情况一般是为了追求高薪或对某个领域或公司比较看好，有自己想法的人；另一类是目前还不具备进入大公司的资本与能力的人，人总得工作与生活，所以不得不先进入小公司成长，但这部分人除非自身公司发展特别好，否则还是应该尽力往大公司靠，努力进入大公司体验其管理模式与文化氛围，对你整个职业生涯是有很大帮助的。 选择什么样的小公司选择什么样的小公司比较好，虽然很多时候也没有太多的选择，毕竟好的小公司也是可遇不可求的事情，但如果有的话，我觉得还是尽力选择满足如下四个条件的小公司比较好。 靠谱的老板。小公司的管理文化与前途基本由老板的品质与能力决定，所以一个有能力、靠谱的老板是第一要素。 高水平的管理团队，技术、管理、营销各方面。管理团队对于创业公司来说非常重要，只有一个稳定的各方面成熟的团队，成功的几率才会大一点，你在里面能获得的成长空间也更多一些。 产品项目具备长远发展的潜力。企业经营就是做一个别人愿意花钱购买的产品，并寻找一个将产品源源不断卖不出的方式，所以产品是不是刚需，有没有人买单，能不能长久很重要。 可靠的资源与渠道。有可靠的资源与渠道，才能将产品源源不断地卖出去，企业才能保持可持续发展。 以上四点从上往下重要性依次递减，同时满足四个条件的小公司应该是极少的，是可遇不可求的事情，可以按从上往下的重要性进行选择。 另外进入小公司，可能常见的一个东西是期权，我认为期权是一个美丽的梦，如果以上四点都靠谱，没有期权也能获得很好的锻炼与成长，如果不靠谱，那么就算拿了期权大概率也是一个美丽的梦，看起来很美好，但不会成真的那种，所以面对期权（画饼），也要保持理性。 职场没有伊甸园最后，不论是大公司，还是小公司，都不存在职场的伊甸园，只有自己不断成长，进步，自己强大了，才有更多的选择空间。我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"Career","slug":"Career","permalink":"http://blog.jboost.cn/categories/Career/"}],"tags":[]},{"title":"Docker笔记（七）：常用服务安装——Nginx、MySql、Redis","slug":"docker-7","date":"2019-08-07T05:29:45.000Z","updated":"2019-08-07T10:18:30.564Z","comments":true,"path":"docker-7.html","link":"","permalink":"http://blog.jboost.cn/docker-7.html","excerpt":"开发中经常需要安装一些常用的服务软件，如Nginx、MySql、Redis等，如果按照普通的安装方法，一般都相对比较繁琐 —— 要经过下载软件或源码包，编译安装，配置，启动等步骤，使用 Docker 来安装这些服务软件能极大地简化安装过程，且速度也很快。","text":"开发中经常需要安装一些常用的服务软件，如Nginx、MySql、Redis等，如果按照普通的安装方法，一般都相对比较繁琐 —— 要经过下载软件或源码包，编译安装，配置，启动等步骤，使用 Docker 来安装这些服务软件能极大地简化安装过程，且速度也很快。 本文以下操作假定你已经装好了docker，并做好了镜像配置。如果没有，请参考 Docker笔记（三）：Docker安装与配置 1. MySql 安装1.1 下载镜像1~$ docker pull mysql:5.7 1.2 创建挂载目录1~$ mkdir -p apps/mysql/conf apps/mysql/data apps/mysql/logs 如上分别创建了配置文件目录，数据存放目录，以及日志文件目录 1.3 启动容器实例1~$ docker run -d -p 3306:3306 --name mysql -v /home/devuser/apps/mysql/conf/my.cnf:/etc/mysql/conf.d/my.cnf -v /home/devuser/apps/mysql/logs:/var/log/mysql -v /home/devuser/apps/mysql/data:/var/lib/mysql --restart=always -e MYSQL_ROOT_PASSWORD=Passw0rd mysql:5.7 其中-d： 表示在后台运行-p： 宿主机端口与容器端口映射–name： 容器名称-v： 宿主机目录与容器目录映射–restart=always：除非被docker stop命令明确停止，否则一直尝试重启处于停止态的容器；如果Docker重启，也会自动启动容器-e： 设置环境变量，这里设置了mysql root用户的密码为Passw0rd 如此，MySql服务就跑起来了，很快很简单有木有。 2. Redis 安装2.1 拉取镜像1~$ docker pull redis:5.0.5 2.2 启动容器1~$ docker run -d --name redis -p 6379:6379 -v /home/devuser/apps/redis/data:/data --restart=always redis:5.0.5 redis-server --appendonly yes --requirepass \"Passw1rd\" -p， -v 与上同，不赘述redis-server –appendonly yes : 在容器启动时执行redis-server命令，并打开redis持久化配置–requirepass： 设置密码 2.3 连接12345~$ docker exec -it redis redis-cli -h 172.17.0.4 -p 6379 -a Passw1rdWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.172.17.0.4:6379&gt; keys *(empty list or set)172.17.0.4:6379&gt; 这种方式把密码暴露了，其它登录用户通过history即可看到密码，不是太安全。可改用如下方式，123456789~$ docker exec -it redis redis-cli127.0.0.1:6379&gt;127.0.0.1:6379&gt; keys *(error) NOAUTH Authentication required.127.0.0.1:6379&gt; auth 'Passw1rd'OK127.0.0.1:6379&gt; keys *(empty list or set)127.0.0.1:6379&gt; 3. Nginx 安装3.1 拉取镜像1~$ docker pull nginx 会拉取最新的（latest）镜像 3.2 创建目录1~$ mkdir -p apps/nginx/html apps/nginx/logs apps/nginx/conf 3.3 先不指定映射路径启动一个容器12~$ docker run -d -p 80:80 --name nginx nginx1fdcd13457a6eaacb511878e10d84ffbe48fe63fd1fb3705f58b2d4195b151d8 这里如果直接指定映射路径运行会报错，123~$ docker run -d -p 80:80 --name nginx -v ~/apps/nginx/html:/usr/share/nginx/html -v ~/apps/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v ~/apps/nginx/logs:/var/log/nginx nginxdab56c13f9e76aad37fcf73411c78d495a6466f1c0d214949650dbae44adddf4docker: Error response from daemon: OCI runtime create failed: container_linux.go:345: starting container process caused \"process_linux.go:424: container init caused \\\"rootfs_linux.go:58: mounting \\\\\\\"/home/devuser/apps/nginx/conf/nginx.conf\\\\\\\" to rootfs \\\\\\\"/home/docker_image/overlay2/e40ccaf4d845a9af92487b47cbc4d505c5c776800ef8887c5b43833b10661427/merged\\\\\\\" at \\\\\\\"/home/docker_image/overlay2/e40ccaf4d845a9af92487b47cbc4d505c5c776800ef8887c5b43833b10661427/merged/etc/nginx/nginx.conf\\\\\\\" caused \\\\\\\"not a directory\\\\\\\"\\\"\": unknown: Are you trying to mount a directory onto a file (or vice-versa)? Check if the specified host path exists and is the expected type. 3.4 将运行容器的配置文件复制到宿主机目录下1~$ docker cp 1fdcd13457a6:/etc/nginx/nginx.conf ~/apps/nginx/conf/ 3.5 删除容器并重新运行123~$ docker stop 1fdcd1345~$ docker rm 1fdcd1345~$ docker run -d -p 80:80 --name nginx -v ~/apps/nginx/html:/usr/share/nginx/html -v ~/apps/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v ~/apps/nginx/logs:/var/log/nginx nginx 3.6 更新配置后重新加载1~$ docker kill -s HUP nginx 类似于 nginx -s reload 4. 总结本文没有总结。我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"}]},{"title":"Spring Boot（十一）：注解结合JWT实现简单的接口鉴权","slug":"springboot-simpleauth","date":"2019-08-01T12:45:59.000Z","updated":"2019-08-12T04:00:24.375Z","comments":true,"path":"springboot-simpleauth.html","link":"","permalink":"http://blog.jboost.cn/springboot-simpleauth.html","excerpt":"一般服务的安全包括认证（Authentication）与授权（Authorization）两部分，认证即证明一个用户是合法的用户，比如通过用户名密码的形式，授权则是控制某个用户可以访问哪些资源。比较成熟的框架有Shiro、Spring Security，如果要实现第三方授权模式，则可采用OAuth2。但如果是一些简单的应用，比如一个只需要鉴别用户是否登录的APP，则可以简单地通过注解+拦截器的方式来实现。本文介绍了具体实现过程，虽基于Spring Boot实现，但稍作修改（主要是拦截器配置）就可以引入其它Spring MVC的项目。","text":"一般服务的安全包括认证（Authentication）与授权（Authorization）两部分，认证即证明一个用户是合法的用户，比如通过用户名密码的形式，授权则是控制某个用户可以访问哪些资源。比较成熟的框架有Shiro、Spring Security，如果要实现第三方授权模式，则可采用OAuth2。但如果是一些简单的应用，比如一个只需要鉴别用户是否登录的APP，则可以简单地通过注解+拦截器的方式来实现。本文介绍了具体实现过程，虽基于Spring Boot实现，但稍作修改（主要是拦截器配置）就可以引入其它Spring MVC的项目。 1. 涉及的知识点 注解：用来标记某个接口是否需要登录 拦截器：拦截所有请求，判断请求的接口是否需要登录验证（基于是否标记了注解），如果需要，验证相应的信息（token），通过则放行，否则返回错误信息 JWT： Json Web Token，一种流行的认证解决方案，它可以生成携带信息的token，但token一旦生成，其过期时间就不好更新，如果需要实现用户有操作就自动延长过期时间的场景，就相对比较麻烦。我们这里只用来生成token，过期通过redis实现 RedisTemplate： 将token存在redis中，通过redis的过期机制来控制token的有效期 ThreadLocal：可以将一次请求中多个环节需要访问的变量通过ThreadLocal来传递，比如userId 2. 依赖配置在pom.xml中添加JWT与redis依赖123456789&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;$&#123;jwt.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 在application.yml配置文件中添加redis相关配置属性12345678910111213spring: redis: host: localhost port: 6379 database: 0 password: 123654 timeout: 3000 jedis: pool: min-idle: 2 max-idle: 8 max-active: 8 max-wait: 1000 3. 定义注解注解的定义你可以根据项目的具体场景，比如需要登录的接口比较多，就可以定义如 @SkipAuth 的注解来标记不需要登录的接口，反之，则可以定义如 @NeedAuth 的注解来标记需要登录的接口，总之就是让标记接口这个操作尽可能少。但也可以基于另一种考虑，万一需要登录的接口忘了加不就存在安全问题吗，所以用 @SkipAuth 相对要保险点。1234@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface SkipAuth &#123;&#125; 4. 定义token管理器123456789101112131415161718192021222324252627282930313233343536373839@Componentpublic class RedisTokenManager &#123; @Autowired private StringRedisTemplate redisTemplate; /** * 生成TOKEN */ public String createToken(String userId) &#123; //使用uuid作为源token String token = Jwts.builder().setId(userId).setIssuedAt(new Date()) .signWith(SignatureAlgorithm.HS256, JwtConstant.JWT_SECRET).compact(); //存储到redis并设置过期时间 redisTemplate.boundValueOps(JwtConstant.AUTHORIZATION + \":\" + userId) .set(token, JwtConstant.TOKEN_EXPIRES_HOUR, TimeUnit.HOURS); return token; &#125; public boolean checkToken(TokenModel model) &#123; if (model == null) &#123; return false; &#125; String token = redisTemplate.boundValueOps(JwtConstant.AUTHORIZATION + \":\" + model.getUserId()).get(); if (token == null || !token.equals(model.getToken())) &#123; return false; &#125; //如果验证成功，说明此用户进行了一次有效操作，延长token的过期时间 redisTemplate.boundValueOps(model.getUserId()) .expire(JwtConstant.TOKEN_EXPIRES_HOUR, TimeUnit.HOURS); return true; &#125; public void deleteToken(String userId) &#123; redisTemplate.delete(userId); &#125;&#125; 在登录接口通过时，调用 createToken 创建token，并保存到redis中，设置过期时间， 在调用未被 @SkipAuth 注解标记的接口时，调用 checkToken 来验证，并更新token的过期时间， 退出登录时，删除token。 5. 定义拦截器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@Component@Slf4jpublic class AuthInterceptor extends HandlerInterceptorAdapter &#123; @Autowired private RedisTokenManager tokenManager; public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; String requestPath = request.getRequestURI().substring(request.getContextPath().length()); // 如果不是映射到方法直接通过 if (!(handler instanceof HandlerMethod)) &#123; return true; &#125; HandlerMethod handlerMethod = (HandlerMethod) handler; Method method = handlerMethod.getMethod(); // 如果方法注明了 SkipAuth，则不需要登录token验证 if (method.getAnnotation(SkipAuth.class) != null) &#123; return true; &#125; // 从header中得到token String authorization = request.getHeader(JwtConstant.AUTHORIZATION); // 验证token if(StringUtils.isBlank(authorization))&#123; WebUtil.outputJsonString(ApiResponse.failed(\"未提供有效Token！\"), response); return false; &#125; try &#123; Claims claims = Jwts.parser().setSigningKey(JwtConstant.JWT_SECRET) .parseClaimsJws(authorization).getBody(); String userId = claims.getId(); TokenModel model = new TokenModel(userId, authorization); if (tokenManager.checkToken(model)) &#123; // 通过ThreadLocal设置下游需要访问的值 AuthUtil.setUserId(model.getUserId()); return true; &#125; else &#123; log.info(\"连接\" + requestPath + \"拒绝\"); WebUtil.outputJsonString(ApiResponse.failed(\"未提供有效Token！\"), response); return false; &#125; &#125; catch (Exception e) &#123; log.error(\"连接\" + requestPath + \"发生错误:\", e); WebUtil.outputJsonString(ApiResponse.failed(\"校验Token发生异常！\"), response); return false; &#125; &#125; @Override public void afterCompletion( HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) &#123; //结束后清除，否则由于线程池复用，导致ThreadLocal的值被其他用户获取 AuthUtil.clear(); &#125;&#125; 拦截器通过对请求方法是否标记注解 @SkipAuth 来判断是否需要进行token验证，如果验证通过，则从JWT token中解析出userId，通过AuthUtil工具方法保存到ThreadLocal中，供下游访问。在请求处理结束调用 afterCompletion 方法中，要清除掉ThreadLocal中的值，否则由于线程池的复用，导致被其他用户获取。 然后，注册拦截器1234567891011121314151617181920@Configurationpublic class WebConfiguration implements WebMvcConfigurer &#123; private AuthInterceptor authInterceptor; @Autowired public void setAuthInterceptor(AuthInterceptor authInterceptor)&#123; this.authInterceptor = authInterceptor; &#125; /** * 注册鉴权拦截器 * @param * @return */ public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(authInterceptor) .addPathPatterns(\"/**\") .excludePathPatterns(\"/error\"); &#125;&#125; 这里将 /error 这个接口排除了，因为如果接口处理过程中出现异常，则spring boot会自动跳转到 /error 接口，又会进入拦截器校验（因为/error接口没有标注 @SkipAuth 注解）。 6. 验证通过以上几步，一个简单的接口认证功能就实现了，我们可以通过添加一个登录接口，两个测试接口（一个需要认证，一个不需要认证）来验证下。登录接口1234567891011@SkipAuth@RequestMapping(\"/login\")public ApiResponse login(@RequestBody Map&lt;String, Object&gt; params) &#123; String username = MapUtils.getString(params, \"username\"); String password = MapUtils.getString(params, \"password\"); if(\"ksxy\".equals(username) &amp;&amp; \"jboost\".equals(password))&#123; return ApiResponse.success(tokenManager.createToken(username)); &#125; else &#123; return ApiResponse.failed(\"用户名或密码错误\"); &#125;&#125; 登录成功后，通过createToken方法创建了JWT token。测试接口12345678910@SkipAuth@RequestMapping(\"/skip-auth\")public ApiResponse skipAuth() &#123; return ApiResponse.success(\"不需要认证的接口调用\");&#125;@RequestMapping(\"/need-auth\")public ApiResponse needAuth() &#123; return ApiResponse.success(\"username: \" + AuthUtil.getUserId());&#125; 7. 总结本文介绍了一个简单的接口认证方案，适用于不需要基于用户角色进行授权的场景。如果有较复杂的授权需求，则还是基于Shiro， Spring Security， OAuth2等框架来实现。这里也可以不用JWT，但是需要自己去做一些处理，比如将userId以某种形式包含在token中，解析时取出。本文完整实例代码：https://github.com/ronwxy/springboot-demos/tree/master/springboot-simpleauth","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"老被跨域问题烦？看看都有哪些处理方法","slug":"cors","date":"2019-07-30T04:56:24.000Z","updated":"2019-07-31T05:39:09.209Z","comments":true,"path":"cors.html","link":"","permalink":"http://blog.jboost.cn/cors.html","excerpt":"前面写的《IT技术人员的自我修养》，没想到几天内收到了不少良好的反馈，在此也感谢大家的关注。往后会不定时分享一些技术、管理领域的工作经验总结与感悟，欢迎大家持续关注、交流。最近被问及一个跨域的问题，包括之前面试时发现很多面试者对跨域及其处理也是一知半解，故本文对该问题进行了梳理总结，以供参考。","text":"前面写的《IT技术人员的自我修养》，没想到几天内收到了不少良好的反馈，在此也感谢大家的关注。往后会不定时分享一些技术、管理领域的工作经验总结与感悟，欢迎大家持续关注、交流。最近被问及一个跨域的问题，包括之前面试时发现很多面试者对跨域及其处理也是一知半解，故本文对该问题进行了梳理总结，以供参考。 1. 什么是跨域理解什么是跨域，就要先了解一个叫“同源策略”的东西，什么是“同源策略”？这是浏览器为了网站访问安全，对来自不同源的请求做一些必要的访问限制的一种策略。那什么叫“同源”呢？我们知道，一个http请求地址一般包含四部分：协议://域名:端口/路径，所谓同源，就是前面三者，即协议、域名、端口都一样。举例说明，假如我们有一个地址 http://blog.jboost.cn/docker-1.html， 来看以下地址是否与它同源 地址 是否同源 说明 https://blog.jboost.cn/docker-1.html 不同源 协议不同，一个http，一个https http://www.jboost.cn/docker-1.html 不同源 域名不同 http://blog.jboost.cn:8080/docker-1.html 不同源 端口不同，一个是默认端口80，一个是8080 http://blog.jboost.cn/docker-2.html 同源 虽然路径不同，但协议、域名、端口（默认80）都相同 那么浏览器对不同源的请求做了哪些访问限制呢？共有三种限制 对Cookie、LocalStorage，以及IndexDB（浏览器提供的类NoSQL的一个本地数据库）的访问 对DOM的访问 AJAX请求 而跨域就是要打破这种访问限制，对不同源的资源请求也能顺利进行，最常见的就是AJAX请求，比如前后端分离架构中，两者服务域名不同，前端通过AJAX直接访问服务端接口，就会存在跨域问题。 2. 为什么会存在跨域前面说“同源策略”时已经提到，浏览器是为了网站的访问安全，才设置了跨域这道屏障。那么前面所说的三种限制，分别都是如何来保障网站安全的。 对本地存储Cookie、LocalStorage、IndexDB的访问限制我们系统的登录凭证一般是通过在Cookie中设置 SESSIONID（如针对浏览器表单请求）或直接返回 token（如针对REST请求）的形式返回给客户端的，比如Tomcat是通过在Cookie中设置名为 JSESSIONID 的属性来保存的，而一般REST请求的token前端会存储于 LocalStorage 中，如果不存在访问限制，则你访问的其它网站可能就会获取到这些凭证，然后伪造你的身份来发起非法请求，这就太不安全了。 对DOM的访问限制如果不对DOM进行访问限制，那么其它网站，尤其一些钓鱼网站，就可以通过 &lt;iframe&gt; 的形式拿到你访问网站的DOM，进而获取到你输入的一些敏感信息，比如用户名、密码… 对AJAX请求的限制同源策略规定，AJAX请求只能发给同源的网址，否则就会报错。至于为什么要限制，一方面是避免1中所提到伪造非法请求，另一方面我理解是AJAX过于灵活，如果不做限制，可能网站的接口资源就会被其它网站随意使用，就像你的私有物品被别人招呼都不打任意拿去用一样。 总之，同源策略是浏览器提供的最基本的一种安全保障机制或约定。 3. 怎么实现跨域访问我们平常遇到的跨域问题基本都出现在AJAX请求的场景，一般而言，可以通过代理、CORS、JSONP等方式来解决跨域问题。 3.1 代理既然“同源策略”是浏览器端的机制，那我们就可以绕开浏览器，最常见的做法就是使用代理，如 Nginx，比如我们前端项目的域名是 http://blog.jboost.cn，服务端接口域名是 http://api.jboost.cn，我们在 Nginx 中提供如下配置12345678910server&#123; # 端口 listen 80; # 域名 server_name blog.jboost.cn; # 所有 http://blog.jboost.cn/api/xxx 请求都会被转发到 http://api.jboost.cn/api/xxx location ^~ /api &#123; proxy_pass http://api.jboost.cn; &#125; &#125; 则前端通过AJAX请求服务端接口 http://api.jboost.cn/api/xxx 都可以改为通过 http://blog.jboost.cn/api/xxx 来访问，从而避免不同源的跨域问题。 3.2 CORSCORS是Cross-Origin Resource Sharing的简写，即跨域资源共享，CORS需要服务端与浏览器同时支持，目前所有浏览器（除IE10以下）都支持CORS，因此，实现CORS，主要就是服务端的工作了。例如在Spring Boot中，我们可通过如下配置注册一个CorsFilter的过滤器来实现跨域支持。12345678910111213141516171819202122232425@Configuration@ConditionalOnClass(&#123;Servlet.class, CorsFilter.class&#125;)public class CORSAutoConfiguration &#123; @Bean @ConditionalOnMissingBean(name = \"corsFilterRegistrationBean\") public FilterRegistrationBean corsFilterRegistrationBean() &#123; UrlBasedCorsConfigurationSource corsConfigurationSource = new UrlBasedCorsConfigurationSource(); CorsConfiguration corsConfiguration = new CorsConfiguration(); corsConfiguration.applyPermitDefaultValues(); corsConfiguration.setAllowedMethods(Arrays.asList(CorsConfiguration.ALL)); corsConfiguration.addExposedHeader(HttpHeaders.DATE); corsConfigurationSource.registerCorsConfiguration(\"/**\", corsConfiguration); CorsFilter corsFilter = new CorsFilter(corsConfigurationSource); FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); filterRegistrationBean.setFilter(corsFilter); filterRegistrationBean.setOrder(Ordered.HIGHEST_PRECEDENCE); filterRegistrationBean.addUrlPatterns(\"/*\"); return filterRegistrationBean; &#125;&#125; 其实质就是在响应消息的Header中添加几个属性，主要有 Access-Control-Allow-Origin 必需，表示允许跨域的请求源，可以是具体的域名，也可以是 * ，表示任意域名 Access-Control-Allow-Methods 必需，表示允许跨域访问的HTTP方法，如GET、POST、PUT、DELETE等，可以是 * ，表示所有 Access-Control-Allow-Headers 如果请求包括 Access-Control-Request-Headers 头信息，则必需，表示服务器支持的所有头信息字段 3.3 JSONPJSONP是利用浏览器对JS一些标签（如 &lt;script&gt;, &lt;img&gt;等）的 src 属性不具有同源策略限制的特性实现的，如前端添加1&lt;script type=\"text/javascript\" src=\"http://api.jboost.cn/hello?name=jboost&amp;callback=jsonpCallback\"/&gt; 并且定义JS方法 jsonpCallback。服务端接口返回内容需要是JS方法jsonpCallback的调用格式，如jsonpCallback({&quot;name&quot;:&quot;jboost&quot;})，这样在jsonpCallback方法中就可以获取服务端实际返回的结果数据{&quot;name&quot;:&quot;jboost&quot;}了。JSONP方式的局限性也很明显，一是只支持GET请求——你没见过哪些&lt;script&gt;, &lt;img&gt;标签是POST请求吧，二是需要对服务端返回数据格式做处理。 4. 总结三种跨域支持的实现，代理方式最简单，对客户端、服务端都不具有侵入性，但如果需要支持的请求源比较多，或者是与第三方对接的话，代理方式就不太适用了。CORS相对来说是一种标准的处理方式，并且通过过滤器的方式对业务代码也没有任何侵入性。而JSONP方式局限性较大，只支持GET，并且需要服务端做返回数据格式的支持。可针对具体情况选择适用的方式。","categories":[{"name":"高效实践","slug":"高效实践","permalink":"http://blog.jboost.cn/categories/高效实践/"}],"tags":[{"name":"web","slug":"web","permalink":"http://blog.jboost.cn/tags/web/"}]},{"title":"Spring Boot从入门到实战（十）：异步处理","slug":"springboot-async","date":"2019-07-22T10:25:49.000Z","updated":"2019-07-24T01:52:03.885Z","comments":true,"path":"springboot-async.html","link":"","permalink":"http://blog.jboost.cn/springboot-async.html","excerpt":"在业务开发中，有时候会遇到一些非核心的附加功能，比如短信或微信模板消息通知，或者一些耗时比较久，但主流程不需要立即获得其结果反馈的操作，比如保存图片、同步数据到其它合作方等等。如果将这些操作都置于主流程中同步处理，势必会对核心流程的性能造成影响，甚至由于第三方服务的问题导致自身服务不可用。这时候就应该将这些操作异步化，以提高主流程的性能，并与第三方解耦，提高主流程的可用性。","text":"在业务开发中，有时候会遇到一些非核心的附加功能，比如短信或微信模板消息通知，或者一些耗时比较久，但主流程不需要立即获得其结果反馈的操作，比如保存图片、同步数据到其它合作方等等。如果将这些操作都置于主流程中同步处理，势必会对核心流程的性能造成影响，甚至由于第三方服务的问题导致自身服务不可用。这时候就应该将这些操作异步化，以提高主流程的性能，并与第三方解耦，提高主流程的可用性。 在Spring Boot中，或者说在Spring中，我们实现异步处理一般有以下几种方式： 1. 通过 @EnableAsync 与 @Asyc 注解结合实现2. 通过异步事件实现3. 通过消息队列实现 1. 基于注解实现我们以前在Spring中提供异步支持一般是在配置文件 applicationContext.xml 中添加类似如下配置12&lt;task:annotation-driven executor=\"executor\" /&gt;&lt;task:executor id=\"executor\" pool-size=\"10-200\" queue-capacity=\"2000\"/&gt; Spring的 @EnableAsync 注解的功能与&lt;task:annotation-driven/&gt;类似，将其添加于一个 @Configuration 配置类上，可对Spring应用的上下文开启异步方法支持。 @Async 注解可以标注在方法或类上，表示某个方法或某个类里的所有方法需要通过异步方式来调用。 我们以一个demo来示例具体用法，demo地址：https://github.com/ronwxy/springboot-demos/tree/master/springboot-async 添加 @EnableAsync 注解 在一个 @Configuration 配置类上添加 @EnableAysnc 注解，我们一般可以添加到启动类上，如12345678@SpringBootApplication@EnableAsyncpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 配置相关的异步执行线程池 可通过配置类的方式对异步线程池进行配置，并提供异步执行时出现异常的处理方法，如1234567891011121314151617181920212223242526272829303132333435363738394041@Configurationpublic class AsyncConfig implements AsyncConfigurer &#123; @Value(\"$&#123;async.corePoolSize:10&#125;\") private int corePoolSize; @Value(\"$&#123;async.maxPoolSize:200&#125;\") private int maxPoolSize; @Value(\"$&#123;async.queueCapacity:2000&#125;\") private int queueCapacity; @Value(\"$&#123;async.keepAlive:5&#125;\") private int keepAlive; public Executor getAsyncExecutor() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(corePoolSize); executor.setMaxPoolSize(maxPoolSize); executor.setQueueCapacity(queueCapacity); executor.setKeepAliveSeconds(keepAlive); executor.setThreadNamePrefix(\"async-\"); executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); executor.setDaemon(false); //以用户线程模式运行 executor.initialize(); return executor; &#125; public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() &#123; return new MyAsyncUncaughtExceptionHandler(); &#125; public static class MyAsyncUncaughtExceptionHandler implements AsyncUncaughtExceptionHandler &#123; public void handleUncaughtException(Throwable throwable, Method method, Object... objects) &#123; System.out.println(\"catch exception when invoke \" + method.getName()); throwable.printStackTrace(); &#125; &#125;&#125; 这里我们通过实现 AsyncConfigurer 接口提供了一个异步执行线程池对象，各参数的说明可以参考【线程池的基本原理，看完就懂了】，里面有很详细的介绍。且通过实现 AsyncUncaughtExceptionHandler 接口提供了一个异步执行过程中未捕获异常的处理类。 定义异步方法 异步方法的定义只需要在类（类上注解表示该类的所有方法都异步执行）或方法上添加 @Async 注解即可，如12345678910111213@Servicepublic class AsyncService &#123; @Async public void asyncMethod()&#123; System.out.println(\"2. running in thread: \" + Thread.currentThread().getName()); &#125; @Async public void asyncMethodWithException() &#123; throw new RuntimeException(\"exception in async method\"); &#125;&#125; 测试 我们可以通过如下测试类来对异步方法进行测试 1234567891011121314151617181920212223@RunWith(SpringRunner.class)@SpringBootTestpublic class AnnotationBasedAsyncTest &#123; @Autowired private AsyncService asyncService; @Test public void testAsync() throws InterruptedException &#123; System.out.println(\"1. running in thread: \" + Thread.currentThread().getName()); asyncService.asyncMethod(); Thread.sleep(3); &#125; @Test public void testAysncWithException() throws InterruptedException &#123; System.out.println(\"1. running in thread: \" + Thread.currentThread().getName()); asyncService.asyncMethodWithException(); Thread.sleep(3); &#125;&#125; 因为异步方法在一个新的线程中执行，可能在主线程执行完后还没来得及处理，所以通过sleep来等待它执行完成。具体执行结果读者可自行尝试运行，这里就不贴图了。 2. 基于事件实现第二种方式是通过Spring框架的事件监听机制实现，但Spring的事件监听默认是同步执行的，所以实际上还是需要借助 @EnableAsync 与 @Async 来实现异步。 添加 @EnableAsync 注解 与上同，可添加到启动类上。 自定义事件类通过继承 ApplicationEvent 来自定义一个事件 1234567891011public class MyEvent extends ApplicationEvent &#123; private String arg; public MyEvent(Object source, String arg) &#123; super(source); this.arg = arg; &#125; //getter/setter&#125; 定义事件处理类支持两种形式，一是通过实现 ApplicationListener 接口，如下 123456789@Component@Asyncpublic class MyEventHandler implements ApplicationListener&lt;MyEvent&gt; &#123; public void onApplicationEvent(MyEvent event) &#123; System.out.println(\"2. running in thread: \" + Thread.currentThread().getName()); System.out.println(\"2. arg value: \" + event.getArg()); &#125;&#125; 二是通过 @EventListener 注解，如下12345678910@Componentpublic class MyEventHandler2 &#123; @EventListener @Async public void handle(MyEvent event)&#123; System.out.println(\"3. running in thread: \" + Thread.currentThread().getName()); System.out.println(\"3. arg value: \" + event.getArg()); &#125;&#125; 注意两者都需要添加 @Async 注解，否则默认是同步方式执行。 定义事件发送类可以通过实现 ApplicationEventPublisherAware 接口来使用 ApplicationEventPublisher 的 publishEvent()方法发送事件， 12345678910111213@Componentpublic class MyEventPublisher implements ApplicationEventPublisherAware &#123; protected ApplicationEventPublisher applicationEventPublisher; public void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) &#123; this.applicationEventPublisher = applicationEventPublisher; &#125; public void publishEvent(ApplicationEvent event)&#123; this.applicationEventPublisher.publishEvent(event); &#125;&#125; 测试 可以通过如下测试类来进行测试，1234567891011121314@RunWith(SpringRunner.class)@SpringBootTestpublic class EventBasedAsyncTest &#123; @Autowired private MyEventPublisher myEventPublisher; @Test public void testAsync() throws InterruptedException &#123; System.out.println(\"1. running in thread: \" + Thread.currentThread().getName()); myEventPublisher.publishEvent(new MyEvent(this,\"testing event based async\")); Thread.sleep(3); &#125;&#125; 运行后发现两个事件处理类都执行了，因为两者都监听了同一个事件 MyEvent 。 3. 基于消息队列实现以上两种方式都是基于服务器本机运行，如果服务进程出现异常退出，可能导致异步执行中断。如果需要保证任务执行的可靠性，可以借助消息队列的持久化与重试机制。阿里云上的消息队列服务提供了几种类型的消息支持，如顺序消息、定时/延时消息、事务消息等（详情可参考：https://help.aliyun.com/document_detail/29532.html?spm=5176.234368.1278132.btn4.6f43db25Rn8oey ），如果项目是基于阿里云部署的，可以考虑使用其中一类消息服务来实现业务需求。 4. 总结本文对spring boot下异步处理的几种方法进行了介绍，如果对任务执行的可靠性要求不高，则推荐使用第一种方式，如果可靠性要求较高，则推荐使用自建消息队列或云消息队列服务的方式。本文demo源码地址：https://github.com/ronwxy/springboot-demos/tree/master/springboot-async/src/main/java/cn/jboost/async我的个人博客地址：http://blog.jboost.cn我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"Docker笔记（六）：容器管理","slug":"docker-6","date":"2019-07-21T03:04:16.000Z","updated":"2019-07-22T10:24:14.304Z","comments":true,"path":"docker-6.html","link":"","permalink":"http://blog.jboost.cn/docker-6.html","excerpt":"容器是Docker中的另一核心概念，在Docker中，应用的运行都是在容器内进行的，容器则基于镜像创建。前面已对Docker镜像做了基本介绍，本文对Docker容器管理的相关内容做一个梳理。","text":"容器是Docker中的另一核心概念，在Docker中，应用的运行都是在容器内进行的，容器则基于镜像创建。前面已对Docker镜像做了基本介绍，本文对Docker容器管理的相关内容做一个梳理。 1. 启动容器启动容器的命令格式如下1docker run [OPTIONS] IMAGE-NAME [COMMAND] [ARG...] 其中OPTIONS部分可指定容器运行的一些可选项，常用选项包括： -d 将容器以后台进程（daemon）的形式运行 -p 指定容器内应用暴露端口与主机端口的映射，如 -p 8080:80 表示将容器内80端口映射到主机的8080端口（主机端口在前，容器端口在后） -v 指定容器与主机的挂载目录映射，如 -v /var/log:/log 表示将容器的/log目录挂载到主机的/var/log目录（同样主机目录在前，容器目录在后），后续对容器的/log写操作实际作用于主机的/var/log目录 -e 为容器设置环境变量 -t 为容器启动一个伪终端（pseudo-tty） -i 让容器的标准输入保持打开，一般与 -t 配合使用，让容器启动后就打开一个可交互的命令行界面 -w 指定容器的工作目录 COMMAND [ARG..] 部分就是容器需要运行的应用进程启动命令与参数，如果镜像中有通过 CMD， 或 ENTRYPOINT 指定了容器启动程序，则可省略。另外可通过 –name 指定容器的名称，以及 –restart 来指定重启策略，–restart有三种取值，代表容器支持的三种不同的重启策略 取值 描述 always 除非被docker stop命令明确停止，否则一直尝试重启处于停止态的容器；如果Docker重启，也会自动启动容器 unless-stopped 与always的区别是，停止态的容器不在Docker重启的时候被重启 on-failed 在容器退出时返回值不为0的时候，重启容器；如果Docker重启，容器也会被启动，不管之前是否处于停止状态 以启动一个mysql数据库服务为例12345docker run -d -p 3306:3306 --name mysql \\ -v /home/devuser/apps/mysql/conf/my.cnf:/etc/mysql/conf.d/my.cnf \\ -v /home/devuser/apps/mysql/logs:/var/log/mysql \\ -v /home/devuser/apps/mysql/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=Passw0rd --restart=always mysql:5.7 上述命令启动了一个mysql容器服务，-d 表示以后台进程运行，执行命令后只返回一个容器ID，不会输出任何其它信息；-p 将容器暴露的端口3306映射到宿主机的3306端口，外部主机就可以通过宿主机IP与3306端口来访问mysql服务； –name 指定了容器名称为mysql； -v 将mysql的配置文件路径、日志路径、数据存储路径映射到了宿主机对应的路径目录；-e 设置了一个环节变量指定mysql root账号的密码；–restart 指定容器在异常退出时，包括Docker重启时，自动启动容器。 我们前面有提过，当我们执行CLI命令时，实际上是客户端（Docker Client）通过发送请求到Docker后台进程（Docker Daemon），由Docker后台进程来执行的，那么当我们执行上述docker run命令的时候，Docker后台进程具体都干了些啥呢？一般来说，包括如下几个操作步骤 检测本地是否存在指定的镜像，如果不存在，就从公共仓库下载 利用镜像创建一个容器，并启动它 分配一个文件系统，并在只读的镜像层上面挂载一层可读写层（容器存储层） 从宿主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行应用程序完毕后容器被终止 2. 管理已有容器一般对已有容器的管理包括如下几个操作： 查看运行中的容器 docker ps 或 docker container ls 查看所有容器 docker ps -a 或 docker container ls -a 停止运行 docker stop xxx 开始停止状态的容器 docker start xxx 重启运行状态的容器 docker restart xxx 删除停止状态的容器 docker rm xxx 强制删除容器（包括运行状态中） docker rm -f xxx 删除所有停止状态的容器 docker container prune 其中xxx既可以是容器ID（短ID即可，只要与其它区分开来），也可以是容器名称。docker rm之前必须要先docker stop将容器置为停止状态，而docker rm -f可以强制删除运行状态的容器，其背后是通过Linux/POSIX信号来实现的，docker rm -f命令直接发出SIGKILL信号，不会给容器内运行进程任何缓冲的时间，立即终止，而docker stop命令却是先发送SIGTERM信号，通知容器进程结束，会为进程预留一个清理并优雅停止的机会，如果一段时间后进程还没有终止，那么就会发送SIGKILL信号，来终止进程的运行。 我们也可以像镜像操作中一样，组合使用命令来更方便地操作，如强制删除所有容器（慎用）1docker rm -f $(docker ps -aq) 3. 进入容器容器在运行时指定 -d 选项时， 是以后台进程的形式运行的，如果我们需要进入容器查看或操作，可以通过docker exec命令，docker exec命令的格式如下1docker exec [OPTIONS] container-id COMMAND OPTIONS常用的一般是 -t， -i，意义跟在docker run选项中一样 —— 为容器启动一个伪终端（pseudo-tty），并保持标准输入打开，从而可以像Linux命令行一样进行交互， COMMAND一般为 bash。 另外还有一个命令是docker attach xxx，其中xxx是容器ID，但推荐使用docker exec，因为docker attach中当执行exit退出容器时，容器也会随之终止，但docker exec则不会。 如果不进入容器，也可以通过docker logs xxx，xxx是容器ID，来查看容器的输出信息。 4. 导入导出容器可以使用docker export命令将一个容器的快照进行导出，如1docker export xxx &gt; mycontainer.tar 其中xxx是容器ID，可以通过docker ps -a查看，上述命令将容器的当前快照导出到了本地文件。 docker import命令则可以将一个容器快照文件导入为镜像，如1cat mycontainer.tar | docker import - test/myimage:v1.0 可以通过URL来导入，如1docker import http://test.com/testimage.tgz test/myimage2:v1.0 由此可见，我们获取镜像又多了一个来源——从已有容器快照文件导入。 5. 总结本文对容器的一些基本操作进行了介绍，需要注意的是如之前所说，容器应以无状态的形式运行，所有产生的数据应该通过挂载数据卷的方式写入宿主机文件目录，避免容器销毁时造成数据丢失；尽量使用docker stop + docker rm的方式来替代docker rm -f，使容器内运行程序“优雅”地退出。有时候可能遇到这样的场景，容器创建运行后，我们需要对运行的一些参数进行更新或添加，这时候该怎么操作。后文会对该场景进行介绍，欢迎关注。 我的个人博客地址：http://blog.jboost.cn我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"}]},{"title":"Docker笔记（五）：整一个自己的镜像","slug":"docker-5","date":"2019-07-17T08:32:35.000Z","updated":"2019-07-24T01:51:09.675Z","comments":true,"path":"docker-5.html","link":"","permalink":"http://blog.jboost.cn/docker-5.html","excerpt":"获取镜像的途径有两个，一是从镜像仓库获取，如官方的Docker Hub，二是自定义。上文已经介绍如何从镜像仓库获取镜像，本文基于一个Springboot项目，来介绍自定义一个镜像的基本流程。","text":"获取镜像的途径有两个，一是从镜像仓库获取，如官方的Docker Hub，二是自定义。上文已经介绍如何从镜像仓库获取镜像，本文基于一个Springboot项目，来介绍自定义一个镜像的基本流程。 1. 定制镜像的本质我们知道镜像是分层存储的，镜像的构建也是一层一层进行的，一层构建完后，就变为只读，在其上再构建下一层。因此定制镜像，实际上就是定义每一层要干的事，比如执行某个命令，设置一个环境变量，声明一个暴露端口等等。然后在构建时，按照各层的定义，一层一层地完成构建，最终形成一个包含这些层的镜像。 2. Dockerfile文件Docker中定义各层要干的事的文件叫Dockerfile，它是一个文本文件，包含了一条条的指令，每一条指令对应一层镜像，指令的内容就描述了这一层该如何构建。如下示例了一个非常简单的Dockerfile，12FROM nginxRUN echo &apos;&lt;h1&gt;Hello jboost!&lt;/h1&gt;&apos; &gt; /usr/share/nginx/html/index.html 我们定制镜像，必须要以某一个镜像为基础，在其上构建自己需要的层，如上示例中，我们是以nginx镜像为基础，然后在第二层定制了我们自己的内容——修改index.html的内容为&lt;h1&gt;Hello jboost!&lt;/h1&gt;，这样运行容器打开nginx主页时就不会显示默认的页面内容了。 上面示例中接触了Dockerfile的两个指令 FROM：FROM指令指定基础镜像，每一个定制镜像必须要有一个基础镜像，所以必须要有一条FROM指令，并且是Dockerfile的第一条指令 RUN：RUN指令指定需要执行的命令，后面接的命令就像是shell脚本一样可执行 Dockerfile还提供了许多其它指令，后续我们再集中介绍，本文只对接触到的指令做简单说明。 3. 自定义一个镜像这部分以一个Springboot项目为基础，介绍自定义一个镜像涉及的基本环节。项目地址为：https://github.com/ronwxy/swagger-register ，该项目是一个Swagger API文档注册服务，其它项目可将Swagger API信息注册到该服务，进行统一查看与管理。 3.1 定义Dockerfile文件首先，我们在项目的根目录下创建一个Dockerfile文件（文件名就叫Dockerfile），其内容为：12345678FROM openjdk:8-jdk-alpineENV PROFILE=devRUN mkdir /app /logsCOPY ./target/swagger-register-1.0.0-SNAPSHOT.jar /app/app.jarWORKDIR /appVOLUME /register-dataEXPOSE 11090CMD [&quot;java&quot;, &quot;-Dspring.profiles.active=$&#123;PROFILE&#125;&quot;, &quot;-jar&quot;, &quot;app.jar&quot;] 从上往下依次介绍如下 第一行：FORM openjdk:8-jdk-alpine， 表示以openjdk:8-jdk-alpine这个镜像为基础镜像，因为这是一个Springboot项目所以必须要有jdk支持，我们在定制镜像时，可以找一个最适合的镜像作为基础镜像。 第二行：ENV PROFILE=dev， 定义了一个环境变量，这个环境变量可以在后面被引用 第三行：RUN mkdir /app /logs，通过mkdir命令创建了两个目录，用来保存jar执行文件及日志 第四行：COPY ./target/swagger-register-1.0.0-SNAPSHOT.jar /app/app.jar 将target目录下的jar包复制到/app目录下，并且进行重命名 第五行：WORKDIR /app， 指定工作目录为/app，后面各层的当前目录就是指定的工作目录 第六行：VOLUME /register-data， 定义一个匿名数据卷，前面说过写操作不要直接在容器内进行，而要改为写挂载的数据卷目录，这个定义可在运行容器时通过 -v 来覆盖。 第七行：EXPOSE 11090， 声明了运行容器时提供的服务端口，也仅仅是个声明而已，只是告诉使用的人要映射这个端口，通过 -p 可映射端口。 第八行：CMD [“java”, “-Dspring.profiles.active=${PROFILE}”, “-jar”, “app.jar”]， 指定了容器启动命令，因为是一个Springboot项目，所以就是一个java -jar的执行命令，容器启动的时候就会执行该命令来运行Springboot服务，这里引用了第二行定义的环境变量PROFILE 3.2 配置maven插件定义好Dockerfile后，为了方便构建镜像，我们可以借助maven的dockerfile插件dockerfile-maven-plugin，在pom.xml的build部分加入配置如下 123456789101112131415161718192021&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- Docker maven plugin --&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.4.10&lt;/version&gt; &lt;configuration&gt; &lt;repository&gt;$&#123;docker.image.prefix&#125;/$&#123;project.artifactId&#125;&lt;/repository&gt; &lt;buildArgs&gt; &lt;JAR_FILE&gt;target/$&#123;project.build.finalName&#125;.jar&lt;/JAR_FILE&gt; &lt;/buildArgs&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- Docker maven plugin --&gt; &lt;/plugins&gt;&lt;/build&gt; repository指定了镜像的名称，docker.image.prefix需要properties部分进行定义，我这里是springboot。 3.3 构建镜像下载源码：https://github.com/ronwxy/swagger-register.git ，然后在项目的根目录下执行如下命令(前提是本地已经装好了docker与maven及jdk)1mvn clean package -Dmaven.test.skip=true dockerfile:build 该命令首先会执行mvn clean package -Dmaven.test.skip=true对项目进行打包，生成./target/swagger-register-1.0.0-SNAPSHOT.jar文件，然后基于当前目录下的Dockerfile文件进行构建，如下图所示 由上图可看出，该镜像构建分八步(对应Dockerfile的八行指令)，每一步生成一个镜像层，每一层都有唯一的ID。由图中也可以看出，除了COPY之类的命令外，每一层的构建实际上是先基于上一层启动一个容器，然后执行该层定义的操作，再移除这个容器来实现的，如第八步中12345Step 8/8 : CMD [\"java\", \"-Dspring.profiles.active=$&#123;PROFILE&#125;\", \"-jar\", \"app.jar\"][INFO] [INFO] ---&gt; Running in f4acd0b53bca[INFO] Removing intermediate container f4acd0b53bca[INFO] ---&gt; a9ee579f2d62 先启动一个ID为f4acd0b53bca的容器，在其中执行CMD所定义的命令，然后再移除容器f4acd0b53bca，最后生成ID为a9ee579f2d62的镜像。 构建完后，我们就可以在本地镜像中通过docker iamges看到我们定制的镜像了，如图 图中springboot/swagger-register镜像即为我们刚刚构建好的定制镜像。 3.4 启动容器我们可以通过以下命令来启动一个刚才定制镜像的容器1docker run -d --name swagger-register -p 11090:11090 -v /home/jenkins/swagger-register/register-data:/register-data -v /home/jenkins/swagger-register/logs:/logs --restart=always springboot/swagger-register:latest 其中： -d 表示以后台进程方式运行 –name 指定容器名称 -p 指定端口映射，左边为宿主机端口，右边为容器服务端口 -v 指定数据卷挂载，左边为宿主机目录，右边为容器目录 –restart=always 表示在docker启动时自动启动该容器 关于容器相关的内容后面详细介绍，这里不展开说明了。启动容器后， 我们就可以浏览器打开地址 http://宿主机ip:11090/doc.html 来访问服务了（打开页面后内容是空的，因为没有任何服务注册Swagger API， 相关内容可参考 swagger api文档集中化注册管理） 4. 总结本文介绍了一个基于Springboot项目的Docker镜像定制及使用过程，对镜像的构建过程，及Dockerfile的基本指令以及容器的运行做了基本介绍。后续会对Dockerfile的其它指令及Dockerfile的一些最佳实践进行更为详细的介绍，欢迎关注。我的个人博客地址：http://blog.jboost.cn我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"}]},{"title":"Docker笔记（四）：Docker镜像管理","slug":"docker-4","date":"2019-07-16T13:22:11.000Z","updated":"2019-07-24T01:51:02.477Z","comments":true,"path":"docker-4.html","link":"","permalink":"http://blog.jboost.cn/docker-4.html","excerpt":"在Docker中，应用是通过容器来运行的，而容器的运行是基于镜像的，类似面向对象设计中类与对象的关系——没有类的定义就谈不上实例的创建与使用，没有镜像的定义就谈不上容器的创建与运行。","text":"在Docker中，应用是通过容器来运行的，而容器的运行是基于镜像的，类似面向对象设计中类与对象的关系——没有类的定义就谈不上实例的创建与使用，没有镜像的定义就谈不上容器的创建与运行。 1. 获取镜像镜像从哪里来，一般两个途径，一是公共镜像库，如官方镜像库Docker Hub，上面有大量的高质量的镜像直接可拿来用；二是自定义，我们可基于一个已有镜像，在其基础上增加一些层（还记得镜像的分层存储特性吧），然后构建形成自己的镜像。 如果我们知道某个镜像的名称，则可直接通过docker pull来下载镜像到本地，如ubuntu、redis、nginx等，docker pull命令的格式如下1docker pull [选项] [Docker Registry的地址[:端口号]/]仓库名[:标签] 其中选项可设置： -a, –all-tags：下载仓库中所有标签（一般指版本）的镜像 –disable-content-trust：跳过镜像验证，默认为true Docker Registry的地址即镜像仓库地址，一般为域名或IP加端口号，如果不指定则默认为Docker Hub；仓库名包含两部分，&lt;用户名&gt;/&lt;软件名&gt;，对于Docker Hub，如果不给出用户名，则默认为library，表示官方提供；标签一般是对应软件的版本号，如果不指定则默认为latest。 比如我们要下一个nginx镜像，则可执行如下命令 12345678[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker pull nginxUsing default tag: latestlatest: Pulling from library/nginxfc7181108d40: Already exists d2e987ca2267: Pull complete 0b760b431b11: Pull complete Digest: sha256:48cbeee0cb0a3b5e885e36222f969e0a2f41819a68e07aeb6631ca7cb356fed1Status: Downloaded newer image for nginx:latest 这里我们没有指定选项，也没有指定镜像仓库地址，那么默认会从Docker Hub获取镜像（但Docker Hub由于在国外，速度比较慢，所以一般要设置国内加速器，参考Docker笔记（三）：Docker安装与配置第二部分：配置国内镜像)，也没有给出用户名，所以默认是library（第三行），没有指定标签，所以默认是latest（第二行），由第四至第六行可见，这个镜像包含三个层，并且第一个层已经存在了（之前下载的镜像已经包含了这个层， 直接复用），镜像分层的概念及层的复用，应该已经理解了。 如果我们不知道镜像的完整名称怎么办，那就搜索一下，有两个途径，一是通过命令，假设我们记不起nginx全称了， 只记得ngi，则可通过如下命令搜索123456789101112131415[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker search ngiNAME DESCRIPTION STARS OFFICIAL AUTOMATEDnginx Official build of Nginx. 11693 [OK] jwilder/nginx-proxy Automated Nginx reverse proxy for docker con… 1628 [OK]richarvey/nginx-php-fpm Container running Nginx + PHP-FPM capable of… 726 [OK]bitnami/nginx Bitnami nginx Docker Image 69 [OK]linuxserver/nginx An Nginx container, brought to you by LinuxS… 69 tiangolo/nginx-rtmp Docker image with Nginx using the nginx-rtmp… 48 [OK]nginx/nginx-ingress NGINX Ingress Controller for Kubernetes 20 nginxdemos/hello NGINX webserver that serves a simple page co… 18 [OK]jlesage/nginx-proxy-manager Docker container for Nginx Proxy Manager 17 [OK]schmunk42/nginx-redirect A very simple container to redirect HTTP tra… 17 [OK]crunchgeek/nginx-pagespeed Nginx with PageSpeed + GEO IP + VTS + more_s… 13 blacklabelops/nginx Dockerized Nginx Reverse Proxy Server. 12 [OK]... 该命令会从Docker Hub搜索镜像名包含ngi的镜像，其中STARS表示收藏用户数，OFFICIAL为[OK]表示官方提供的镜像，AUTOMATED [OK]表示由自动构建生成，一般选择STARS最多，官方提供的镜像。这种方式获取到的信息有限，比如具体包含哪些版本不知道。还有一个途径是直接在Docker Hub网站上搜索，打开 https://hub.docker.com ， 在搜索框输入ngi，如下图 则会列出所有满足条件的镜像，点开nginx结果链接，可以看到提供的版本（通过版本链接可以查看定义对应镜像的Dockerfile），及相应的文档说明。这种方式获取的信息更加全面，所以推荐这种方式！ 另外，当我们没有执行docker pull，直接通过docker run xx来运行一个容器时，如果没有对应的镜像，则会先自动下载镜像，再基于镜像启动一个容器，比如我们在Docker笔记（三）：Docker安装与配置中检验docker是否安装成功时运行的hello-world 2. 管理本地镜像将镜像下载到本地后，我们可以基于镜像来创建、运行容器，及对镜像进行管理。 查看本地镜像 12345[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEnginx latest f68d6e55e065 2 weeks ago 109MBmysql latest c7109f74d339 5 weeks ago 443MBhello-world latest fce289e99eb9 6 months ago 1.84kB 上面各列依次列出了镜像名称、标签（版本）、镜像ID、创建时间、镜像大小。镜像可以拥有多个标签（版本）。镜像的大小总和一般要大于实际的磁盘占有量，为什么？回忆一下镜像的分层存储概念，层是可以复用的，某个层其中一个镜像有了，另一个镜像就不会再下载了。口说无凭，我们来验证下，docker system df可列出镜像、容器、数据卷所占用的空间 123456[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker system dfTYPE TOTAL ACTIVE SIZE RECLAIMABLEImages 3 1 497.1MB 497.1MB (99%)Containers 1 0 0B 0BLocal Volumes 0 0 0B 0BBuild Cache 0 0 0B 0B 通过docker image ls列出的各镜像大小总共约552MB，但这里列出的镜像大小只有约497MB，这下有凭有据了吧。 根据条件列出镜像123docker image ls nginx # 根据名称列出镜像docker image ls nginx:latest # 根据名称与标签列出镜像docker image ls -f since=hello-world:latest # -f 是--filter的缩写，过滤器参数，列出在hello-world:latest之后建立的镜像，before=hello-world:latest则查看之前建立的镜像 指定显示格式12345docker image ls -q # 只显示镜像IDdocker image ls --digests # 列出镜像摘要docker image ls --format \"&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Repository&#125;&#125;\" # 使用Go的模板语法格式化显示，这里显示格式为 镜像ID：镜像名称docker image ls --format \"table &#123;&#123;.ID&#125;&#125;\\t&#123;&#123;.Repository&#125;&#125;\\t&#123;&#123;.Tag&#125;&#125;\" # 自己定义表格格式 虚悬镜像有时候会看到某些镜像既没有仓库名，也没有标签，均为 &lt;none&gt;。这些镜像原本是有镜像名和标签的，随着官方镜像维护，发布了新版本后(新版本会复用之前的镜像名称与标签，一般是bug修复版)，重新docker pull xx 时， 这个镜像名被转移到了新下载的镜像身上，而旧的镜像上的这个名称则被取消，从而成为了&lt;none&gt; 。除了docker pull可能导致这种情况， docker build也同样可以导致这种现象。由于新旧镜像同名，旧镜像名称被取消，从而出现仓库名、标签均为 &lt;none&gt; 的镜像。这类无标签镜像被称为虚悬镜像(dangling image) ，可以用下面的命令专门显示这类镜像：1docker image ls -f dangling=true 一般虚悬镜像没什么意义了，可以通过如下命令删除1docker image prune 中间层镜像为了加速镜像构建、重复利用资源，Docker会利用中间层镜像。所以在使用一段时间后，可能会看到一些依赖的中间层镜像。默认的docker image ls列表中只会显示顶层镜像，如果希望显示包括中间层镜像在内的所有镜像的话，可以加 -a1$ docker image ls -a 这样会看到很多无标签的镜像，与虚悬镜像不同，这些无标签的镜像很多都是中间层镜像，是其它镜像所依赖的镜像。这些无标签镜像不应该删除，否则会导致上层镜像因为依赖丢失而出错。实际上，这些镜像也没必要删除，因为相同的层只会存一遍，而这些镜像是别的镜像的依赖，因此并不会因为它们被列出来而多存了一份，无论如何你也会需要它们。只要删除那些依赖它们的镜像后，这些依赖的中间层镜像也会被连带删除。 删除镜像删除镜像命令格式1docker image rm [选项] &lt;镜像1&gt; [&lt;镜像2&gt; ...] 选项可以设置： -f, –force 强制删除镜像 –no-prune 不删除没有标签的父镜像 &lt;镜像1&gt;、&lt;镜像2&gt; 等可以是镜像的名称，镜像的全ID，也可以是镜像ID的前面几个数字（只要与其它镜像区分开来就行），或者是镜像摘要。 如删除镜像名称为mysql的镜像1234567[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# docker image rm mysqlUntagged: mysql:latestUntagged: mysql@sha256:415ac63da0ae6725d5aefc9669a1c02f39a00c574fdbc478dfd08db1e97c8f1bDeleted: sha256:c7109f74d339896c8e1a7526224f10a3197e7baf674ff03acbab387aa027882aDeleted: sha256:35d60530f024aa75c91a123a69099f7f6eaf5ad7001bb983f427f674980d8482Deleted: sha256:49d8bb533eee600076e3a513a203ee24044673fcef0c1b79e088b2ba43db2c17... 由上面命令的执行结果可见，删除镜像包括另个行为：Untagged、Deleted。 当我们使用上面命令来删除镜像的时候，实际上是在要求删除某个/某些标签的镜像。所以首先需要做的是将满足要求的所有镜像标签都取消，这就是Untagged的行为。一个镜像可以对应多个标签，因此当我们删除了所指定的标签后，可能还有别的标签指向了这个镜像，如果是这种情况，那么Delete行为就不会发生，仅仅是取消了这个镜像的符合要求的所有标签。所以并非所有的docker image rm都会产生删除镜像的行为，有可能仅仅是取消了某个标签而已。 当该镜像所有的标签都被取消了，该镜像很可能就失去了存在的意义，因此会触发删除行为。镜像是多层存储结构，因此在删除的时候也是从上层向基础层方向依次进行判断删除。如果某个其它镜像正依赖于当前镜像的某一层，这种情况，依旧不会触发删除该层的行为。直到没有任何镜像依赖当前层时，才会真实的删除当前层。 另外还需要注意是容器对镜像的依赖。如果基于镜像启动的容器存在（即使容器没有运行处于停止状态） ，同样不可以删除这个镜像。我们之前说了容器是以镜像为基础，再加一层容器存储层组成的多层存储结构去运行的。所以如果这些容器是不需要的，应该先将它们删除，然后再来删除镜像。 通过组合命令来删除12docker image rm $(docker image ls -q nginx) # 删除镜像名称为nginx的所有镜像docker image rm $(docker image ls -q -f since=hello-world:latest) # 删除所有在hello-world:latest之后建立的镜像 3. 总结本文对镜像的获取及本地镜像的基本管理做了介绍，本文镜像的获取途径都是从镜像仓库直接获取，镜像的另一个获取途径便是自定义，接下来会通过实例来进行介绍，欢迎关注。我的个人博客地址：http://blog.jboost.cn我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"}]},{"title":"Docker笔记（三）：Docker安装与配置","slug":"docker-3","date":"2019-07-14T11:54:05.000Z","updated":"2019-07-15T00:47:02.022Z","comments":true,"path":"docker-3.html","link":"","permalink":"http://blog.jboost.cn/docker-3.html","excerpt":"Docker分为Docker CE社区免费版与Docker EE企业收费版。Docker EE主要是在安全性及镜像、容器高级管理方面提供了一些额外的支持。对于中小型企业、团队或个人来说，用Docker CE即可。","text":"Docker分为Docker CE社区免费版与Docker EE企业收费版。Docker EE主要是在安全性及镜像、容器高级管理方面提供了一些额外的支持。对于中小型企业、团队或个人来说，用Docker CE即可。 1. 安装Docker CEDocker CE有三个更新渠道： Stable：提供最新的GA（General Availability）稳定版，每六个月一版，如 18.09 表示18年9月版，下一版就是19.03——19年3月版 Test：提供GA之前的Pre-release版 Nightly：提供最新的build版本，每天一版 我们一般使用stable版。Docker CE支持在多种操作系统下安装，本文只介绍比较常见的Ubuntu 18.04 LTS、CentOS7、及Windows 10上的安装与配置。 1.1 Ubuntu 18.04 LTS 上安装Docker CE支持的64位Ubuntu系统版本为 Cosmic 18.10 Bionic 18.04 (LTS) Xenial 16.04 (LTS) Docker CE在Ubuntu上支持 overlay2， aufs， 以及 btrfs 几种存储驱动程序，对于Linux内核版本为4或以上系统的安装，Docker CE默认使用 overlay2，如果需要使用 aufs，则需要手动配置（参考： Use the AUFS storage driver） 卸载旧版本 如果系统安装有旧版本，旧版本命名为 docker， docker.io，或docker.engine，可使用如下命令进行卸载1$ sudo apt-get remove docker docker-engine docker.io containerd runc 目录/var/lib/docker下的内容，包括镜像、容器、数据卷、网络等，会被保留。 使用APT安装 apt源使用HTTPS来确保软件下载过程中不被篡改，所以首先添加使用HTTPS传输需要的软件包以及CA证书1234567$ sudo apt-get update$ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common 为了确认下载软件包的合法性，添加Docker官方的GPG key：12$ curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg | sudo apt-key add - 由于国内网络原因，我们一般要使用国内源，否则安装将会灰常灰常慢。向source.list中添加Docker软件源（以下命令添加的是stable版本的APT镜像源，如果需要test或nightly版，将stable改为对应test或nightly即可）1234$ sudo add-apt-repository \\\"deb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu \\$(lsb_release -cs) \\stable\" 然后，便可更新apt软件包缓存，开始安装了12$ sudo apt-get update$ sudo apt-get install docker-ce 以上命令默认会安装软件源里的最新版本，如果需要安装指定版本，则可通过查看可用版本，然后指定版本安装，查看版本1$ apt-cache madison docker-ce 安装指定版本1$ sudo apt-get install docker-ce=&lt;VERSION_STRING&gt; 使用脚本自动安装 Docker提供了一个方便的安装脚本来在开发测试环境安装Docker CE的edge或测试版，Ubuntu上可使用这套脚本来安装Docker CE的edge版12$ curl -fsSL https://get.docker.com -o get-docker.sh$ sudo sh get-docker.sh --mirror Aliyun 启动Docker CE 12$ sudo systemctl enable docker #开启开机自动启动$ sudo systemctl start docker #启动docker 用户组配置 docker命令默认是使用Unix socket与Docker引擎进行通信（回顾下除了Unix socket还有REST API及网络端口），只有root用户或docker用户组里的用户才有权限访问Docker引擎的Unix socket，因此，需要将使用docker的用户加入docker用户组（处于安全考虑，一般尽量不要直接使用root用户来操作）12$ sudo groupadd docker #添加docker用户组$ sudo usermod -aG docker $USER #将当前用户加到docker用户组 退出账号重新登录即可。 测试安装是否成功 1$ docker run hello-world 如果显示如下图，则说明安装已成功 卸载 1$ sudo apt-get purge docker-ce 以上命令可以卸载docker-ce，但是之前的镜像、容器、数据卷等不会自动删除，可通过如下命令彻底删除1$ sudo rm -rf /var/lib/docker 1.2 CentOS 7 上安装Docker CE支持64位的CentOS7，并且要求内核版本不低于3.10。CentOS 7满足最低内核的要求，但由于版本较低，一些功能（如 overlay2 存储层驱动）无法使用，并且部分功能可能不太稳定。可以通过uname -r命令来查看系统内核版本，如12[root@iZwz9dbodbaqxj1gxhpnjxZ ~]# uname -r3.10.0-957.1.3.el7.x86_64 卸载旧版本 如果安装了旧版本，需要先卸载。旧版本的Docker称为docker或者docker-engine，卸载命令12345678910$ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine 使用yum安装 安装依赖包123$ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 由于国内网络原因，我们一般要使用国内源，否则安装可能会灰常灰常慢。添加yum软件源1234$ sudo yum-config-manager \\ --add-repo \\ https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce .repo 如果要安装nightly或test版，执行如下对应的命令12$ sudo yum-config-manager --enable docker-ce-nightly # 启用nightly， 将--enbale改为disable又可以禁用$ sudo yum-config-manager --enable docker-ce-test # 启用test 安装最新版本12$ sudo yum makecache fast # 更新软件源缓存$ sudo yum install docker-ce # 安装最新版本 安装指定版本12$ sudo yum list docker-ce --showduplicates | sort -r # 列出可用版本$ sudo yum install docker-ce-&lt;VERSION_STRING&gt; # 安装指定版本 使用脚本自动安装 执行如下命令，则会自动安装Docker CE的edge版，注意只在开发或测试环境这么用（建议最好还是用stable版） 12$ curl -fsSL get.docker.com -o get-docker.sh$ sudo sh get-docker.sh --mirror Aliyun 启动Docker CE 12$ sudo systemctl enable docker #开启开机自动启动$ sudo systemctl start docker #启动docker 用户组配置 docker命令默认是使用Unix socket与Docker引擎进行通信（回顾下除了Unix socket还有REST API及网络端口），只有root用户或docker用户组里的用户才有权限访问Docker引擎的Unix socket，因此，需要将使用docker的用户加入docker用户组（处于安全考虑，一般尽量不要直接使用root用户来操作）12$ sudo groupadd docker #添加docker用户组$ sudo usermod -aG docker $USER #将当前用户加到docker用户组 退出账号重新登录即可。 测试安装是否成功 1$ docker run hello-world 如果显示如下图，则说明安装已成功 如果在 CentOS 中使用 Docker CE 看到下面的这些警告信息：12WARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled 可以添加内核配置参数以启用这些功能。1234$ sudo tee -a /etc/sysctl.conf &lt;&lt;-EOFnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOF 然后重新加载 sysctl.conf 即可1$ sudo sysctl -p 卸载 12$ sudo yum remove docker-ce # 卸载docker-ce$ sudo rm -rf /var/lib/docker # 该目录下的镜像、容器、数据卷、网络等不会自动删除 1.3 Windows 10 上安装windows 10上的安装非常简单，直接下载stable版本安装。安装完后，在 Windows 搜索栏输入 Docker 点击 Docker for Windows 开始运行 2. 配置国内镜像Docker默认是从Docker Hub（官方的镜像仓库）拉取镜像的，国内访问一般会比较慢，因此可以配置一些镜像加速器，很多云服务商提供了自己的加速器服务，如Azure中国，阿里云（需要登录获取），七牛云等。 Ubuntu、CentOS上，配置国内镜像只需要在/etc/docker/daemon.json中写入如下内容（如果文件不存在则创建一个）123456&#123; \"registry-mirrors\": [ \"https://dockerhub.azk8s.cn\", \"https://reg-mirror.qiniu.com\" ]&#125; 然后重新启动服务12$ sudo systemctl daemon-reload$ sudo systemctl restart docker 对于Windows 10，在系统右下角托盘Docker图标上右键菜单选择Settings ，打开配置窗口后在左侧导航菜单选择 Daemon 。在 Registrymirrors 一栏中填写加速器地址 https://dockerhub.azk8s.cn ，之后点击Apply 保存， Docker 就会自动重启并应用配置的镜像地址了。 可以通过docker info命令来检查加速器是否生效，如果执行命令能看到类似如下信息，则说明加速器配置生效了。12Registry Mirrors: https://dockerhub.azk8s.cn/ 3. 总结Docker分Docker CE与Docker EE两个版本，对大多数人来说，一般使用Docker CE就行了。我们在安装Docker CE时，最好安装stable版，比较稳定可靠。同时，Linux安装时，记得配置Docker软件源，不然有可能太慢。安装完后，需要配置镜像加速器，加快镜像的下载速度。工具有了，接下来就是探索实践了，加油吧少年！我的个人博客地址：http://blog.jboost.cn我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"}]},{"title":"Docker笔记（二）：Docker管理的对象","slug":"docker-2","date":"2019-07-14T00:36:56.000Z","updated":"2019-07-24T01:50:44.879Z","comments":true,"path":"docker-2.html","link":"","permalink":"http://blog.jboost.cn/docker-2.html","excerpt":"在Docker笔记（一）：什么是Docker中，我们提到了Docker管理的对象包含镜像、容器、网络、数据卷等，本文就来介绍下这些对象及用途。","text":"在Docker笔记（一）：什么是Docker中，我们提到了Docker管理的对象包含镜像、容器、网络、数据卷等，本文就来介绍下这些对象及用途。 1. 镜像所谓镜像，是一个静态的概念。它对我们期望干的事情做了一些定义，比如要运行什么程序，需要哪些依赖，需要什么样的配置，需要开放哪个网络端口等等。Docker的镜像是一个特殊的文件系统，提供了运行时需要的程序、库、资源、配置等文件，还包含一些为运行时准备的配置参数（如环境变量、匿名数据卷、用户等），镜像不包含任何动态数据，其内容在构建之后也不会被改变。镜像的文件系统有一个分层存储的概念，采用的是Union FS技术，因此，镜像并不是简单地由一组文件组成，而是由多层文件系统叠加联合组成。如下图所示 镜像构建时，会一层一层地构建，前一层是后一层的基础，每层构建完后就变成只读的，不会再发生改变。镜像分层存储的一大好处是复用，镜像的每一层可以在不同镜像间复用，这就好比我们开发项目时将一些公共功能封装成jar包，在各个项目可以直接依赖使用一样。关于镜像的更多内容，在后续使用时再详述。 2. 容器相对镜像，容器是一个动态的运行时的概念，它与镜像的关系类似于面向对象中类与实例的关系。容器可以被创建、启动、停止、删除等。容器运行实质上就是运行一个进程，但与那些直接在宿主机上运行的进程不同，容器运行在自己的独立的隔离的命名空间中——拥有自己的root文件系统、网络配置、进程空间，甚至自己的用户ID空间，因此虽然是以进程的形式运行，但好像是运行在一个独立的系统中一样，这样相比直接运行于宿主机的进程，容器的运行显得更为安全。前面说到镜像的分层存储概念，对于容器来说，实际上也是以镜像作为基础层，在其上创建了一个当前容器的存储层，如下图 以镜像ubuntu:15.04为基础层所创建的容器，都有一个自己的可读写的存储层（镜像的存储层是只读的）。容器存储层的生命周期与容器一样，容器销毁时，容器的存储层也会随之消亡，任何保存在容器存储层的数据也都会随容器的删除而丢失，因此一般我们要保持容器存储层的无状态化，所有文件的写操作，都应该使用数据卷或绑定宿主机目录。 3. 数据卷数据卷是一个独立于容器，可供一个或多个容器使用的特殊目录，它绕过了Union FS，不会随容器的销毁而消亡。这好比我们在阿里云上建虚机，再加载一个数据盘一样，一般产生的数据都要保存在数据盘，而不是虚机的系统盘。数据卷具备如下特性： 可以在容器之间共享和重用 对数据卷的修改会立马生效 数据卷的更新，不会影响到镜像 数据卷默认会一直存在，不会随容器的删除而消亡 4. 网络Docker容器是如何与外部进行网络通信的？一般来说，我们在运行容器时，只需要指定容器服务端口与宿主机端口的映射，就可以通过宿主机IP与映射的端口访问容器服务了，因为Docker默认使用了Bridge的模式来实现容器与外部的通信。Docker的网络子系统通过使用一些驱动程序，是可插拔式的，默认提供了如下几种驱动： bridge：默认的网络驱动。运行在容器中的应用程序一般是通过网桥与外部进行通信。 host：容器直接使用宿主机的网络通信。host只在基于Docker 17.06或以上版本的Swarm服务中可用 overlay：overlay可将多个Docker daemon进程连接起来使得Swarm服务之间能相互通信，也可以将overlay用于Swarm服务与容器之间，或运行在不同Docker daemon上的容器之间的通信，不需要操作系统层面的路由配置。 macvlan：macvlan允许你分配一个mac地址给容器，让它像一台物理设备一样加入你的网络中。Docker daemon通过mac地址将请求路由给容器，适用于那些希望直接连到物理网络的遗留应用。 none：禁用所有网络。一般与一个自定义的网络驱动一起使用。none不能用于Swarm服务。 其它第三方网络插件：可从Docker Hub或其它第三方供应商获取安装。 总之，bridge适用于在同一台宿主机运行多个容器的场景；host适用于不应与宿主机进行网络隔离的场景；overlay适用于运行在不同宿主机上的容器间通信，或多个应用通过Swarm服务来共同协作的场景；macvlan适用于从虚拟机迁移配置或希望容器作为物理机一样使用网络的场景。 5. 总结本文对Docker所管理的几个基本对象——镜像、容器、数据卷、网络做了简单介绍，这是认识或学习Docker的基础，在后续实践操作过程中，将会对各部分进行更详细的使用说明，欢迎持续关注。我的个人博客地址：http://blog.jboost.cn我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"}]},{"title":"Docker笔记（一）：什么是Docker","slug":"docker-1","date":"2019-07-13T02:13:25.000Z","updated":"2019-07-13T09:59:13.911Z","comments":true,"path":"docker-1.html","link":"","permalink":"http://blog.jboost.cn/docker-1.html","excerpt":"1. 前言接触Docker也有两年多了，断断续续玩过一些应用场景，如安装一些常用工具服务，部署业务项目，基于gitlab+jenkins pipeline+docker的CI/CD实现等。了解其基本知识与操作，但不能说深度掌握，故借此系列进行梳理与学习，也希望对有意学习Docker的人提供参考。","text":"1. 前言接触Docker也有两年多了，断断续续玩过一些应用场景，如安装一些常用工具服务，部署业务项目，基于gitlab+jenkins pipeline+docker的CI/CD实现等。了解其基本知识与操作，但不能说深度掌握，故借此系列进行梳理与学习，也希望对有意学习Docker的人提供参考。 2. Docker简介Docker最初是dotCloud公司（后来也改名为Docker）的一个内部项目，于2013年3月开源。Docker使用Google推出的Go语言实现，基于Linux内核的cgroup、namespace、Union FS等技术（先不用急着了解这些都是啥），对进程进行隔离，是操作系统层面的虚拟化技术。相对于传统的硬件层面的虚拟化技术（虚拟机），Docker显得更为轻量化。下图为传统虚拟机与Docker的结构对比 由上图可看出传统虚拟机技术是在硬件层面虚拟出一套硬件（CPU、内存、磁盘、网卡等）后，在其上运行一个完整的操作系统，再在操作系统上运行应用进程；而Docker的应用进程是直接运行在宿主机的内核上，也不需要进行硬件虚拟，因此，Docker要比传统虚拟机更为轻便。 总结Docker相对传统虚拟化技术的优势如下： 更高的资源利用率：Docker不需要硬件虚拟与运行完整操作系统的开销，所以资源利用率更高，同样配置的主机，采用Docker往往可以运行更多数量的应用。 更高效的使用体验：在操作系统上安装一些常用软件，如mysql，redis等，往往需要折腾好一阵，有些还要手动安装各种依赖，而采用Docker，可能几行命令就可以让一个服务快速运行起来。 一致的运行环境：Docker镜像功能可以把程序运行需要的环境进行封装，确保程序在开发、测试、生产环境都能保持一致性，避免因环境不一致导致程序运行异常。 CI/CD支持：使用Docker可以定制镜像来实现持续集成、持续部署，如基于gitlab + jenkins pipeline + docker的自动化部署。 更轻松的维护：因为Docker保证了运行环境的一致性，因此应用的迁移或缩放将变得很容易；Docker的分层存储与镜像技术，也使得应用重复部分的复用变得更简单，基于基础镜像可以进一步扩展定义自己的镜像，也可以直接使用官方镜像来使用。 3. Docker的基本架构Docker的基本架构图如下 主要包括几部分： Docker daemon（Docker守护进程 dockerd）：Docker的执行引擎，负责监听处理Docker客户端请求与管理Docker相关对象，如镜像、容器、网络、数据卷等。一个Docker守护进程可与其它Docker守护进程进行通信，作为Docker服务进行管理。 Docker client（Docker客户端 docker）：Docker客户端（docker CLI命令）是大多数用户用来与Docker守护进程交互的方式，比如你在命令行执行docker run，Docker客户端将发送该命令请求到Docker守护进程，由守护进程执行。Docker客户端可通过REST API, UNIX Socket或网络接口来与Docker守护进程进行通信，并且可与多个Docker守护进程进行通信。 Docker Registry（Docker注册中心）：用来存储Docker镜像的仓库，类似于Maven的Nexus。Docker官方提供了一个公共镜像仓库Docker Hub（ https://hub.docker.com/ ），docker相关命令默认会从Docker Hub上搜索与下载镜像，我们可以配置一些国内镜像仓库地址来进行加速，甚至搭建自己的私有镜像仓库。 Docker Objects：Docker管理的对象，主要包括镜像、容器、网络、数据卷等。 4. Docker的用途根据第二部分Docker的优势及笔者的经验来看，目前Docker主要用于 常用软件服务的搭建运行，如Mysql、Redis、Nginx等 业务服务的发布部署，尤其是基于SpringBoot的微服务 CI/CD实现，结合Gitlab的webhook，Jenkins的pipeline，实现自动化集成与部署 快速的弹性伸缩，在容器集群化管理的场景中，如Swarm、K8s解决方案中，可基于容器对服务进行快速的弹性伸缩来应对业务量的突发情况 执行环境封装，如一些深度学习框架模型，打成Docker镜像的方式进行发布，可以快速在不同的环境中运行起来 … 5. 总结在微服务架构、DevOps这些概念盛行的时代，容器化技术变得越来越重要，几乎成为每一位开发人员需要掌握的技能。本系列文章是笔者基于自身实践及相关文献参考，对Docker相关技术进行整理，欢迎关注，共同学习。我的个人博客地址：http://blog.jboost.cn我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.jboost.cn/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.jboost.cn/tags/docker/"}]},{"title":"ubuntu18.04上搭建KVM虚拟机环境超完整过程","slug":"ubuntu-kvm","date":"2019-07-11T06:13:23.000Z","updated":"2019-08-26T02:05:42.429Z","comments":true,"path":"ubuntu-kvm.html","link":"","permalink":"http://blog.jboost.cn/ubuntu-kvm.html","excerpt":"看标题这是篇纯运维的文章。在中小型企业中，一般很少配置专业的运维人员，都是由开发人员兼着。同时，对有志于技术管理的开发人员来说，多了解一些运维及整个软件生命周期的知识，是很有帮助的，因为带团队不仅仅是个管人的活，更多的是在你的部下遇到难题或者无人能上的时候，你能协助他解决或亲自上阵，这比只会“吆五喝六”的管理者将能获得更高的敬重与威信。闲话不多说了，记录下整个KVM虚拟机的搭建过程吧。","text":"看标题这是篇纯运维的文章。在中小型企业中，一般很少配置专业的运维人员，都是由开发人员兼着。同时，对有志于技术管理的开发人员来说，多了解一些运维及整个软件生命周期的知识，是很有帮助的，因为带团队不仅仅是个管人的活，更多的是在你的部下遇到难题或者无人能上的时候，你能协助他解决或亲自上阵，这比只会“吆五喝六”的管理者将能获得更高的敬重与威信。闲话不多说了，记录下整个KVM虚拟机的搭建过程吧。 1. KVM安装1.1 配置确认首先需要确认服务器的硬件是否支持虚拟化，执行如下命令确认 12devuser@server_01:~$ egrep -c '(vmx|svm)' /proc/cpuinfo48 如果输出结果大于0，意味着服务器硬件是支持虚拟化的。否则，重启进入BIOS设置中启用VT技术。执行如下命令安装kvm-ok程序，来确定服务器是否能够运行硬件加速的KVM虚拟机 12345devuser@server_01:~$ sudo apt install cpu-checkerdevuser@server_01:~$ sudo kvm-okINFO: /dev/kvm existsKVM acceleration can be used 1.2 安装KVM安装KVM及依赖项12devuser@server_01:~$ sudo apt updatedevuser@server_01:~$ sudo apt install qemu qemu-kvm libvirt-bin bridge-utils virt-manager 启动libvirtd服务，并设置开机自动启动12devuser@server_01:~$ sudo systemctl start libvirtd.servicedevuser@server_01:~$ sudo systemctl enable libvirtd.service 执行service libvirtd status查看libvirtd服务状态，如图 1.3 桥接网络配置一般虚拟机网络配置有Bridge、NAT等几种模式。NAT模式下，虚拟机不需要配置自己的IP，通过宿主机来访问外部网络；Bridge模式下， 虚拟机需要配置自己的IP，然后虚拟出一个网卡， 与宿主机的网卡一起挂到一个虚拟网桥上（类似于交换机）来访问外部网络，这种模式下，虚拟机拥有独立的IP，局域网其它主机能直接通过IP与其通信。简单理解，就是NAT模式下，虚机隐藏在宿主机后面了，虚机能通过宿主机访问外网，但局域网其它主机访问不到它，Bridge模式下，虚机跟宿主机一样平等地存在，局域网其它主机可直接通过IP与其通信。一般我们创建虚机是用来部署服务供使用的， 所以都是用Bridge模式。 ubuntu 18中，网络配置通过netplan来实现了，如下，更改配置文件 /etc/netplan/50-cloud-init.yaml 1234567891011121314151617181920212223devuser@cserver_01:~$ sudo vim /etc/netplan/50-cloud-init.yaml# This file is generated from information provided by# the datasource. Changes to it will not persist across an instance.# To disable cloud-init's network configuration capabilities, write a file# /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg with the following:# network: &#123;config: disabled&#125;network: ethernets: enp6s0: dhcp4: true enp7s0: dhcp4: no dhcp6: no version: 2 bridges: br0: interfaces: [enp7s0] dhcp4: no addresses: [192.168.40.241/24] gateway4: 192.168.40.1 nameservers: addresses: [114.114.114.114,8.8.8.8] 将宿主机原有网卡enp7s0挂到网桥br0上，并指定IP地址为192.168.40.241，nameservers指定DNS服务器。修改完后，通过sudo netplan apply重启网络服务生效，然后通过ifconfig查看，原来挂在enp7s0网卡下的IP现在挂到了br0上，宿主机及所有其它虚拟机都通过该网桥来与外部通讯。我们也可以通过brctl show来直观地查看，1234567devuser@server_01:~$ brctl showbridge name bridge id STP enabled interfacesbr0 8000.2a5be3ec2698 no enp7s0docker0 8000.02424524dcce no veth580af8e veth74119f3 vethe7a2b0f vethfe89039 目前因为还没虚机，所以只有宿主机的网卡enp7s0挂在网桥br0上。同时也可以看到docker容器也是通过网桥docker0来通讯的。 2. 虚拟机安装2.1 安装虚拟机安装命令123456sudo virt-install --name=dev-server1 --memory=16384,maxmemory=16384 \\--vcpus=4,maxvcpus=4 --os-type=linux --os-variant=rhel7 \\--location=/home/devuser/tools/CentOS-7-x86_64-DVD-1810.iso \\--disk path=/var/lib/libvirt/images/devserver1.img,size=300 \\--bridge=br0 --graphics=none --console=pty,target_type=serial \\--extra-args=\"console=tty0 console=ttyS0\" 其中–name指定虚机名称；–memory=16384,maxmemory=16384配置了16G内存；–vcpus=4,maxvcpus=4配置了4个CPU内核；centos7需要指定–os-variant=rhel7；–disk path=xx,size=300指定了磁盘路径与大小，这里是300G。 如果执行上述命令出现qemu-kvm: could not open &#39;xx/CentOS-7-x86_64-DVD-1810.iso&#39;: Permission denied异常退出时，可通过修改/etc/libvirt/qemu.conf文件将user = &quot;root&quot;，group = &quot;root&quot;前面的注释去掉解决（https://github.com/jedi4ever/veewee/issues/996） 如无问题，安装程序将出现如下配置界面 可通过输入选项对应的数字来选择不同的配置，依次操作如下步骤完成时区设置：输入2，回车，选择时区设置；输入1，回车，选择“Set timezone”；输入2，回车，选择“Asia”；回车，输入64，回车，选择“Shanghai” 然后进行安装设置，依次操作如下：输入5，回车，进入安装设置；输入c，回车，选择默认的磁盘进行安装；输入c，回车，使用默认的“2) Use All Space”；输入1，回车，选择“1) Standard Partition”进行标准分区；输入c，回车，完成分区设置 最后进入root密码设置，操作如下：输入8，回车，进入root密码设置；输入密码，回车；输入确认密码，回车 完成上述设置后，输入b开始进行安装 等待一段时间后，安装程序停在如下界面 按回车继续，最后输入用户名root，及前面设置的密码登录系统 2.2 虚拟机网络配置虚拟机安装完后，是没有分配IP的，我们通过ip a命令查看， 这时候的eth0下面空空如也，什么都没有。在/etc/sysconfig/network-scripts/ifcfg-eth0文件中添加如下内容 1234567891011121314151617181920[root@localhost ~]# vi /etc/sysconfig/network-scripts/ifcfg-eth0TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=static #静态指定IPDEFROUTE=yes#IPV4_FAILURE_FATAL=no#IPV6INIT=yes#IPV6_AUTOCONF=yes#IPV6_DEFROUTE=yes#IPV6_FAILURE_FATAL=no#IPV6_ADDR_GEN_MODE=stable-privacyNAME=eth0UUID=449ed621-97a8-45b9-902f-0d347e27de98DEVICE=eth0ONBOOT=yes #开机自动启动IPADDR=192.168.40.96NETMASK=255.255.255.0GATEWAY=192.168.40.1DNS1=192.168.40.1 并通过systemctl restart network重启网络生效，这时候再运行ip a查看，eth0下面已经有配置的IP了。不出意外的话，局域网其它主机就可以通过该IP来远程SSH连接了。 这时候我们再通过brctl show来查看网桥挂载情况，br0下面已经多了一个vnet0虚拟网卡了。123456789devuser@server_01:~$ brctl showbridge name bridge id STP enabled interfacesbr0 8000.2a5be3ec2698 no enp7s0 vnet0docker0 8000.02424524dcce no veth580af8e veth74119f3 vethd270ee8 vethe7a2b0f vethfe89039 虚拟机装完后，默认的hostname是localhost，针对centos7，我们可以通过如下命令来修改hostname1[root@localhost ~]# hostnamectl set-hostname dev-server1 然后在/etc/hosts文件中添加127.0.0.1的host映射 dev-server1123[root@localhost ~]# vi /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 dev-server1::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 Note: 如果出现虚拟机中无法访问外网，外部主机也无法ping通虚拟机的情况，则尝试如下处理 向文件/etc/sysctl.conf添加以下代码，禁用网络过滤器:123net.bridge.bridge-nf-call-ip6tables = 0net.bridge.bridge-nf-call-iptables = 0net.bridge.bridge-nf-call-arptables = 0 重新加载kernel参数：123456devuser@server_01: sudo sysctl -pnet.ipv4.ip_forward = 0...net.bridge.bridge-nf-call-ip6tables = 0net.bridge.bridge-nf-call-iptables = 0net.bridge.bridge-nf-call-arptables = 0 3. 虚拟机管理 列出当前运行的虚拟机virsh list1234devuser@server_01:~$ virsh list Id Name State---------------------------------------------------- 5 dev-server1 running 如果列出所有的，则virsh list --all 从宿主机进入虚拟机virsh console，后面接虚拟机ID或名称12345678devuser@server_01:~$ virsh console 5Connected to domain dev-server1Escape character is ^]CentOS Linux 7 (Core)Kernel 3.10.0-957.el7.x86_64 on an x86_64dev-server1 login: 输入用户名，密码即可登录虚拟机，按Ctrl+]可退出。 启动与关闭虚拟机virsh start|shutdown 12345devuser@cserver_01:~$ virsh start dev-server1Domain dev-server1 starteddevuser@server_01:~$ virsh shutdown 5Domain 5 is being shutdown libvirtd启动时，自动启动虚拟机 12devuser@server_01:~$ virsh autostart dev-server1Domain dev-server1 marked as autostarted 挂起/恢复虚拟机 12devuser@server_01:~$ virsh suspend dev-server1 # 挂起虚拟机devuser@server_01:~$ virsh resume dev-server1 # 恢复挂起的虚拟机 销毁虚拟机 1devuser@server_01:~$ virsh undefine dev-server1 # 彻底销毁虚拟机，会删除虚拟机配置文件，但不会删除虚拟磁盘 我的个人博客地址：http://blog.jboost.cn我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"高效实践","slug":"高效实践","permalink":"http://blog.jboost.cn/categories/高效实践/"}],"tags":[{"name":"kvm","slug":"kvm","permalink":"http://blog.jboost.cn/tags/kvm/"}]},{"title":"软件项目研发流程该怎么规范","slug":"project-process","date":"2019-07-08T11:14:47.000Z","updated":"2019-07-09T11:13:37.300Z","comments":true,"path":"project-process.html","link":"","permalink":"http://blog.jboost.cn/project-process.html","excerpt":"在软件项目研发管理过程中，是否经常出现这样的场景：开发人员不知道什么时候转测；项目经理拿个Excel文档群里一发，某任务前天就应该完成的，怎么现在还没开始搞；前端问这部分UI是谁在做，什么时候能做完；测试说线上这个bug又是谁改出来的，这次没转测这模块……等等。整个协作感觉一团乱麻，团队内部充满了甩锅与抱怨的氛围。软件项目的研发流程该怎么规范，让团队成员都能目标明确，步调一致，让产品迭代充满节奏感。本文基于笔者项目研发管理经验整理，希望起到抛砖引玉的作用，探讨高效团队的协作流程模式。","text":"在软件项目研发管理过程中，是否经常出现这样的场景：开发人员不知道什么时候转测；项目经理拿个Excel文档群里一发，某任务前天就应该完成的，怎么现在还没开始搞；前端问这部分UI是谁在做，什么时候能做完；测试说线上这个bug又是谁改出来的，这次没转测这模块……等等。整个协作感觉一团乱麻，团队内部充满了甩锅与抱怨的氛围。软件项目的研发流程该怎么规范，让团队成员都能目标明确，步调一致，让产品迭代充满节奏感。本文基于笔者项目研发管理经验整理，希望起到抛砖引玉的作用，探讨高效团队的协作流程模式。 1. 协作流程图 基本原则： 所有问题可跟踪 （需求、Bug、优化） 所有工作透明化 （工作量、进展、Block因素） 2. 各阶段内容详解2.1. 需求收集确认本阶段主要是与产品经理相关的活动内容： 产品经理在每次版本开始之前定期收集各方需求，包括客户反馈、领导意见（对很多中小企业来说，老板就是最大的“用户”）、市场调研及技术团队需求等来源，输出需求列表 在版本开始之前召开版本计划会议，参与者包括项目经理、产品经理，及项目核心成员，按优先级梳理需求列表，输出下次版本的初步任务列表（之所以说初步，是因为该列表后面可能根据评审情况进行调整） 产品经理基于初步任务列表完成详细需求文档，组织团队成员——包括相关UI、开发、测试，召开 需求评审会议，输出评审意见及修正完成时间 产品经理针对需求评审会议中团队提出的意见建议，在修正完成时间内及时修正需求文档，并及时通知团队相关成员，输出确定的需求文档 注：可在需求评审会议后，进行任务的初步认领分配与时间估算，初步确定转测、上线时间节点 2.2. 设计开发 项目经理根据需求文档完成任务拆解，并在任务管理系统中创建对应任务单，指定经办人 各经办人认领任务后，根据自身任务的期限，及时与依赖方沟通，确定依赖任务的完成时间，以免影响自身任务进度，存在问题及时向项目经理反馈。 UI设计完成后，相关开发人员与产品经理需对UI设计进行确认，如果涉及内容较多，可组织UI评审会议（由产品经理或项目经理权衡组织） 涉及流程的开发任务需要有必要的设计，技术相关负责人负责对设计review，没有review的设计不能开发；任务开发完成需要进行代码review 项目经理定期组织项目例会（紧急版本建议每天一次，较长期版本建议一周一次或两次），持续跟进任务进度与问题，并及时协调处理，以保障进度预期 在预定转测时间节点前一天，开发人员编写转测文档，描述本次版本调整内容（附上任务列表）及注意事项，并通知项目相关人员（钉钉群或邮件） 2.3. 测试 需求评审会议后，测试人员需对各功能模块编写测试用例文档，并在转测前组织测试评审会议，对各功能各环节进行复核与查漏补缺 一次版本任务可根据情况分批测试，并确定每轮转测的内容与时间节点；分批测试完成后，需在上线前进行集成测试，注意预留一定的时间用于问题修复 测试完成，需要将测试结论通报项目相关人员（钉钉群或邮件），包括遗留问题与是否达到上线要求结论 注：产品经理可在转测后对开发实现进行验收，以确定开发是否符合需求实际，以便及时进行调整 2.4. 上线 上线人员需在上线前编写上线方案文档，记录此次上线内容，并对此次上线操作进行推演，对所涉及的所有操作按步骤进行记录，如数据库操作，代码merge，jenkins构建等；对可能存在的问题进行备注及对应的处理方案，并提交技术相关负责人review 项目经理结合测试结论及其它各方面情况，决策是否上线，并将意见通知到项目相关人员（钉钉群或邮件） 上线人员按照上线方案文档记录的步骤，依次完成上线操作（上线操作最好至少由两人完成，一人操作，一人检视，避免出错） 上线完成后，测试人员与产品经理对此次上线进行线上验证，确保线上功能流程无问题 验证无误后，由项目经理或其他指定负责人将上线通知发布至利益相关者，包括项目团队所有成员及相关合作方，说明上线时间、上线内容、影响因素、注意事项等（即时通讯群或邮件） 2.5. 复盘 版本结束后，项目经理根据情况对上个周期组织复盘总结会，总结存在的问题与原因，及后续规避的办法，总结积累的经验等 以上各阶段并不是完全串行推进的，相互之间存在一些穿插，比如下一版本需求的收集整理与当前版本的开发是并行推进的，开发与测试也可以以分阶段转测的形式并行推进，等等。 3. 一些常用工具 jira 用于项目任务管理，其中Agile插件可方便查看整体任务面板，对任务状态一目了然，需要求团队成员养成及时更新状态的习惯 confluence 文档管理，用于各类文档的集中化维护，以上所述的如需求文档、开发设计文档、转测文档、上线文档等均可使用confluence以项目空间的形式集中化管理。 gitlab 代码管理 jenkins 项目部署构建工具 nexus 搭建maven私有库 4. 总结团队工作讲求步调与节奏，好的流程与规范可以让一个水平一般的人也能充分发挥其作用，从而让团队整体稳步前进，高效产出。而不好的流程，或根本不重视流程的团队，却往往一盘散沙，甩锅与抱怨充斥，战斗力低下。本文以相对较粗粒度对软件项目的基本流程管理做了介绍，更细节的内容可能需要团队根据内部具体情况进行相应处理与对待。链接： https://pan.baidu.com/s/1WBHsIWoquKTQHJ6IaSql3Q 是笔者基于以前团队敏捷项目管理及一些具体问题的思考分享PPT，供参考。提取码：awya 我的个人博客地址：http://blog.jboost.cn我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"teamwork","slug":"teamwork","permalink":"http://blog.jboost.cn/categories/teamwork/"}],"tags":[{"name":"agile","slug":"agile","permalink":"http://blog.jboost.cn/tags/agile/"}]},{"title":"线程池的基本原理，看完就懂了","slug":"threadpool","date":"2019-07-05T09:32:30.000Z","updated":"2019-07-09T11:19:28.733Z","comments":true,"path":"threadpool.html","link":"","permalink":"http://blog.jboost.cn/threadpool.html","excerpt":"本文内容是基于研发部门内部的分享整理，记录下来供学习或回顾。","text":"本文内容是基于研发部门内部的分享整理，记录下来供学习或回顾。 1. 为什么要用线程池 降低资源消耗。通过重复利用已创建的线程降低线程创建、销毁线程造成的消耗。 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配、调优和监控 2. ThreadPoolExecutor线程池类参数详解 参数 说明 corePoolSize 核心线程数量，线程池维护线程的最少数量 maximumPoolSize 线程池维护线程的最大数量 keepAliveTime 线程池除核心线程外的其他线程的最长空闲时间，超过该时间的空闲线程会被销毁 unit keepAliveTime的单位，TimeUnit中的几个静态属性：NANOSECONDS、MICROSECONDS、MILLISECONDS、SECONDS workQueue 线程池所使用的任务缓冲队列 threadFactory 线程工厂，用于创建线程，一般用默认的即可 handler 线程池对拒绝任务的处理策略 当线程池任务处理不过来的时候（什么时候认为处理不过来后面描述），可以通过handler指定的策略进行处理，ThreadPoolExecutor提供了四种策略： ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常；也是默认的处理方式。 ThreadPoolExecutor.DiscardPolicy：丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程） ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 可以通过实现RejectedExecutionHandler接口自定义处理方式。 3. 线程池任务执行3.1. 添加执行任务 submit() 该方法返回一个Future对象，可执行带返回值的线程；或者执行想随时可以取消的线程。Future对象的get()方法获取返回值。Future对象的cancel(true/false)取消任务，未开始或已完成返回false，参数表示是否中断执行中的线程 execute() 没有返回值。 3.2. 线程池任务提交过程一个线程提交到线程池的处理流程如下图 如果此时线程池中的数量小于corePoolSize，即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务。 如果此时线程池中的数量等于corePoolSize，但是缓冲队列workQueue未满，那么任务被放入缓冲队列。 如果此时线程池中的数量大于等于corePoolSize，缓冲队列workQueue满，并且线程池中的数量小于maximumPoolSize，建新的线程来处理被添加的任务。 如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量等于maximumPoolSize，那么通过 handler所指定的策略来处理此任务。 当线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止。这样，线程池可以动态的调整池中的线程数。 总结即：处理任务判断的优先级为 核心线程corePoolSize、任务队列workQueue、最大线程maximumPoolSize，如果三者都满了，使用handler处理被拒绝的任务。 注意： 当workQueue使用的是无界限队列时，maximumPoolSize参数就变的无意义了，比如new LinkedBlockingQueue(),或者new ArrayBlockingQueue(Integer.MAX_VALUE); 使用SynchronousQueue队列时由于该队列没有容量的特性，所以不会对任务进行排队，如果线程池中没有空闲线程，会立即创建一个新线程来接收这个任务。maximumPoolSize要设置大一点。 核心线程和最大线程数量相等时keepAliveTime无作用. 3.3. 线程池关闭 shutdown() 不接收新任务,会处理已添加任务 shutdownNow() 不接受新任务,不处理已添加任务,中断正在处理的任务 4. 常用队列介绍 ArrayBlockingQueue： 这是一个由数组实现的容量固定的有界阻塞队列. SynchronousQueue： 没有容量，不能缓存数据；每个put必须等待一个take; offer()的时候如果没有另一个线程在poll()或者take()的话返回false。 LinkedBlockingQueue： 这是一个由单链表实现的默认无界的阻塞队列。LinkedBlockingQueue提供了一个可选有界的构造函数，而在未指明容量时，容量默认为Integer.MAX_VALUE。 队列操作: 方法 说明 add 增加一个元索; 如果队列已满，则抛出一个异常 remove 移除并返回队列头部的元素; 如果队列为空，则抛出一个异常 offer 添加一个元素并返回true; 如果队列已满，则返回false poll 移除并返回队列头部的元素; 如果队列为空，则返回null put 添加一个元素; 如果队列满，则阻塞 take 移除并返回队列头部的元素; 如果队列为空，则阻塞 element 返回队列头部的元素; 如果队列为空，则抛出一个异常 peek 返回队列头部的元素; 如果队列为空，则返回null 5. Executors线程工厂类 Executors.newCachedThreadPool();说明: 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程.内部实现：new ThreadPoolExecutor(0,Integer.MAX_VALUE,60L,TimeUnit.SECONDS,new SynchronousQueue()); Executors.newFixedThreadPool(int);说明: 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。内部实现：new ThreadPoolExecutor(nThreads, nThreads,0L,TimeUnit.MILLISECONDS,new LinkedBlockingQueue()); Executors.newSingleThreadExecutor();说明:创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照顺序执行。内部实现：new ThreadPoolExecutor(1,1,0L,TimeUnit.MILLISECONDS,new LinkedBlockingQueue()) Executors.newScheduledThreadPool(int);说明:创建一个定长线程池，支持定时及周期性任务执行。内部实现：new ScheduledThreadPoolExecutor(corePoolSize) 【附】阿里巴巴Java开发手册中对线程池的使用规范 【强制】创建线程或线程池时请指定有意义的线程名称，方便出错时回溯。正例： 123456public class TimerTaskThread extends Thread &#123; public TimerTaskThread()&#123; super.setName(\"TimerTaskThread\"); ... &#125;&#125; 【强制】线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。说明： 使用线程池的好处是减少在创建和销毁线程上所花的时间以及系统资源的开销，解决资源不足的问题。如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。 【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。说明： Executors 返回的线程池对象的弊端如下：1） FixedThreadPool 和 SingleThreadPool:允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。2） CachedThreadPool 和 ScheduledThreadPool:允许的创建线程数量为 Integer.MAX_VALUE， 可能会创建大量的线程，从而导致 OOM。 6. 总结ThreadPoolExecutor通过几个核心参数来定义不同类型的线程池，适用于不同的使用场景；其中在任务提交时，会依次判断corePoolSize， workQueque， 及maximumPoolSize，不同的状态不同的处理。技术领域水太深，如果不是日常使用，基本一段时间后某些知识点就忘的差不多了，因此阶段性地回顾与总结，对夯实自己的技术基础很有必要。我的个人博客地址：http://blog.jboost.cn我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注，及时获取更新内容）———————————————————————————————————————————————————————————————","categories":[{"name":"高效实践","slug":"高效实践","permalink":"http://blog.jboost.cn/categories/高效实践/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"concurrency","slug":"concurrency","permalink":"http://blog.jboost.cn/tags/concurrency/"}]},{"title":"Spring Boot从入门到实战（九）：统一异常处理","slug":"springboot-error","date":"2019-07-03T06:35:02.000Z","updated":"2019-07-22T10:30:36.823Z","comments":true,"path":"springboot-error.html","link":"","permalink":"http://blog.jboost.cn/springboot-error.html","excerpt":"都说管理的精髓就是“制度管人，流程管事”。而所谓流程，就是对一些日常工作环节、方式方法、次序等进行标准化、规范化。且不论精不精髓，在技术团队中，对一些通用场景，统一规范是必要的，只有步调一致，才能高效向前。如前后端交互协议，如本文探讨的异常处理。","text":"都说管理的精髓就是“制度管人，流程管事”。而所谓流程，就是对一些日常工作环节、方式方法、次序等进行标准化、规范化。且不论精不精髓，在技术团队中，对一些通用场景，统一规范是必要的，只有步调一致，才能高效向前。如前后端交互协议，如本文探讨的异常处理。 1. Spring Mvc中的异常处理在spring mvc中，跟异常处理的相关类大致如下 上图中，spring mvc中处理异常的类（包括在请求映射时与请求处理过程中抛出的异常），都是 HandlerExceptionResolver 接口的实现，并且都实现了 Ordered 接口。与拦截器链类似，如果容器中存在多个实现了 HandlerExceptionResolver 接口的异常处理类，则它们的 resolveException 方法会被依次调用，顺序由order决定，值越小的先执行，只要其中一个调用返回不是null，则后续的异常处理将不再执行。 各实现类简单介绍如下： DefaultHandlerExceptionResolver： 这个是默认实现，处理Spring定义的各种标准异常，将其转换为对应的Http Status Code，具体处理的异常参考 doResolveException 方法 ResponseStatusExceptionResolver：用来支持@ResponseStatus注解使用的实现，如果自定义的异常通过@ResponseStatus注解进行了修饰，并且容器中存在ResponseStatusExceptionResolver的bean，则自定义异常抛出时会被该bean进行处理，返回注解定义的Http Status Code及内容给客户端 ExceptionHandlerExceptionResolver：用来支持@ExceptionHandler注解使用的实现，使用该注解修饰的方法来处理对应的异常。不过该注解的作用范围只在controller类，如果需要全局处理，则需要配合@ControllerAdvice注解使用。 SimpleMappingExceptionResolver：将异常映射为视图 HandlerExceptionResolverComposite：就是各类实现的组合，依次执行，只要其中一个处理返回不为null，则不再处理。 因为本文主要是对spring boot如何对异常统一处理进行探讨，所以以上只对各实现做了基本介绍，更加详细的内容可查阅相关文档或后续再补上。 2. Spring Boot中如何统一异常处理通过第一部分介绍，可以使用@ExceptionHandler + @ControllerAdvice 组合的方式来实现异常的全局统一处理。对于REST服务来说，spring mvc提供了一个抽象类 ResponseEntityExceptionHandler， 该类类似于上面介绍的 DefaultHandlerExceptionResolver，对一些标准的异常进行了处理，但不是返回 ModelAndView对象， 而是返回 ResponseEntity对象。故我们可以基于该类来实现REST服务异常的统一处理定义异常处理类 BaseWebApplicationExceptionHandler 如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@RestControllerAdvicepublic class BaseWebApplicationExceptionHandler extends ResponseEntityExceptionHandler &#123; private boolean includeStackTrace; public BaseWebApplicationExceptionHandler(boolean includeStackTrace)&#123; super(); this.includeStackTrace = includeStackTrace; &#125; private final Logger logger = LoggerFactory.getLogger(getClass()); @ExceptionHandler(BizException.class) public ResponseEntity&lt;Object&gt; handleBizException(BizException ex) &#123; logger.warn(\"catch biz exception: \" + ex.toString(), ex.getCause()); return this.asResponseEntity(HttpStatus.valueOf(ex.getHttpStatus()), ex.getErrorCode(), ex.getErrorMessage(), ex); &#125; @ExceptionHandler(&#123;IllegalArgumentException.class, IllegalStateException.class&#125;) public ResponseEntity&lt;Object&gt; handleIllegalArgumentException(Exception ex) &#123; logger.warn(\"catch illegal exception.\", ex); return this.asResponseEntity(HttpStatus.BAD_REQUEST, HttpStatus.BAD_REQUEST.name().toLowerCase(), ex.getMessage(), ex); &#125; @ExceptionHandler(Exception.class) public ResponseEntity&lt;Object&gt; handleException(Exception ex) &#123; logger.error(\"catch exception.\", ex); return this.asResponseEntity(HttpStatus.INTERNAL_SERVER_ERROR, HttpStatus.INTERNAL_SERVER_ERROR.name().toLowerCase(), ExceptionConstants.INNER_SERVER_ERROR_MSG, ex); &#125; protected ResponseEntity&lt;Object&gt; handleExceptionInternal( Exception ex, @Nullable Object body, HttpHeaders headers, HttpStatus status, WebRequest request) &#123; if (HttpStatus.INTERNAL_SERVER_ERROR.equals(status)) &#123; request.setAttribute(WebUtils.ERROR_EXCEPTION_ATTRIBUTE, ex, WebRequest.SCOPE_REQUEST); &#125; logger.warn(\"catch uncustom exception.\", ex); return this.asResponseEntity(status, status.name().toLowerCase(), ex.getMessage(), ex); &#125; protected ResponseEntity&lt;Object&gt; asResponseEntity(HttpStatus status, String errorCode, String errorMessage, Exception ex) &#123; Map&lt;String, Object&gt; data = new LinkedHashMap&lt;&gt;(); data.put(BizException.ERROR_CODE, errorCode); data.put(BizException.ERROR_MESSAGE, errorMessage); //是否包含异常的stack trace if(includeStackTrace)&#123; addStackTrace(data, ex); &#125; return new ResponseEntity&lt;&gt;(data, status); &#125; private void addStackTrace(Map&lt;String, Object&gt; errorAttributes, Throwable error) &#123; StringWriter stackTrace = new StringWriter(); error.printStackTrace(new PrintWriter(stackTrace)); stackTrace.flush(); errorAttributes.put(BizException.ERROR_TRACE, stackTrace.toString()); &#125;&#125; 这里有几点： 定义了一个includeStackTrace变量，来控制是否输出异常栈信息 自定义了一个异常类BizException，表示可预知的业务异常，并对它提供了处理方法，见handleBizException方法 对其它未预知异常，用Exception类型进行最后处理，见handleException方法 重写了超类的handleExceptionInternal方法，统一响应内容的字段与格式 针对REST服务，使用的是@RestControllerAdvice注解，而不是@ControllerAdvice BaseWebApplicationExceptionHandler是通过增强的方式对controller抛出的异常做了统一处理，那如果请求都没有到达controller怎么办，比如在过滤器那边就抛异常了，Spring Boot其实对错误的处理做了一些自动化配置，参考ErrorMvcAutoConfiguration类，具体这里不详述，只提出方案——自定义ErrorAttributes实现，如下所示1234567891011public class BaseErrorAttributes extends DefaultErrorAttributes &#123; private boolean includeStackTrace; @Override public Map&lt;String, Object&gt; getErrorAttributes(WebRequest webRequest, boolean includeStackTrace) &#123; Map&lt;String, Object&gt; errorAttributes = new LinkedHashMap&lt;String, Object&gt;(); addStatus(errorAttributes, webRequest); addErrorDetails(errorAttributes, webRequest, this.includeStackTrace); return errorAttributes; &#125; 以上只列出了主要部分，具体实现可参考源码。这里同样定义了includeStackTrace来控制是否包含异常栈信息。 最后，将以上两个实现通过配置文件注入容器，如下：123456789101112131415161718192021222324252627282930313233@Configuration@ConditionalOnClass(&#123;Servlet.class, DispatcherServlet.class, WebMvcConfigurer.class&#125;)@ConditionalOnMissingBean(ResponseEntityExceptionHandler.class)@AutoConfigureBefore(ErrorMvcAutoConfiguration.class)public class ExceptionHandlerAutoConfiguration &#123; @Profile(&#123;\"test\", \"formal\", \"prod\"&#125;) @Bean public ResponseEntityExceptionHandler defaultGlobalExceptionHandler() &#123; //测试、正式环境，不输出异常的stack trace return new BaseWebApplicationExceptionHandler(false); &#125; @Profile(&#123;\"default\",\"local\",\"dev\"&#125;) @Bean public ResponseEntityExceptionHandler devGlobalExceptionHandler() &#123; //本地、开发环境，输出异常的stack trace return new BaseWebApplicationExceptionHandler(true); &#125; @Profile(&#123;\"test\", \"formal\", \"prod\"&#125;) @Bean public ErrorAttributes basicErrorAttributes() &#123; //测试、正式环境，不输出异常的stack trace return new BaseErrorAttributes(false); &#125; @Profile(&#123;\"default\",\"local\",\"dev\"&#125;) @Bean public ErrorAttributes devBasicErrorAttributes() &#123; //本地、开发环境，输出异常的stack trace return new BaseErrorAttributes(true); &#125;&#125; 上面的@Profile主要是控制针对不同环境，输出不同的响应内容。以上配置的意思是在profile为default、local、dev时，响应内容中包含异常栈信息；profile为test、formal、prod时，响应内容不包含异常栈信息。这么做的好处是，开发阶段，当前端联调时，如果出错，可直接从响应内容中看到异常栈，方便服务端开发人员快速定位问题，而测试、生产环境， 就不要返回异常栈信息了。 3. 基于Spring Boot的异常处理规范 异常的表示形式异常一般可通过自定义异常类，或定义异常的信息，比如code，message之类，然后通过一个统一的异常类进行封装。如果每一种异常都定义一个异常类，则会造成异常类过多，所以实践开发中我一般倾向于后者。可以定义一个接口，该接口主要是方便后面的异常处理工具类实现12345public interface BaseErrors &#123; String getCode(); String getMsg();&#125; 然后定义一个枚举，实现该接口，在该枚举中定义异常信息，如123456789101112131415161718public enum ErrorCodeEnum implements BaseErrors &#123; qrcode_existed(\"该公众号下已存在同名二维码\"), authorizer_notexist(\"公众号不存在\"), private String msg; private ErrorCodeEnum(String msg) &#123; this.msg = msg; &#125; public String getCode() &#123; return name(); &#125; public String getMsg() &#123; return msg; &#125;&#125; 封装异常处理分场景定义了ClientSideException，ServerSideException，UnauthorizedException，ForbiddenException异常，分别表示客户端异常（400），服务端异常（500），未授权异常（401），禁止访问异常（403），如ClientSideException定义12345678910public class ClientSideException extends BizException &#123; public &lt;E extends Enum&lt;E&gt; &amp; BaseErrors&gt; ClientSideException(E exceptionCode, Throwable cause) &#123; super(HttpStatus.BAD_REQUEST, exceptionCode, cause); &#125; public &lt;E extends Enum&lt;E&gt; &amp; BaseErrors&gt; ClientSideException(E exceptionCode) &#123; super(HttpStatus.BAD_REQUEST, exceptionCode, null); &#125;&#125; 并且提供一个异常工具类ExceptionUtil，方便不同场景使用， rethrowClientSideException：抛出ClientSideException，将以status code 400返回客户端。由客户端引起的异常调用该方法，如参数校验失败。 rethrowUnauthorizedException： 抛出UnauthorizedException，将以status code 401返回客户端。访问未授权时调用，如token校验失败等。 rethrowForbiddenException： 抛出ForbidenException，将以status code 403返回客户端。访问被禁止时调用，如用户被禁用等。 rethrowServerSideException： 抛出ServerSideException，将以status code 500返回客户端。服务端引起的异常调用该方法，如调用第三方服务异常，数据库访问出错等。 在实际使用时，分两种情况， 不通过try/catch主动抛出异常，如： 1234if (StringUtils.isEmpty(appId)) &#123; LOG.warn(\"the authorizer for site[&#123;&#125;] is not existed.\", templateMsgRequestDto.getSiteId()); ExceptionUtil.rethrowClientSideException(ErrorCodeEnum.authorizer_notexist);&#125; 通过try/catch异常重新抛出（注意：可预知的异常，需要给客户端返回某种提示信息的，必须通过该方式重新抛出。否则将返回统一的code 500,提示“抱歉，服务出错了，请稍后重试”的提示信息）如： 1234567try &#123; String result = wxOpenService.getWxOpenComponentService().getWxMpServiceByAppid(appId).getTemplateMsgService().sendTemplateMsg(templateMessage); LOG.info(\"result: &#123;&#125;\", result);&#125; catch (WxErrorException wxException) &#123; //这里不需要打日志，会统一在异常处理里记录日志 ExceptionUtil.rethrowServerSideException(ExceptionCodeEnum.templatemsg_fail, wxException);&#125; 具体实现参考源码： https://github.com/ronwxy/base-spring-boot/tree/master/spring-boot-autoconfigure/src/main/java/cn/jboost/springboot/autoconfig/error另附demo源码：https://github.com/ronwxy/springboot-demos/tree/master/springboot-error 4. 总结本文写完感觉信息量有点多，对于不具备一定基础的人来说理解可能有点难度。如果有任何疑问，欢迎交流。后续有需要的话也可以针对某个环节再进行细化补充。本文所提的规范不一定是最好的实践，但规范或流程的管理，都是遵循先僵化，后优化，再固化的步骤，先解决有没有的问题，再解决好不好的问题。我的个人博客地址：http://blog.jboost.cn我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy （一个不只有技术干货的公众号，欢迎关注）———————————————————————————————————————————————————————————————欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"使用nvm来管理Node多版本","slug":"use-nvm","date":"2019-07-02T00:41:51.000Z","updated":"2019-07-09T11:19:28.689Z","comments":true,"path":"use-nvm.html","link":"","permalink":"http://blog.jboost.cn/use-nvm.html","excerpt":"最近在为前端配置jenkins持续集成环境时，在运行npm install下载依赖包的时候，速度极慢，而本地很快。对比node版本，一个v10.15.3，速度很快，一个v8.10.0，速度极慢。两者都设置了国内镜像。升级node能否解决问题？有没有工具支持node多版本管理，像python的anaconda一样？答案是有，叫nvm —— node version manager。","text":"最近在为前端配置jenkins持续集成环境时，在运行npm install下载依赖包的时候，速度极慢，而本地很快。对比node版本，一个v10.15.3，速度很快，一个v8.10.0，速度极慢。两者都设置了国内镜像。升级node能否解决问题？有没有工具支持node多版本管理，像python的anaconda一样？答案是有，叫nvm —— node version manager。 项目地址： https://github.com/nvm-sh/nvm 1. 安装linux下：12345# 下载并执行安装curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash# 安装后执行source使其生效source ~/.bashrc 为了加速node的下载，可在~/.bashrc中添加 export NVM_NODEJS_ORG_MIRROR=https://npm.taobao.org/mirrors/node windows：参考 https://github.com/coreybutler/nvm-windows/releases 2. 使用 列出所有node版本nvm ls-remote 只列出长期支持版本，一般生产环境使用long term support版nvm ls-remote --lts 安装指定版本nvm install v10.15.3 安装完后即可查看安装的node及npm的版本 12node -v npm -v 查看已安装版本nvm ls 使用指定的版本，重连bash即失效nvm use 10.15.3 设置默认，重连也生效nvm alias default 10.15.3 配置npm国内淘宝镜像123npm config set registry https://registry.npm.taobao.org --globalnpm config set disturl https://npm.taobao.org/dist --global 3. 总结nvm可在一个系统中非常便捷地管理多个node版本，并能自由切换使用哪个版本，方便需要多版本并存的场景。 我的个人博客地址：http://blog.jboost.cn我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy————————————————————————————————————————欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"高效实践","slug":"高效实践","permalink":"http://blog.jboost.cn/categories/高效实践/"}],"tags":[{"name":"node","slug":"node","permalink":"http://blog.jboost.cn/tags/node/"},{"name":"npm","slug":"npm","permalink":"http://blog.jboost.cn/tags/npm/"}]},{"title":"redission-tomcat 快速实现从单机部署到多机部署","slug":"session-redis","date":"2019-06-29T01:01:24.000Z","updated":"2019-07-09T11:19:28.777Z","comments":true,"path":"session-redis.html","link":"","permalink":"http://blog.jboost.cn/session-redis.html","excerpt":"一些项目初期出于简单快速，都是做单机开发与部署，但是随着业务的扩展或对可用性要求的提高，单机环境已不满足需求。单机部署往多机部署切换，其中可能存在的一个重要环节就是session的共享（如果一开始就是基于token的认证则可忽略）。本文介绍一个基于redis的tomcat session管理开源项目：redission-tomcat，可无代码侵入式地快速实现session共享。","text":"一些项目初期出于简单快速，都是做单机开发与部署，但是随着业务的扩展或对可用性要求的提高，单机环境已不满足需求。单机部署往多机部署切换，其中可能存在的一个重要环节就是session的共享（如果一开始就是基于token的认证则可忽略）。本文介绍一个基于redis的tomcat session管理开源项目：redission-tomcat，可无代码侵入式地快速实现session共享。 1. 简介redisson是与jedis类似的一个redis客户端，其功能比jedis要更丰富一些。redission-tomcat是一个基于redis的tomcat session管理器项目，项目地址：https://github.com/redisson/redisson/tree/master/redisson-tomcat 。相比于其它实现，该项目的存储更为高效，写操作也更为优化。每一个session参数是在调用HttpSession.setAttribute时写入redis的，其它方案却一般是每次都将整个session进行序列化后写入。 2. 使用 将redisson-all-3.11.0.jar，redisson-tomcat-8-3.11.0.jar（针对tomcat8，其它版本可在上述项目地址页面找到下载链接）两个jar包下载放到tomcat的lib目录下。 在tomcat conf目录下的context.xml文件中添加如下配置 123&lt;Manager className=\"org.redisson.tomcat.RedissonSessionManager\"configPath=\"$&#123;catalina.base&#125;/conf/redisson.conf\" readMode=\"MEMORY\" updateMode=\"AFTER_REQUEST\" broadcastSessionEvents=\"false\"/&gt; 其中 configPath：指向Redisson的json或yaml格式的配置文件，第3步中给出。 readMode：session属性的读取模式。可取值 1. MEMORY, 该模式会将session属性同时保存到本地tomcat session与redis中，后续的session更新通过redis事件传播到本地tomcat session；2. REDIS，只将session属性保存到redis中。默认为REDIS。 updateMode：session属性的更新模式。可取值 1. DEFAULT，session属性只通过setAttribute方法保存到redis中；2. AFTER_REQUEST，在每次请求之后，将所有session属性保存至redis。默认为DEFAULT。 broadcastSessionEvents：如果设置为true，则sessionCreated与sessionDestroyed事件将会被广播到所有tomcat实例，并使所有注册的HttpSessionListeners监听器被触发。默认为false。 在tomcat conf目录下新增配置文件redisson.conf，内容如下12345678910111213141516171819202122232425&#123; \"singleServerConfig\":&#123; \"idleConnectionTimeout\":10000, \"connectTimeout\":10000, \"timeout\":3000, \"retryAttempts\":3, \"retryInterval\":1500, \"password\":\"123456\", \"subscriptionsPerConnection\":5, \"clientName\":null, \"address\": \"redis://127.0.0.1:6379\", \"subscriptionConnectionMinimumIdleSize\":1, \"subscriptionConnectionPoolSize\":50, \"connectionMinimumIdleSize\":24, \"connectionPoolSize\":64, \"database\":0, \"dnsMonitoringInterval\":5000 &#125;, \"threads\":16, \"nettyThreads\":32, \"codec\":&#123; \"class\":\"org.redisson.codec.FstCodec\" &#125;, \"transportMode\":\"NIO\"&#125; 以上为单机模式redis环境配置，其中password，address修改为自己的值。如果是集群模式，则配置文件为12345678910111213141516171819202122232425262728293031323334353637&#123; \"sentinelServersConfig\":&#123; \"idleConnectionTimeout\":10000, \"connectTimeout\":10000, \"timeout\":3000, \"retryAttempts\":3, \"retryInterval\":1500, \"failedSlaveReconnectionInterval\":3000, \"failedSlaveCheckInterval\":60000, \"password\":null, \"subscriptionsPerConnection\":5, \"clientName\":null, \"loadBalancer\":&#123; \"class\":\"org.redisson.connection.balancer.RoundRobinLoadBalancer\" &#125;, \"subscriptionConnectionMinimumIdleSize\":1, \"subscriptionConnectionPoolSize\":50, \"slaveConnectionMinimumIdleSize\":24, \"slaveConnectionPoolSize\":64, \"masterConnectionMinimumIdleSize\":24, \"masterConnectionPoolSize\":64, \"readMode\":\"SLAVE\", \"subscriptionMode\":\"SLAVE\", \"sentinelAddresses\":[ \"redis://127.0.0.1:26379\", \"redis://127.0.0.1:26389\" ], \"masterName\":\"mymaster\", \"database\":0 &#125;, \"threads\":16, \"nettyThreads\":32, \"codec\":&#123; \"class\":\"org.redisson.codec.FstCodec\" &#125;, \"transportMode\":\"NIO\"&#125; 我们可以使用nginx来实现负载均衡，参考配置1234567891011121314151617upstream cnserver&#123; server 127.0.0.1:8080 weight=2 fail_timeout=10s max_fails=1; server 127.0.0.1:8081 weight=2 fail_timeout=10s max_fails=1;&#125;server &#123; listen 80; server_name localhost; index index.html index.htm; location /rest/ &#123; index index.html; proxy_pass http://cnserver/rest/; &#125;&#125; 以上即为使用redisson-tomcat来实现单机部署到多机部署的所有配置。 3. 总结技术架构都是随着业务的发展而不断演进。在业务发展初期，用户量、业务复杂度都相对较低，为了实现快速上线验证，往往采用简单单一的架构。许多项目可能还没来得及进行架构演进升级就GG了，而有幸继续成长的项目必然会随着业务的扩张不断优化与升级。本文介绍的redisson-tomcat可帮助单机项目快速切换到多机支持，当然只是在session管理环节。如果涉及到其它如文件上传，定时任务等分布式支持，则要另做相应调整了。 我的个人博客地址：http://blog.jboost.cn我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy （一个不只有实战干货的技术公众号， 欢迎关注）———————————————————————————————————————————————————————————————欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"高效实践","slug":"高效实践","permalink":"http://blog.jboost.cn/categories/高效实践/"}],"tags":[{"name":"session","slug":"session","permalink":"http://blog.jboost.cn/tags/session/"},{"name":"tomcat","slug":"tomcat","permalink":"http://blog.jboost.cn/tags/tomcat/"},{"name":"redission","slug":"redission","permalink":"http://blog.jboost.cn/tags/redission/"}]},{"title":"swagger api文档集中化注册管理","slug":"swagger-register","date":"2019-06-28T08:59:05.000Z","updated":"2019-07-09T11:19:30.989Z","comments":true,"path":"swagger-register.html","link":"","permalink":"http://blog.jboost.cn/swagger-register.html","excerpt":"接口文档是前后端开发对接时很重要的一个组件。手动编写接口文档既费时，又存在文档不能随代码及时更新的问题，因此产生了像swagger这样的自动生成接口文档的框架。swagger文档一般是随项目代码生成与更新，访问地址也是基于项目地址，因此对项目数不多的团队还好。如果团队的项目很多，比如采用微服务架构的团队，动则几十甚至上百个服务项目，那就意味着前端开发人员需要记住几十甚至上百个swagger文档地址，那就很不友好了。目前貌似还没有较流行的API文档集中化管理项目（也或者是我没找到），因此花了点时间自己集成了一个，介绍如下。","text":"接口文档是前后端开发对接时很重要的一个组件。手动编写接口文档既费时，又存在文档不能随代码及时更新的问题，因此产生了像swagger这样的自动生成接口文档的框架。swagger文档一般是随项目代码生成与更新，访问地址也是基于项目地址，因此对项目数不多的团队还好。如果团队的项目很多，比如采用微服务架构的团队，动则几十甚至上百个服务项目，那就意味着前端开发人员需要记住几十甚至上百个swagger文档地址，那就很不友好了。目前貌似还没有较流行的API文档集中化管理项目（也或者是我没找到），因此花了点时间自己集成了一个，介绍如下。 1. swagger-bootstrap-ui项目该项目是github上的一个开源项目（https://github.com/xiaoymin/swagger-bootstrap-ui ），对swagger ui做了增强，功能整体看起来要丰富一些。来看看效果， 该项目的调试url地址原本是基于自身服务的，我将它改为了注册服务的url地址，以支持注册服务的接口调试。调整后的源码地址： https://github.com/ronwxy/swagger-bootstrap-ui 2. swagger api注册服务该项目集成了swagger-bootstrap-ui，并提供了swagger api注册接口，接受所有提供了有效配置的服务项目注册，让注册的服务在一个页面上可统一查看，再也不用记太多文档地址了。 启动注册服务后，访问 http://localhost:11090/doc.html 打开文档页面。如上图，可通过下拉列表来选择不同项目，加载项目的接口文档查看或调试。项目地址： https://github.com/ronwxy/swagger-register （如果觉得有用，不要吝啬你的star，反正又不要钱，O(∩_∩)O） 3. 服务端配置在业务服务端，需要提供一些配置。首先，需要配置一些Bean，如下提供了一个配置类（这里只列出了主要部分，完整代码参考： https://github.com/ronwxy/base-spring-boot）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class Swagger2AutoConfiguration &#123; @Bean public Docket restApi() &#123; ParameterBuilder builder = new ParameterBuilder(); builder.name(\"x-auth-token\").description(\"授权token\") .modelRef(new ModelRef(\"string\")) .parameterType(\"header\") .required(false); return new Docket(DocumentationType.SWAGGER_2) .groupName(groupName) .select() .apis(RequestHandlerSelectors.basePackage(apisBasePackage)) .paths(PathSelectors.any()) .build() .globalOperationParameters(Collections.singletonList(builder.build())) .apiInfo(apiInfo()); &#125; @Profile(&#123;\"dev\"&#125;) @Bean public CommandLineRunner swaggerRegistar(ConfigurableApplicationContext context) &#123; return new SwaggerInfoRegistar(context); &#125; /** * use to register swagger api info url to swagger api registry; * * @author liubo */ public class SwaggerInfoRegistar implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; String url = buildLocalSwaggerDocsUrl(); registerLocalSwaggerUrl(url); &#125; /** * register the v2/api-docs url * * @param url */ private void registerLocalSwaggerUrl(String url) &#123; RestTemplate restTemplate = new RestTemplate(); restTemplate.getMessageConverters().add(new FormHttpMessageConverter()); MultiValueMap&lt;String, Object&gt; body = new LinkedMultiValueMap&lt;&gt;(); body.add(\"project\", getApiTitle()); body.add(\"url\", url); ResponseEntity&lt;Map&gt; re = restTemplate.postForEntity(getSwaggerRegisterUrl(), body, Map.class); if (HttpStatus.OK.equals(re.getStatusCode())) &#123; logger.info(\"swagger api registered success to &#123;&#125;\", getSwaggerRegisterUrl()); &#125; else &#123; logger.warn(\"swagger api registered failed [&#123;&#125;]\", re.getBody().get(\"msg\")); &#125; &#125; &#125;&#125; 该类完成了swagger的基本配置，同时将swagger的/v2/api-docs地址注册到了步骤2中介绍的注册服务。 然后，因为要从注册服务端调用该业务服务的接口进行调试，存在跨域，因此服务需要做跨域支持，配置文件中添加如下定义， 1234567891011121314151617181920@Bean@ConditionalOnMissingBean(name = \"corsFilterRegistrationBean\")public FilterRegistrationBean corsFilterRegistrationBean() &#123; UrlBasedCorsConfigurationSource corsConfigurationSource = new UrlBasedCorsConfigurationSource(); CorsConfiguration corsConfiguration = new CorsConfiguration(); corsConfiguration.applyPermitDefaultValues(); corsConfiguration.setAllowedMethods(Arrays.asList(CorsConfiguration.ALL)); corsConfiguration.addExposedHeader(HttpHeaders.DATE); corsConfigurationSource.registerCorsConfiguration(\"/**\", corsConfiguration); CorsFilter corsFilter = new CorsFilter(corsConfigurationSource); FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); filterRegistrationBean.setFilter(corsFilter); filterRegistrationBean.setOrder(Ordered.HIGHEST_PRECEDENCE); filterRegistrationBean.addUrlPatterns(\"/*\"); return filterRegistrationBean;&#125; 最后，在属性配置文件application.yml中配置一些必要的属性，123456swagger: api-title: Demo标题 #会展示在下拉列表框中，一般写项目名称 api-description: Demo描述，集中注册 group-name: Demo项目 apis-base-package: cn.jboost.springboot.swagger # API类所在包名 swagger-registry-path: http://localhost:11090/swagger/register #就是2中注册服务的注册接口地址 配置完后， 就可以像一般项目一样编写接口类，加swagger注解。项目启动时， 会自动向注册服务完成注册，刷新注册服务的文档页面即可在下拉列表看到。 4. 总结本文介绍了一个基于swagger ui增强版项目swagger-bootstrap-ui的接口文档集中化管理实现。采用该实现，将所有swagger在线接口文档集中管理，有效提高前后端对接效率。 如果觉得本文有用，欢迎转发、推荐。 我的个人博客地址：http://blog.jboost.cn我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy （欢迎关注，及时获取技术干货分享）———————————————————————————————————————————————————————————————欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"高效实践","slug":"高效实践","permalink":"http://blog.jboost.cn/categories/高效实践/"}],"tags":[{"name":"swagger","slug":"swagger","permalink":"http://blog.jboost.cn/tags/swagger/"}]},{"title":"Spring Boot从入门到实战（八）：集成AOPLog来记录接口访问日志","slug":"springboot-aoplog","date":"2019-06-27T03:03:57.000Z","updated":"2019-07-24T01:51:53.445Z","comments":true,"path":"springboot-aoplog.html","link":"","permalink":"http://blog.jboost.cn/springboot-aoplog.html","excerpt":"日志是一个Web项目中必不可少的部分，借助它我们可以做许多事情，比如问题排查、访问统计、监控告警等。一般通过引入slf4j的一些实现框架来做日志功能，如log4j,logback,log4j2，其性能也是依次增强。在springboot中，默认使用的框架是logback。我们经常需要在方法开头或结尾加日志记录传入参数或返回结果，以此来复现当时的请求情况。但是手动添加日志，不仅繁琐重复，也影响代码的美观简洁。本文引入一个基于AOP实现的日志框架，并通过spring-boot-starter的方式完成集成。 原文地址：http://blog.jboost.cn/springboot-aoplog.html","text":"日志是一个Web项目中必不可少的部分，借助它我们可以做许多事情，比如问题排查、访问统计、监控告警等。一般通过引入slf4j的一些实现框架来做日志功能，如log4j,logback,log4j2，其性能也是依次增强。在springboot中，默认使用的框架是logback。我们经常需要在方法开头或结尾加日志记录传入参数或返回结果，以此来复现当时的请求情况。但是手动添加日志，不仅繁琐重复，也影响代码的美观简洁。本文引入一个基于AOP实现的日志框架，并通过spring-boot-starter的方式完成集成。 原文地址：http://blog.jboost.cn/springboot-aoplog.html 1. aop-logging项目项目地址： https://github.com/ronwxy/aop-logging该项目基于 https://github.com/nickvl/aop-logging.git ， 在其基础上添加了ReqId来串联某次客户端请求（参考com.github.nickvl.xspring.core.log.aop.ReqIdFilter）, 添加了方法执行时长（参考com.github.nickvl.xspring.core.log.aop.AOPLogger.logTheMethod方法中elapsedTime）。 该项目提供了基于注解的AOP日志功能。根据不同的日志级别，提供的注解有LogTrace,LogDebug,LogInfo,LogWarn,LogError,LogFatal,LogException，可修饰于类（等同于该类内所有方法上添加）与方法上，前面六个分别表示在不同日志级别下记录方法被调用的日志，LogException表示在方法抛出异常时，记录相应日志。这些注解都提供了一个LogPoint枚举类型的属性value，取值{IN,OUT,BOTH}，分别表示在方法调用入口、方法调用返回前，以及包含两者的位置打印对应日志，默认为BOTH。 2. 集成可以通过基于xml或基于java配置的方式来集成AOP日志功能，我这里基于java配置（基于xml的方式参考源码README文件）并且通过spring-boot-starter的形式进行封装（源码地址： https://github.com/ronwxy/base-spring-boot ），避免每个项目都需要配置。自动配置类如下12345678910111213141516171819202122232425262728293031@Configuration@ConditionalOnClass(AOPLogger.class)@ConditionalOnMissingBean(AOPLogger.class)public class AopLoggerAutoConfiguration &#123; private static final boolean SKIP_NULL_FIELDS = true; private static final Set&lt;String&gt; EXCLUDE_SECURE_FIELD_NAMES = Collections.emptySet(); @Bean public AOPLogger aopLogger() &#123; AOPLogger aopLogger = new AOPLogger(); aopLogger.setLogAdapter(new UniversalLogAdapter(SKIP_NULL_FIELDS, EXCLUDE_SECURE_FIELD_NAMES)); return aopLogger; &#125; /** * 注册一个过滤器，用来生成一个reqId，标记一次请求，从而将本次请求所产生的日志串联起来 * @param * @return */ @Bean public FilterRegistrationBean reqIdFilter() &#123; ReqIdFilter reqIdFilter = new ReqIdFilter(); FilterRegistrationBean registrationBean = new FilterRegistrationBean(); registrationBean.setFilter(reqIdFilter); List&lt;String&gt; urlPatterns = Collections.singletonList(\"/*\"); registrationBean.setUrlPatterns(urlPatterns); registrationBean.setOrder(100); return registrationBean; &#125;&#125; 将基础框架base-spring-boot通过mvn clean install进行本地安装后，即可在项目中通过依赖进行引入（基础框架中已在spring-boot-parent中引入，直接继承亦可），如12345&lt;dependency&gt; &lt;groupId&gt;cn.jboost.springboot&lt;/groupId&gt; &lt;artifactId&gt;aoplog-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 3. 使用引入依赖之后，我们再定义一个日志配置文件logback-spring.xml，为了后面方便地将日志导入ELK做集中的日志分析管理，该配置文件中将日志以json格式输出，并根据日志级别分别写入debug.log,info.log,warn.log,error.log以及interface.log（专用于接口访问日志），配置示例如下（完整配置参考： https://github.com/ronwxy/springboot-demos/blob/master/springboot-aoplog/src/main/resources/logback-spring.xml）1234567891011121314151617181920212223242526272829303132&lt;appender name=\"interfaceLog\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt;$&#123;logPath&#125;/elk/interface.log&lt;/file&gt; &lt;encoder class=\"net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder\"&gt; &lt;providers&gt; &lt;pattern&gt; &lt;pattern&gt; &#123; \"project\": \"$&#123;projectName&#125;\", \"timestamp\": \"%date&#123;\\\"yyyy-MM-dd'T'HH:mm:ss,SSSZ\\\"&#125;\", \"log_level\": \"%level\", \"thread\": \"%thread\", \"class_name\": \"%X&#123;callingClass&#125;\", \"class_method\":\"%X&#123;callingMethod&#125;\", \"line_number\": null, \"message\": \"%message\", \"stack_trace\": \"%exception&#123;5&#125;\", \"req_id\": \"%X&#123;reqId&#125;\", \"elapsed_time\": \"#asLong&#123;%X&#123;elapsedTime&#125;&#125;\" &#125; &lt;/pattern&gt; &lt;/pattern&gt; &lt;/providers&gt; &lt;/encoder&gt; &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;/filter&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;$&#123;logPath&#125;/bak/interface.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;totalSizeCap&gt;1GB&lt;/totalSizeCap&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; 为了将该日志配置文件可以不经修改地达到复用，将一些参数配置外置了，故需在配置文件applicaiton.yml中配置如下参数12345logger: path: D:\\logs #默认当前项目路径下的logs目录 level: info # 默认info apiPackage: cn.jboost.springboot.aoplog.controller #必须配置, api接口类所在包 rootPackage: cn.jboost.springboot #必须配置，项目根包，记录该包内各类通过slf4j输出的日志 最后，直接在需要记录访问日志的接口类上加注解@LogInfo就行了，如12345678910@RestController@RequestMapping(\"test\")@LogInfopublic class AoplogTestController &#123; @GetMapping public String test(@RequestParam String user)&#123; return \"Hi \" + user; &#125;&#125; 注意：在pom.xml中默认添加的spring-boot-maven-plugin下需要添加repackage的goal才能自动生成日志目录与日志文件，如下所示 123456789101112131415&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 启动程序，调用@LogInfo标注的接口类下的API时，可以看到控制台有打印接口访问日志，如执行demo程序（源码： https://github.com/ronwxy/springboot-demos/tree/master/springboot-aoplog ），调用 http://localhost:8080/test?user=jboost 时，控制台打印日志如下12[2019-06-27 14:29:59] [INFO ] [http-nio-8080-exec-1] [cn.jboost.springboot.aoplog.controller.AoplogTestController:184] --calling: test(user=jboost)[2019-06-27 14:29:59] [INFO ] [http-nio-8080-exec-1] [cn.jboost.springboot.aoplog.controller.AoplogTestController:189] --returning: test(1 arguments):Hi jboost 日志文件interface.log中打印日志如下，（其中req_id在本次请求的所有日志都相同，这样就可以将一次请求的所有日志串联起来，便于分析与定位问题；elapsed_time标明了方法执行时长，可用于接口性能监测）12&#123;\"project\":\"aoplog-test\",\"timestamp\":\"2019-06-27T14:29:59,030+0800\",\"log_level\":\"INFO\",\"thread\":\"http-nio-8080-exec-1\",\"class_name\":\"cn.jboost.springboot.aoplog.controller.AoplogTestController\",\"class_method\":\"test\",\"line_number\":null,\"message\":\"calling: test(user=jboost)\",\"stack_trace\":\"\",\"req_id\":\"5d146267aa147904bc014e71\",\"elapsed_time\":null&#125;&#123;\"project\":\"aoplog-test\",\"timestamp\":\"2019-06-27T14:29:59,036+0800\",\"log_level\":\"INFO\",\"thread\":\"http-nio-8080-exec-1\",\"class_name\":\"cn.jboost.springboot.aoplog.controller.AoplogTestController\",\"class_method\":\"test\",\"line_number\":null,\"message\":\"returning: test(1 arguments):Hi jboost\",\"stack_trace\":\"\",\"req_id\":\"5d146267aa147904bc014e71\",\"elapsed_time\":2&#125; 4. 总结Web项目中经常需要通过查看接口请求及返回参数来定位问题，手动编写代码打印显得繁琐而重复。使用aop-logging通过简单的注解即可实现接口日志自动打印。本文介绍的方案与日志配置模板可直接用于实际项目开发。当然，注解不仅可用于Controller层，也可以用于Service等其它层，但一般Controller层加上即可，避免日志打印过多。 本文示例项目源码地址：https://github.com/ronwxy/springboot-demos/tree/master/springboot-aoplog我的个人博客地址：http://blog.jboost.cn我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy （欢迎关注，及时获取技术干货分享）—————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"},{"name":"logback","slug":"logback","permalink":"http://blog.jboost.cn/tags/logback/"}]},{"title":"案例解析：springboot自动配置未生效问题定位（条件断点）","slug":"issue-conditiontrack","date":"2019-06-25T13:33:00.000Z","updated":"2019-07-24T01:51:38.811Z","comments":true,"path":"issue-conditiontrack.html","link":"","permalink":"http://blog.jboost.cn/issue-conditiontrack.html","excerpt":"Spring Boot在为开发人员提供更高层次的封装，进而提高开发效率的同时，也为出现问题时如何进行定位带来了一定复杂性与难度。但Spring Boot同时又提供了一些诊断工具来辅助开发与分析，如spring-boot-starter-actuator。本文分享一个基于actuator与IDEA条件断点来定位自动配置未生效的案例。望对类似问题分析与处理提供参考。","text":"Spring Boot在为开发人员提供更高层次的封装，进而提高开发效率的同时，也为出现问题时如何进行定位带来了一定复杂性与难度。但Spring Boot同时又提供了一些诊断工具来辅助开发与分析，如spring-boot-starter-actuator。本文分享一个基于actuator与IDEA条件断点来定位自动配置未生效的案例。望对类似问题分析与处理提供参考。 问题确认在前文介绍的 Spring Boot从入门到实战：整合通用Mapper简化单表操作 中，我们对druid连接池做了自动配置，并且注入了druid的监控统计功能，如下 但本地运行后通过 http://localhost:8080/druid/index.html 访问时却出现错误，通过浏览器的开发者工具查看该请求返回404，推测上述代码中定义的StatViewServlet未注入成功。我们用actuator来确认下是否如此。在项目中加入spring-boot-starter-actuator，并且application.yml中添加如下配置123456789management: endpoints: web: exposure: include: \"*\" exclude: beans,trace endpoint: health: show-details: always 在spring-boot 2.x 版本当中，作为安全性考虑，将actuator 控件中的端口，只默认开放/health 和/info 两个端口，其他端口默认关闭， 因此需要添加如上配置。注意include的值 * 必须加引号，否则无法启动。 重启程序后访问 http://localhost:8080/actuator/conditions 确认上述两个实例化方法未满足@ConditionalOnProperty的条件，从而未执行生效，如图 条件断点从上面分析确认是因为条件注解 @ConditionalOnProperty(prefix = &quot;spring.datasource.druid&quot;, name = &quot;druidServletSettings&quot;) 未满足使方法未执行导致。那这个条件为什么没有满足呢，查看application.yml中也做了 spring.datasource.druid.druidServletSettings属性的配置。 当你无法理清头绪，确定问题原因时，那就Debug吧。查看注解@ConditionalOnProperty源码，找到其实现支持类OnPropertyCondition，如下123456789101112131415@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Documented@Conditional(&#123;OnPropertyCondition.class&#125;)public @interface ConditionalOnProperty &#123; String[] value() default &#123;&#125;; String prefix() default \"\"; String[] name() default &#123;&#125;; String havingValue() default \"\"; boolean matchIfMissing() default false;&#125; 查看OnPropertyCondition源码，了解它是通过getMatchOutcome方法来判断是否满足注解参数所指定的条件的，如下所示123456789101112131415161718@Overridepublic ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; List&lt;AnnotationAttributes&gt; allAnnotationAttributes = annotationAttributesFromMultiValueMap( metadata.getAllAnnotationAttributes( ConditionalOnProperty.class.getName())); List&lt;ConditionMessage&gt; noMatch = new ArrayList&lt;&gt;(); List&lt;ConditionMessage&gt; match = new ArrayList&lt;&gt;(); for (AnnotationAttributes annotationAttributes : allAnnotationAttributes) &#123; ConditionOutcome outcome = determineOutcome(annotationAttributes, context.getEnvironment()); (outcome.isMatch() ? match : noMatch).add(outcome.getConditionMessage()); &#125; if (!noMatch.isEmpty()) &#123; return ConditionOutcome.noMatch(ConditionMessage.of(noMatch)); &#125; return ConditionOutcome.match(ConditionMessage.of(match));&#125; 在调用determineOutcome处打断点，调试什么原因导致条件未满足，但是这里是一个for循环，如果for元素过多的话，将可能需要断点阻断很多次才能找到你想要查看的那个元素。所幸IDEA提供了不同类型的断点来处理这类问题，前面 案例解析：使用IDEA异常断点来定位java.lang.ArrayStoreException的问题 我们介绍了异常断点的使用。这里介绍用条件断点来处理这类循环块中的debug问题。 在上述代码for循环中调用determineOutcome行打断点，并在断点上右键，弹出如下窗口 图中Condition框即可输入你要指定的条件，可以直接写java判断表达式代码，并引用该行代码处能访问的变量，如这里我们输入 annotationAttributes.get(&quot;name&quot;).equals(&quot;druidServletSettings&quot;)，然后点击Debug窗口的“Resume Program (F9)”按钮，则在不满足指定条件时，断点处将不会被阻断，直到条件满足，这样就能很容易定位到我们想要查看的元素。（当然这里allAnnotationAttributes变量其实只有一个元素，仅仅是为了演示条件变量的使用，当集合元素很多时，使用条件断点就能体会到它的方便之处） 问题定位通过Debug的方式深入条件注解的判断逻辑（其中循环处可使用条件断点），最终来到如下代码片段 在这里是判断来自所有属性源配置的属性中，是否包含条件注解指定的属性，即spring.datasource.druid.druidServletSettings，由上图可见，spring.datasource.druid.druidServletSettings只是某些属性的前缀，并不存在完全匹配的属性，因此返回false，导致条件不满足。回看注解@ConditionOnProperty的javadoc，123456789* If the property is not contained in the &#123;@link Environment&#125; at all, the * &#123;@link #matchIfMissing()&#125; attribute is consulted. By default missing attributes do not * match. * &lt;p&gt; * This condition cannot be reliably used for matching collection properties. For example, * in the following configuration, the condition matches if &#123;@code spring.example.values&#125; * is present in the &#123;@link Environment&#125; but does not match if * &#123;@code spring.example.values[0]&#125; is present. * 当Environment中不包含该属性时，则看matchIfMissing的值，该值默认为false，如果包含该属性，则再对比属性值与havingValue的值，相等即满足，不等则不满足。并且该条件注解不能用于匹配集合类型属性。上述spring.datasource.druid.druidServletSettings实际上属于一个Map类型，因此不能想当然地认为该注解是只要属性集中某属性名称包含该值即满足。 总结当难以定位到问题原因时，可以进行Debug，跟踪程序运行的各个步骤，当要在循环中Debug定位到某个元素时，可以用条件断点来实现。@ConditionalOnProperty注解不是存在某属性就行，还需要值相等，并且不适用于集合类型属性。我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ——————————————————————————————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"案例解析","slug":"案例解析","permalink":"http://blog.jboost.cn/categories/案例解析/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"}]},{"title":"Spring Boot从入门到实战（七）：整合通用Mapper简化单表操作","slug":"springboot-tkmapper","date":"2019-06-24T11:32:15.000Z","updated":"2019-07-22T10:30:03.487Z","comments":true,"path":"springboot-tkmapper.html","link":"","permalink":"http://blog.jboost.cn/springboot-tkmapper.html","excerpt":"数据库访问是web应用必不可少的部分。现今最常用的数据库ORM框架有Hibernate与Mybatis，Hibernate貌似在传统IT企业用的较多，而Mybatis则在互联网企业应用较多。通用Mapper（https://github.com/abel533/Mapper） 是一个基于Mybatis，将单表的增删改查通过通用方法实现，来减少SQL编写的开源框架，且也有对应开源的mapper-spring-boot-starter提供。我们在此基础上加了一些定制化的内容，以便达到更大程度的复用。","text":"数据库访问是web应用必不可少的部分。现今最常用的数据库ORM框架有Hibernate与Mybatis，Hibernate貌似在传统IT企业用的较多，而Mybatis则在互联网企业应用较多。通用Mapper（https://github.com/abel533/Mapper） 是一个基于Mybatis，将单表的增删改查通过通用方法实现，来减少SQL编写的开源框架，且也有对应开源的mapper-spring-boot-starter提供。我们在此基础上加了一些定制化的内容，以便达到更大程度的复用。 框架源码地址：https://github.com/ronwxy/base-spring-boot （持续更新完善中，欢迎follow，star）Demo源码地址：https://github.com/ronwxy/springboot-demos/tree/master/springboot-tkmapper 在开源mapper-spring-boot-starter的基础上，增加了如下内容： 针对MySQL数据库与PostgreSQL数据库添加了一些Java类型与数据库类型的转换处理类，如将List、Map类型与MySQL数据库的json类型进行转换处理 对Domain、Mapper、Service、Controller各层进行了封装，将基本的增删改查功能在各层通用化 提供了基于druid连接池的自动配置 其它一些调整，如默认映射复杂类型属性（主要是List、Map类型，其它自定义类型需要自定义转换处理类），将枚举作为简单类型处理 提供了一个parent项目，将一些常用的框架进行集成，实际项目可继承parent简化依赖配置（持续更新完善） 该框架可用于实际基于springboot的项目，只需简单配置数据源，即可引入druid连接池及通用mapper的功能，以及各层基本的增删改查方法。 如何使用？下文给出使用步骤，可参考示例：https://github.com/ronwxy/springboot-demos/tree/master/springboot-tkmapper 1. 框架Maven部署安装下载框架源码后，在项目根路径下执行mvn clean install可安装到本地maven库。如果需要共享，且搭了Nexus私服，则在根路径pom.xml文件中添加distributionManagement配置，指定Nexus仓库分发地址，使用mvn clean deploy安装到远程maven仓库，如1234567891011121314&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;url&gt; http://ip:port/repository/maven-releases/ &lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;url&gt; http://ip:port/repository/maven-snapshots/ &lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; 上述指定的repository需要在maven的全部配置文件settings.xml中有对应账号配置(id需要一一对应)，如 123456789101112 &lt;servers&gt; &lt;server&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;xxx&lt;/password&gt; &lt;/server&gt;&lt;server&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;xxx&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; 2. pom.xml配置项目中引入该数据库框架有三种方式： 直接引入 cn.jboost.springboot:tkmapper-spring-boot-starter（没有连接池） 直接引入 cn.jboost.springboot:druid-spring-boot-starter（druid连接池支持） 项目继承 cn.jboost.springboot:spring-boot-parent（使用的是druid连接池） 三种方式的pom.xml配置如下 123456789101112131415161718192021#第一种方式&lt;dependency&gt; &lt;groupId&gt;cn.jboost.springboot&lt;/groupId&gt; &lt;artifactId&gt;tkmapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;#第二种方式&lt;dependency&gt; &lt;groupId&gt;cn.jboost.springboot&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;#第三种方式&lt;parent&gt; &lt;groupId&gt;cn.jboost.springboot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-parent&lt;/artifactId&gt; &lt;version&gt;1.2-SNAPSHOT&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt; 根据情况引入mysql或postgresql的驱动依赖（其它数据库暂未做类型转换支持，未作测试） 3. 配置数据源如果使用druid连接池，则在application.yml配置文件中，加入如下数据源配置（推荐）12345678910111213141516171819202122232425262728293031spring: datasource: druid: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/test?autoReconnect=true&amp;useUnicode=true&amp;characterEncoding=utf-8 username: root password: # 自定义配置 initialSize: 2 # 初始化大小 minIdle: 1 # 最小连接 maxActive: 5 # 最大连接 druidServletSettings: allow: 127.0.0.1 deny: loginUsername: admin loginPassword: Passw0rd resetEnable: true druidFilterSettings: exclusions: '*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*' maxWait: 60000 # 配置获取连接等待超时的时间 timeBetweenEvictionRunsMillis: 60000 # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 minEvictableIdleTimeMillis: 300000 # 配置一个连接在池中最小生存的时间，单位是毫秒 validationQuery: SELECT 'x' testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true # 打开PSCache，并且指定每个连接上PSCache的大小 maxPoolPreparedStatementPerConnectionSize: 20 filters: stat #,wall（添加wall代码里不能直接拼接sql，druid有sql注入校验） # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙 connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 # 通过connectProperties属性来打开mergeSql功能；慢SQL记录 useGlobalDataSourceStat: true # 合并多个DruidDataSource的监控数据 如果不使用连接池，则配置相对简单，如下123456spring: datasource: url: jdbc:mysql://localhost:3306/test?autoReconnect=true&amp;useUnicode=true&amp;characterEncoding=utf-8 username: root password: driver-class-name: com.mysql.jdbc.Driver 4. 定义相应domain，mapper，service，controller各层对象以demo为例（demo数据库脚本见resources/schema.sql），domain定义一个User类,12345678910111213141516@Table(name = \"user\")@Getter@Setter@ToStringpublic class User extends AutoIncrementKeyBaseDomain&lt;Integer&gt; &#123; private String name; @ColumnType(jdbcType = JdbcType.CHAR) private Gender gender; private List&lt;String&gt; favor; private Map&lt;String, String&gt; address; public enum Gender&#123; M, F &#125;&#125; 需要添加@Table注解指定数据库表名，可通过继承AutoIncrementKeyBaseDomain来实现自增主键，或UUIDKeyBaseDomain来实现UUID主键，如果自定义其它类型主键，则继承BaseDomain。 该框架Service层通用方法实现BaseService只支持单列主键，不支持组合主键（也不建议使用组合主键） 框架默认对List、Map等复杂类型属性会映射到mysql的json类型或postgresql的jsonb类型，如果某个属性不需要映射，可添加@Transient注解；枚举类型需添加@ColumnType指定jdbcType。 dao层定义UserMapper，123@Repositorypublic interface UserMapper extends BaseMapper&lt;User&gt; &#123;&#125; BaseMapper默认实现了单表的增删改查及批量插入等功能，如需定义复杂查询，可在该接口中定义，然后通过mapper xml文件编写实现。 service层定义 UserService，继承了BaseService的通用功能（具体可查看源码），同样可在该类中自定义方法12345678910@Servicepublic class UserService extends BaseService&lt;Integer, User&gt; &#123; @Transactional public void createWithTransaction(User user)&#123; create(user); //用于测试事务 throw new RuntimeException(\"抛出异常，让前面的数据库操作回滚\"); &#125;&#125; controller层定义 UserController，继承了BaseController的通用接口（具体可查看源码）1234@RestController@RequestMapping(\"/user\")public class UserController extends BaseController&lt;Integer, User&gt; &#123;&#125; 如上，只需要定义各层对应的接口或类，继承基础接口或类，便完成了用户基本的增删改查功能，不需要写一行具体的实现代码。 5. 测试、运行 示例中提供了两个新建用户的单元测试，参考SpringbootTkmapperApplicationTests类 运行，在主类上直接运行，然后浏览器里打开 http://localhost:8080/user 则可列出单元测试中创建的用户（其它接口参考BaseController实现） 6. 总结本文介绍框架基于tk.mybatis:mapper-spring-boot-starter做了一些自定义扩展，以更大程度地实现复用。可用于实际项目开发，使用过程中如果遇到问题，可关注公众号留言反馈。我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ———————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"案例解析：使用IDEA异常断点来定位java.lang.ArrayStoreException的问题","slug":"issue-errortrack","date":"2019-06-21T10:31:03.000Z","updated":"2019-07-09T11:19:28.656Z","comments":true,"path":"issue-errortrack.html","link":"","permalink":"http://blog.jboost.cn/issue-errortrack.html","excerpt":"最近对 base-spring-boot （https://github.com/ronwxy/base-spring-boot） 项目进行了升级。在将其用于应用开发中时遇到java.lang.ArrayStoreException的异常导致程序无法启动。平常开发过程中面对这种描述不够清楚，无法定位具体原因的问题该如何处理？本文分享通过使用IDEA异常断点来定位此类问题的方法。","text":"最近对 base-spring-boot （https://github.com/ronwxy/base-spring-boot） 项目进行了升级。在将其用于应用开发中时遇到java.lang.ArrayStoreException的异常导致程序无法启动。平常开发过程中面对这种描述不够清楚，无法定位具体原因的问题该如何处理？本文分享通过使用IDEA异常断点来定位此类问题的方法。 启动程序时抛出如下异常，导致启动失败 12345678910111213141516171819202122232425org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;devGlobalExceptionHandler&apos; defined in class path resource [cn/jboost/springboot/autoconfig/error/exception/ExceptionHandlerAutoConfiguration.class]: Post-processing of merged bean definition failed; nested exception is java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:570) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:843) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) ~[spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) [spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) [spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) [spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) [spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) [spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE] at com.cnbot.kindergarten.CnbotKindergartenApplication.main(CnbotKindergartenApplication.java:10) [classes/:na]Caused by: java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy at sun.reflect.annotation.AnnotationParser.parseClassArray(AnnotationParser.java:724) ~[na:1.8.0_201] at sun.reflect.annotation.AnnotationParser.parseArray(AnnotationParser.java:531) ~[na:1.8.0_201] at sun.reflect.annotation.AnnotationParser.parseMemberValue(AnnotationParser.java:355) ~[na:1.8.0_201] at sun.reflect.annotation.AnnotationParser.parseAnnotation2(AnnotationParser.java:286) ~[na:1.8.0_201] at sun.reflect.annotation.AnnotationParser.parseAnnotations2(AnnotationParser.java:120) ~[na:1.8.0_201] at sun.reflect.annotation.AnnotationParser.parseAnnotations(AnnotationParser.java:72) ~[na:1.8.0_201] ... 单纯看异常栈，无法定位问题原因，只能看到是在调用devGlobalExceptionHandler创建bean时出错，错误信息java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy。这属于框架内部抛出的异常，通常的设置断点Debug的方法很难定位到具体原因，可通过IDEA的异常断点来进行定位，它会在程序运行过程中出现指定异常时进行阻断。 1. 添加异常断点在IDEA的Debug面板中，点击“View Breakpoints”（两个重叠的红色圈按钮），如下 打开“Breakpoints”窗口，在该窗口中点击“+”按钮，选择“Java Exception Breakpoints”， 如下图 然后在弹出的“Enter Exception Class”窗口中输入ArrayStoreException选中对应异常，依次点击OK，Done按钮即完成异常断点添加。 2. 程序debug开始以Debug模式启动程序。 程序运行后，在前面配置的异常出现时，将会进行阻断，如图 可以看到程序阻断在上图高亮的那行代码处，异常便是从这里抛出的。查看parseClassValue方法，可看到这里有catchTypeNotPresentException异常，并且包装成我们在异常栈看到的TypeNotPresentExceptionProxy返回。离真相很近了。 我们可以在上述catch块中添加一个断点，查看异常包装前的状态，如图 重新Debug运行，将定位到上图代码处，查看异常，看到如下图所示信息 该信息表示org.springframework.security.access.AccessDeniedException这个类不存在，导致BaseWebApplicationExceptionHandler类型的bean实例化时出错。这时候问题基本已经定位到了。 查看源码，在BaseWebApplicationExceptionHandler中有对AccessDeniedException的统一处理，但是spring-boot-autoconfigure所有的依赖都是optional的（不会传递依赖），而在新开发的项目中，并没有引入spring-security，因此导致AccessDeniedException这个类找不到而报错。目前通过去掉该部分处理解决。 总结IDEA的Debug支持好几种断点类型，如前文介绍的异常断点，以及比较常用的条件断点等。当无法从异常栈信息找到问题所在时，借用这些类型的断点进行Debug，往往事情就变得简单了。 我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ———————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"案例解析","slug":"案例解析","permalink":"http://blog.jboost.cn/categories/案例解析/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"}]},{"title":"Spring Boot从入门到实战（六）：整合Web项目常用功能","slug":"springboot-base","date":"2019-06-20T14:17:22.000Z","updated":"2019-07-22T10:29:50.279Z","comments":true,"path":"springboot-base.html","link":"","permalink":"http://blog.jboost.cn/springboot-base.html","excerpt":"在Web应用开发过程中，一般都涵盖一些常用功能的实现，如数据库访问、异常处理、消息队列、缓存服务、OSS服务，以及接口日志配置，接口文档生成等。如果每个项目都来一套，则既费力又难以维护。可以通过Spring Boot的Starter来将这些常用功能进行整合与集中维护，以达到开箱即用的目的。","text":"在Web应用开发过程中，一般都涵盖一些常用功能的实现，如数据库访问、异常处理、消息队列、缓存服务、OSS服务，以及接口日志配置，接口文档生成等。如果每个项目都来一套，则既费力又难以维护。可以通过Spring Boot的Starter来将这些常用功能进行整合与集中维护，以达到开箱即用的目的。 项目基于Spring Boot 2.1.5.RELEASE 版。项目地址： https://github.com/ronwxy/base-spring-boot 整个项目分为如下几部分： spring-boot-autoconfigure： 具体的各功能实现，每个功能通过package的形式组织 spring-boot-commons： 一些公共的工具类或共享类 spring-boot-dependencies： 依赖的集中维护管理，集中管理各个依赖的版本号 spring-boot-parent： 提供一个基本的父项目，web服务项目可通过继承该项目创建 spring-boot-starters： 各功能的starter项目，引入相应starter即引入相应功能 spring-boot-dependencies 项目该项目主要是对所有依赖进行集中定义。通过 dependencyManagement 对依赖进行声明， 12345678910111213141516171819&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-boot.version&#125;&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.jboost.springboot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;base-spring-boot.version&#125;&lt;/version&gt; &lt;/dependency&gt; ... &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 这样，所有依赖的版本可以集中统一管理，在其它地方引用的时候可以省去版本的声明，如 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; spring-boot-autoconfigure 项目该项目是各功能自动配置的具体实现，以package的形式进行组织，如 tkmapper 包下实现了通用Mapper的自动配置，error 包下实现了错误处理的自动配置， 等等。 该项目继承了spring-boot-dependencies， 在项目的 pom.xml 中，依赖部分声明类似于 1234567891011121314&lt;dependencies&gt; &lt;!-- spring denpendencies --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; ...&lt;/dependencies&gt; 不需要再指定版本号，通过将optional设置为true，表示该依赖不会进行传递，即另外一个项目引用该项目时，optional的依赖不会被传递依赖过去。 在 resources/META-INF/spring.factories 文件中，声明了所有自动配置类， 如下 1234567891011org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\cn.jboost.springboot.autoconfig.tkmapper.MapperAutoConfiguration,\\cn.jboost.springboot.autoconfig.aoplog.AopLoggerAutoConfiguration,\\cn.jboost.springboot.autoconfig.alimq.config.AliMQAutoConfiguration,\\cn.jboost.springboot.autoconfig.qiniu.QiniuAutoConfiguration,\\cn.jboost.springboot.autoconfig.swagger.Swagger2AutoConfiguration,\\cn.jboost.springboot.autoconfig.druid.DruidAutoConfiguration,\\cn.jboost.springboot.autoconfig.error.exception.ExceptionHandlerAutoConfiguration,\\cn.jboost.springboot.autoconfig.alimns.MnsAutoConfiguration,\\cn.jboost.springboot.autoconfig.redis.RedisClientAutoConfiguration,\\cn.jboost.springboot.autoconfig.web.CORSAutoConfiguration spring-boot-starters 项目该项目包含按功能划分的多个子项目，主要用来引入依赖以达到自动配置的依赖条件，使引入对应starter时，能让自动配置生效。如通用Mapper集成的 tkmapper-spring-boot-starter 依赖如下 123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 同时在 resources/META-INF/spring.provides 里声明了该starter的用途，这里可随意编写。 spring-boot-commons 项目可将一些常用的工具类， 或共享类放到这个项目中。比如一些常量定义，加解密工具类等。 spring-boot-parent 项目该项目将Web应用需要的一些常见功能整合进来，应用项目可继承该项目进行构建，从而直接引入相应的功能。 在接下来的spring boot系列博文中，将一一详细介绍各功能的整合集成与应用。同时会不断更新与完善，以达到能直接用于生产项目的水平。 我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ——————————————————————————————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"研发团队如何借助Gitlab来做代码review","slug":"code-review","date":"2019-06-18T12:03:21.000Z","updated":"2019-07-09T11:19:28.710Z","comments":true,"path":"code-review.html","link":"","permalink":"http://blog.jboost.cn/code-review.html","excerpt":"代码review是代码质量保障的手段之一，同时开发成员之间代码review也是一种技术交流的方式，虽然会占用一些时间，但对团队而言，总体是个利大于弊的事情。如何借助现有工具在团队内部形成代码review的流程与规范，是team leader或技术管理者需要考虑的问题。本文分享一种基于Gitlab代码merge流程的code review方法，以供参考与探讨。如有更好的方法，欢迎交流。","text":"代码review是代码质量保障的手段之一，同时开发成员之间代码review也是一种技术交流的方式，虽然会占用一些时间，但对团队而言，总体是个利大于弊的事情。如何借助现有工具在团队内部形成代码review的流程与规范，是team leader或技术管理者需要考虑的问题。本文分享一种基于Gitlab代码merge流程的code review方法，以供参考与探讨。如有更好的方法，欢迎交流。 1. 设置成员角色首先需要对你团队的成员分配角色，在Gitlab groups里选择一个group，然后左边菜单栏点击 Members，可在 Members 页面添加或编辑成员角色，如下图所示。 其中角色包含如下几类： Guest：权限最小，基本查看功能 Reporter：只能查看，不能push Developer：能push，也能merge不受限制的分支 Master：除了项目的迁移、删除等管理权限没有，其它权限基本都有 Owner：权限最大，包括项目的迁移、删除等管理权限 详细权限参考： https://docs.gitlab.com/ee/user/permissions.html 确定团队中技术水平、经验较好的成员为Master，负责代码的review与分支的合并；其他成员为Developer，提交合并请求，接受review意见；Master之间可以互相review。 2. 配置分支保护在项目页面左侧菜单栏 Settings -&gt; Repository， 进入“Protected Branches”部分配置分支保护，如下图所示。 在这里可以针对每个分支，设置允许什么角色可以merge，允许什么角色可以push，选项包括三个：“Masters”， “Developers + Masters”， “No one”。这里设置成只允许master可以直接push与merge这几个常设分支的代码。（如果更严格一点，可以将“Allowed to push”设置成“No one”） 3. 代码review流程3.1. 开发（开发者负责） 本地切到develop分支， 拉取最新代码（相关命令如下，GUI工具操作自行查相关文档） 123git branch #查看当前位于哪个分支，前面打星号即为当前分支git checkout develop #切换到develop分支git pull #拉取最新代码 从develop分支切出子分支 1git checkout -b feature-1101 #从当前分支切出子分支，命名为\"feature-1101\" 编码、本地自测完之后，提交子分支到远程仓库 123git add * #加入暂存区git commit -m \"commit msg\" #提交到本地仓库git push origin feature-1101 #提交到远程仓库 3.2 发起Merge请求（开发者负责） 在项目主页面，依次点击左侧“Merge Requests”（下图1），“New merge request”（下图2），打开新建Merge请求页面 在新建Merge请求页面，选择merge的源分支，及目标分支，如下图源分支为“feature-1101”，目标分支为“develop”，点击“Compare branches and continue”按钮进入对比与提交页面 在对比与提交页面，可以点击“Changes” tab查看本次修改（这里我为了演示，只是加了两个换行），确认无误，点击“Submit merge request”按钮，提交merge请求 提交之后，将结果页面的浏览器地址发到团队即时通讯群（如钉钉），并@相应的同事申请review 3.3 代码Review（code reviewer负责） 负责代码Review的同事收到申请后，点击merge请求地址，打开页面，查看“Changes” 这里可通过“Inline”单边查看，也可以通过“Side-by-side”两个版本对比查看 review完成后，若无问题，则可点击”Merge”按钮完成merge，同时可删除对应的子分支“feature-1101”，若有问题，则可点击“Close merge request”按钮关闭该merge请求（也可以不关闭复用该merge请求），同时通知开发者进行相应调整，重新提交代码发起merge请求（如果之前没关闭merge请求，则刷新即可看到调整）。 3.4 冲突解决（开发者负责） merge的时候，可能存在代码冲突，这时，开发者可从develop分支重新拉取最新代码进行本地merge， 解决冲突后重新提交代码进行review 12345678git pull origin develop #在当前子分支拉取develop分支的最新代码进行本地merge# 解决冲突代码# 提交git add *git commit -m \"fix merge conflict\"git push origin feature-1101 自行解决不了时，寻求协助 4. 借助阿里钉钉机器人来改善体验前面流程中提醒code reviewer是需要开发者自己来发消息通知的，可不可以把这个流程自动化。我们可以借助Gitlab的webhook与钉钉机器人来实现。 在钉钉群右上角点击“…”，打开群设置，群机器人中点击添加机器人，会显示可以添加的机器人类型，如下图所示 选择Gitlab，点击添加，输入机器人名称，如“Gitlab”，点击完成即创建了一个Gitlab的钉钉机器人。回到“群机器人”窗口，将能看到刚刚创建的Gitlab机器人，如图 点击齿轮按钮，进入设置页，可看到webhook地址，点击复制，复制该机器人的webhook地址。如图 在Gitlab项目主页进入 Settings -&gt; Integrations， 将前面复制的webhook地址填入URL中，Trigger 部分选择“Merge request events”（不要勾太多，不然提醒太多就有点骚扰了），然后点击“Add webhook”就完成了。如图 当有开发人员提交merge请求时，钉钉机器人将在钉钉群里发出通知，code reviewer点击消息里的链接即可进入页面进行code review， review完成，将分支merge之后，钉钉机器人也会发出消息（所有merge相关的事件都会发出消息）。如图 5. 总结团队协作，流程、规范很重要，不同的团队可能有不同的适用流程与规范。此文分享了基于Gitlab与阿里钉钉群机器人的代码review流程，希望对团队研发协作有一定参考价值，也欢迎一起探讨、交流。 我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ———————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"teamwork","slug":"teamwork","permalink":"http://blog.jboost.cn/categories/teamwork/"}],"tags":[{"name":"git","slug":"git","permalink":"http://blog.jboost.cn/tags/git/"}]},{"title":"团队项目的Git分支如何管理","slug":"git-branch","date":"2019-06-17T05:28:19.000Z","updated":"2019-07-09T11:19:28.488Z","comments":true,"path":"git-branch.html","link":"","permalink":"http://blog.jboost.cn/git-branch.html","excerpt":"许多公司的开发团队都采用Git来做代码版本控制。如何有效地协同开发人员之间，以及开发、测试、上线各环节的工作，可能都有各自的流程与规范。本文分享的是作者一直沿用的团队项目Git分支管理规范，希望给有缘阅读的人以参考，如果有更好的实践，也欢迎指教、讨论。","text":"许多公司的开发团队都采用Git来做代码版本控制。如何有效地协同开发人员之间，以及开发、测试、上线各环节的工作，可能都有各自的流程与规范。本文分享的是作者一直沿用的团队项目Git分支管理规范，希望给有缘阅读的人以参考，如果有更好的实践，也欢迎指教、讨论。 分支管理创建项目时（一般是服务型项目，工具型或辅助型项目可以简单一些），会针对不同环境创建三个常设分支： develop：开发环境的稳定分支，公共开发环境基于该分支构建。 pre-release：测试环境的稳定分支，测试环境基于该分支构建。 master：生产环境的稳定分支，生产环境基于该分支构建。仅用来发布新版本，除了从pre-release或生产环境Bug修复分支进行merge，不接受任何其它修改 平时开发工作中，会根据需要由开发人员创建两类临时分支： 功能（feature）分支：为了开发某个特定功能，从develop分支上面分出来的。开发完成后，要merge到develop分支。功能分支的命名，可以采用feature-*的形式命名(*为任务单号) Bug修复（fixbug）分支：为了修复某个bug，从常设分支上面分出来的。修复完成后，再merge到对应的分支。Bug修复分支的命名，可以采用fixbug-*的形式命名（*为bug单号） 流程规范正常开发流程 从develop分支切出一个新分支，根据是功能还是bug，命名为feature-* 或 fixbug-*。 开发者完成开发，提交分支到远程仓库。 开发者发起merge请求（可在gitlab页面“New merge request”），将新分支请求merge到develop分支，并提醒code reviewer进行review code reviewer对代码review之后，若无问题，则接受merge请求，新分支merge到develop分支，同时可删除新建分支；若有问题，则不能进行merge，可close该请求，同时通知开发者在新分支上进行相应调整。调整完后提交代码重复review流程。 转测时，直接从当前develop分支merge到pre-release分支，重新构建测试环境完成转测。 测试完成后，从pre-release分支merge到master分支，基于master分支构建生产环境完成上线。并对master分支打tag，tag名可为v1.0.0_2019032115（即版本号_上线时间） 流程示意图如下所示 并行开发测试环境Bug修复流程并行开发（即前一个版本已经转测但未上线，后一个版本又已在开发中并部分合并到了develop分支）过程中，转测后测试环境发现的bug需要修复，但是develop分支此时又有新内容且该部分内容目前不计划转测，可以pre-release切出一个bug修复分支。完成之后需要同时merge到pre-release分支与develop分支。merge时参考“正常开发流程”。流程示意图如下 生产环境Bug修复流程生产环境的Bug分两种情况： 紧急Bug：严重影响用户使用的为紧急Bug，需立即进行修复。如关键业务流程存在问题，影响用户正常的业务行为。 非紧急Bug或优化：非关键业务流程问题，仅影响用户使用体验，或出现频率较小等，为非紧急Bug，可规划到后续版本进行修复。 非紧急Bug修复参考“正常开发流程”。 紧急Bug修复，需要从master分支切出一个bug修复分支，完成之后需要同时merge到master分支与develop分支（如果需要测试介入验证，则可先merge到pre-release分支，验证通过后再merge到master分支上线）。merge时参考“正常开发流程”。流程示意图如下 我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ———————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"teamwork","slug":"teamwork","permalink":"http://blog.jboost.cn/categories/teamwork/"}],"tags":[{"name":"git","slug":"git","permalink":"http://blog.jboost.cn/tags/git/"}]},{"title":"命令行高效操作Git，看这篇就够了","slug":"use-git","date":"2019-06-16T06:30:07.000Z","updated":"2019-07-09T11:19:28.676Z","comments":true,"path":"use-git.html","link":"","permalink":"http://blog.jboost.cn/use-git.html","excerpt":"对于软件开发人员来说，git几乎是每天都需要接触的工具。但对于相处如此亲密的工作伙伴，你对它的了解又有多少，是不是还在傻瓜式地打开一个GUI工具，点击提交按钮，然后“卧槽，又冲突了”，一脸懵逼到不知所措，责怪谁又在你前面提交了，谁又改了你的代码。","text":"对于软件开发人员来说，git几乎是每天都需要接触的工具。但对于相处如此亲密的工作伙伴，你对它的了解又有多少，是不是还在傻瓜式地打开一个GUI工具，点击提交按钮，然后“卧槽，又冲突了”，一脸懵逼到不知所措，责怪谁又在你前面提交了，谁又改了你的代码。 博主从一开始接触git，就没用过任何GUI工具，都是通过命令行进行操作，发现这种方式不仅对git的理解更深，效率也更高，遇到问题时一般都知道如何来处理，故做此分享。本文所有知识与操作只涉及日常使用场景，更多详细内容可自行查阅其它资料。本文Git版本为 windows-2.20.1版。 基础理论git的理论知识，对使用者来说只需要知道它是分布式版本控制系统，了解如下三个概念即可， 工作区：就是你直接操作的文件目录与内容 暂存区：暂时为你保存还没将内容提交到版本库的一个区域，对应.git目录下的stage或index文件 版本库：分本地版本库与远程版本库，本地版本库就理解为对应.git目录即可，远程版本库就是远程仓库，如gitlab或github的repository。 如下图，我们平时提交代码的过程基本都是从工作区add到暂存区，然后再commit到本地仓库，最后push到远程仓库。 基本命令对于日常工作，掌握如下几个基本命令一般就够了 git status 查看修改状态 git pull origin master 拉取远程仓库master分支合并到本地，master根据场景换成其它分支名 git add file 添加文件到暂存区，可用 * 添加所有 git commit -m &quot;commit message&quot; 提交到本地版本库，并添加注释，注释表明此次修改内容，要清晰准确 git push origin master 将本地版本提交到远程仓库的master分支，master根据场景换成其它分支名 对大部分日常工作来说， 上面几个命令基本就够用了。 新建项目1. 从本地到远程 项目开发的时候，有时候是先在本地建一个项目，再提交到远程仓库的。 创建项目目录（或通过IDE创建），命令行cd到项目目录 执行git init ， 将在项目目录创建.git目录 执行git add * ，将所有文件添加到暂存区，这里要先创建一个.gitignore文件，将不需要版本维护的文件添加进去忽略，不然各种IDE编译文件夹，环境相关文件都加到版本库去了。删除文件用git rm file_name 执行git commit -m &quot;upload project&quot; ，提交到本地仓库 在gitlab或github上创建一个仓库，并将仓库地址复制下来 执行git remote add origin git@server-name:path/repo-name.git ，关联远程仓库，仓库地址如果是http开头则要用户名密码，如果是git开头，则是走的ssh协议，需要将你本机的ssh公钥添加到远程仓库服务上。 执行git push -u origin master ，推送本地仓库内容到远程仓库 这样在远程仓库目录，就能看到你提交上去的文件内容了。 2. 从远程到本地更多的时候，是远程仓库已有项目了，需要下载到本地开发。 git clone git@server-name:path/repo-name.git ， 将远程仓库的内容下载到本地，这里仓库地址的处理同上 修改内容 git add * ，将修改的内容添加到暂存区 git commit -m &quot;fix xxx issue&quot; ，提交到本地仓库 git push -u origin master ， 推送本地仓库内容至远程仓库 版本回退有时候改了文件，想反悔怎么办，git给你“后悔药”。 单个文件的还原： git checkout file_name ，丢弃工作区的修改，还原到上次提交（commit）的版本， git reset HEAD file_name ，把暂存区的修改撤销掉（unstage），重新放回工作区。即还原到上次添加到暂存区（add）的版本 这里涉及几个场景 场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout file_name。 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时（执行了add，但没执行commit），想丢弃修改，分两步，第一步用命令git reset HEAD file_name，就回到了场景1，第二步按场景1操作。 场景3：已经提交了不合适的修改到版本库时，想要撤销本次的全部提交，参考下面的整个版本的还原，不过前提是没有推送到远程库。 整个版本的还原： git reset --hard HEAD^^， 回退到上上个版本 git reset --hard 3628164， 回退到具体某个版本 3628164 是具体某个commit_id缩写 找不到commit_id？ git reflog 可查看每一个命令的历史记录，获取对应操作的commit_id。git log [--pretty=oneline]， 可查看commit记录 上一个版本就是HEAD^，上上一个版本就是HEAD^^，往上100个版本写成HEAD~100。3628164 是具体某个commit_id，不需要写全，只需要唯一确定就行，可往前进也可往后退。（git windows2.20.1版貌似不支持对HEAD^的操作） 多人协作 首先，可以试图用 git push origin branch_name 推送自己的修改； 如果推送失败，则因为远程分支比你的本地更新，需要先用 git pull 试图合并； 如果合并有冲突，则手动解决冲突，并在本地提交； 没有冲突或者解决掉冲突后，再用 git push origin branch-name 推送就能成功！ 如果git pull提示“no tracking information”，则说明本地分支和远程分支的链接关系没有创建，用命令git branch –set-upstream branch-name origin/branch-name 在本地创建和远程分支对应的分支，使用git checkout -b branch-name origin/branch-name，本地和远程分支的名称最好一致 分支管理平时开发时需要创建子分支来实现你的功能模块，然后再合并到主分支中。 git checkout -b your_branch_name ， 创建并切换分支 git branch ， 查看分支，标有*号表示当前所在分支 git merge dev ， 合并指定dev分支到当前分支 git merge --no-ff -m &quot;merge with no-ff&quot; dev ， 合并分支并生成commit记录 git branch -d dev ， 删除分支 git checkout -b dev = git branch dev + git checkout dev Fast-forward合并，“快进模式”，也就是直接把master指向dev的当前提交，所以合并速度非常快。存在冲突的不能fast forward。git merge --no-ff -m &quot;merge with no-ff&quot; dev Fast forward模式下，删除分支后，会丢掉分支信息。如果强制禁用Fast forward模式，Git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息 标签管理当发布版本时，一般需要对当前版本进行标签记录，以便后续进行版本查看或回退。 git tag tag_name ， 对当前分支打标签 git tag ， 查看所有标签 git tag v0.9 6224937 ，针对某个具体commit id打标签 git show tag_name ， 查看标签信息 git tag -a v0.1 -m &quot;version 0.1 released&quot; 3628164 ， 带有说明的标签 git tag -d v0.1 ， 删除标签 git push origin tag_name ， 推送标签到远程 git push origin --tags ， 一次性推送所有标签 删除已经推送到远程的标签： git tag -d v0.9 ， 先本地删除 git push origin :refs/tags/v0.9 ， 然后从远程删除 提高效率的Tips 配置命令别名 123git config --global alias.st status # 后面可以用git st 来代替git status了git config --global alias.ck checkout # 后面可以用 git ck 来代替 git checkout了git config --global alias.cm 'commit -m' # 后面可以用git cm 来代替 git commit -m 了 git pull origin master 或 git push origin master， 可直接 git pull 或 git push， 如果出现“no tracking information”的提示，则说明本地分支和远程分支的链接关系没有创建，用命令 git branch --set-upstream-to=origin/master master 建立关联即可。 总结以上命令虽然看起来多，但平常用的最频繁的应该是“基本命令”与“分支管理”部分，只要多用几次，自然便能记住，应付日常工作完全没有问题，彻底脱离GUI操作，让工作更有效率。 我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ———————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"高效实践","slug":"高效实践","permalink":"http://blog.jboost.cn/categories/高效实践/"}],"tags":[{"name":"git","slug":"git","permalink":"http://blog.jboost.cn/tags/git/"}]},{"title":"案例解析：线程池使用不当导致系统崩溃","slug":"issue-threadpool","date":"2019-06-15T03:01:58.000Z","updated":"2019-07-09T11:19:28.488Z","comments":true,"path":"issue-threadpool.html","link":"","permalink":"http://blog.jboost.cn/issue-threadpool.html","excerpt":"前几天，发现一台阿里云服务器上的Web服务不可用。远程SSH登录不上，尝试几次登录上去之后，执行命令都显示1-bash: fork: Cannot allocate memory 一看以为是内存泄漏导致溢出。因为执行不了任何命令， 只能通过控制台重启服务器恢复服务。","text":"前几天，发现一台阿里云服务器上的Web服务不可用。远程SSH登录不上，尝试几次登录上去之后，执行命令都显示1-bash: fork: Cannot allocate memory 一看以为是内存泄漏导致溢出。因为执行不了任何命令， 只能通过控制台重启服务器恢复服务。 初步排查服务恢复后，查看系统日志，linux系统日志路径/var/log/messages，可通过journalctl命令查看，如12journalctl --since=\"2019-06-12 06:00:00\" --until=\"2019-06-12 10:00:00\"` 可查看since之后，until之前时间段的日志。除了发现crond[14954]: (CRON) CAN&#39;T FORK (do_command): Cannot allocate memory 这个错误日志，未见其它异常（下面的sshd[10764]: error: fork: Cannot allocate memory应是ssh登录执行命名失败的日志） 通过阿里云-云监控-主机监控查看内存使用率指标，这段时间内，内存使用率一直在40%以下，基本可排除内存溢出的可能。 通过搜索查阅到进程数超过操作系统限制可能导致bash: fork: Cannot allocate memory的报错(参考： https://blog.csdn.net/wangshuminjava/article/details/80603847 ）。通过ps -eLf|wc -l查看当前进程线程数(ps -ef只打印进程，ps -eLf会打印所有的线程), 只有1000多个，故障时刻系统到底运行了多少线程已无从得知，只能持续跟进监测。 问题定位几天后，再次通过ps -eLf|wc -l查看，发现线程数已达16000多个。直接执行ps -eLf可看到大量tomcat进程所产生的线程，猜测是不是线程死锁导致大量线程未完成一直hung在那里。 执行 jstack 进程号 &gt; ~/jstack.txt 命令将进程所运行线程情况打印出来分析，发现大量的WAITING状态的线程，如下1234567891011\"pool-19-thread-1\" #254 prio=5 os_prio=0 tid=0x00007f0b700a6000 nid=0x29a9 waiting on condition [0x00007f0b274df000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000006ce3d8790&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) 根据上述内容可看出线程在等一个条件，并且是在执行LinkedBlockingQueue.take方法的时候，查看该方法的java doc，当队列为空时，该方法将会一直等待直到有元素可用。12345678/** * Retrieves and removes the head of this queue, waiting if necessary * until an element becomes available. * * @return the head of this queue * @throws InterruptedException if interrupted while waiting */E take() throws InterruptedException; 询问同事在哪里用到了LinkedBlockingQueue，同事回忆起不久前用线程池实现往阿里云OSS服务通过追加的方式上传文件功能，查看代码后发现问题——线程池没有关闭。为了使文件片段保存不存在错乱，每次保存文件时，都new了一个线程池对象，1ThreadPoolExecutor saveImgThreadPool = new ThreadPoolExecutor(1, 1, 0, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;()); 但处理完后， 没有关闭这个线程池对象，这样线程池仍会通过take方法去取等待队列中是否还有未完成的线程任务，等待队列为空时将会一直等待，这样就导致大量的线程hung在这里了（基本是只要方法被调一次，就会产生一个hung住的线程）。 延伸 线程状态为“waiting for monitor entry”：意味着它 在等待进入一个临界区 ，所以它在”Entry Set“队列中等待。此时线程状态一般都是 Blocked：java.lang.Thread.State: BLOCKED (on object monitor) 线程状态为“waiting on condition”：说明它在等待另一个条件的发生，来把自己唤醒，或者干脆它是调用了 sleep(N)。此时线程状态大致为以下几种：java.lang.Thread.State: WAITING (parking)：一直等那个条件发生（本文案例即为此种场景）；java.lang.Thread.State: TIMED_WAITING (parking或sleeping)：定时的，那个条件不到来，也将定时唤醒自己。 如果大量线程在“waiting for monitor entry”：可能是一个全局锁阻塞住了大量线程。如果短时间内打印的thread dump 文件反映，随着时间流逝，waiting for monitor entry 的线程越来越多，没有减少的趋势，可能意味着某些线程在临界区里呆的时间太长了，以至于越来越多新线程迟迟无法进入临界区。 如果大量线程在“waiting on condition”：可能是它们又跑去获取第三方资源，尤其是第三方网络资源，迟迟获取不到Response，导致大量线程进入等待状态。所以如果你发现有大量的线程都处在 Wait on condition，从线程堆栈看，正等待网络读写，这可能是一个网络瓶颈的征兆，因为网络阻塞导致线程无法执行。也可能是如本文所提到的，由于程序编写不当所致。 参考： https://www.cnblogs.com/rainy-shurun/p/5732341.html 我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy —————————————————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"案例解析","slug":"案例解析","permalink":"http://blog.jboost.cn/categories/案例解析/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"}]},{"title":"Spring Boot从入门到实战（五）：写一个自己的starter","slug":"springboot-starter","date":"2019-06-14T07:19:43.000Z","updated":"2019-07-24T01:52:22.312Z","comments":true,"path":"springboot-starter.html","link":"","permalink":"http://blog.jboost.cn/springboot-starter.html","excerpt":"曾遇到几位面试者，简历上写着精通Spring Boot，当聊到自动配置及对starter的理解时，却说不出个所以然来。找工作时，简历一定要注重实际，精通这种字眼还是少用，不然面试官对你期望越高，失望也就越大。其实结合前一篇介绍的Spring Boot自动配置，对Spring Boot的Starter实现将很容易理解，不论是使用其官方提供的Starter，还是自定义自己的Starter，都变得很容易。","text":"曾遇到几位面试者，简历上写着精通Spring Boot，当聊到自动配置及对starter的理解时，却说不出个所以然来。找工作时，简历一定要注重实际，精通这种字眼还是少用，不然面试官对你期望越高，失望也就越大。其实结合前一篇介绍的Spring Boot自动配置，对Spring Boot的Starter实现将很容易理解，不论是使用其官方提供的Starter，还是自定义自己的Starter，都变得很容易。 根据前面介绍，Spring Boot自动配置的实现，主要由如下几部分完成： @EnableAutoConfiguration注解 SpringApplication类 spring-boot-autoconfigure jar包 spring.factories文件 项目结构官方提供的starter，大多包含两个jar包： 一个starter——没有任何实现，只用来管理依赖（即实现这个starter的功能需要依赖哪些jar），一个autoconfigure——包含所有具体实现，包括自动配置类，及META-INF/spring.factories文件。本文示例的自定义starter，为了方便，将两者合并写到了一个。 但是在实际项目中，还是建议像官方一样，定义一个spring-boot-dependencies声明所有依赖及其版本，做统一依赖版本管理，一个spring-boot-autoconfigure，实现所有自动配置类及相应的Bean，一个spring-boot-starters，针对每个模块引入必须的jar依赖，方便项目中引入。 官方提供的starter，命名遵循spring-boot-starter-xxx， 自定义starter，命名遵循xxx-spring-boot-starter。 示例的项目结构如下图 springboot-starter这里为了简单，将starter与autoconfigure整到一个项目，命名也为了与前面demo项目保持一致，没按规范来。 配置类 MyAutoConfig12345678910111213@Configuration@EnableConfigurationProperties(MyProperties.class)public class MyAutoConfig &#123; @Autowired private MyProperties myProperties; @Bean @ConditionalOnProperty(prefix = \"my\", name = \"disable\", havingValue = \"false\") public MyService myService()&#123; return new MyService(\"Hi \" + myProperties.getName() + \", welcome to visit \" + myProperties.getWebsite()); &#125;&#125; 该类中通过@EnableConfigurationProperties及@Autowired 引入了配置属性Bean MyProperties 以访问用户配置的属性，@Bean注解即向容器中注入方法返回值类型的Bean，这样在容器其它bean中通过@Autowired即可引用访问， @ConditionalOnProperty是条件注解，这里表明当配置属性my.disable=false时才实例化这个MyService bean。 配置属性类 MyProperties1234567@ConfigurationProperties(prefix = \"my\")public class MyProperties &#123; private String name; private String website; getter/setter;&#125; 配置属性类封装了用户在配置文件中定义的属性，该示例中将前缀为my的属性封装起来，访问name，website对应配置属性key就是my.name，my.website。 服务Bean MyService1234567891011public class MyService &#123; private String hiStr; public MyService(String hiStr)&#123; this.hiStr = hiStr; &#125; public String sayHi()&#123; return this.hiStr; &#125;&#125; 提供服务功能的bean，也即需要实例化注入到Spring上下文的bean。 spring.factories12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ cn.jboost.springboot.starter.MyAutoConfig 指定了自动配置类（带包名的全路径类名） springboot-usingstarter该项目引用springboot-starter，调用MyService服务的项目，主类没什么特别的1234567@SpringBootApplicationpublic class SpringbootUsingstarterApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootUsingstarterApplication.class, args); &#125;&#125; 配置文件application.properties123my.disable=falsemy.name=jboostmy.website=blog.jboost.cn 在测试类SpringbootUsingstarterApplicationTests中编写测试1234567@Autowiredprivate MyService myService;@Testpublic void testStarter()&#123; System.out.printf(myService.sayHi());&#125; pom.xml中引入springboot-starter依赖12345678910111213 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;cn.jboost.springboot&lt;/groupId&gt; &lt;artifactId&gt;springboot-starter&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 运行，控制台会打印出 Hi jboost, welcome to visit blog.jboost.cn将配置属性my.disable的值改为true或其它非false的值再运行测试代码试试，会报MyService bean找不到的错误，说明@ConditionalOnProperty注解生效了 本示例仅作实现自定义starter演示用，项目结构、命名都不够规范，仅供参考，项目实战starter在后面继续分享。 本文示例项目源码地址：https://github.com/ronwxy/springboot-demos/tree/master/springboot-starterhttps://github.com/ronwxy/springboot-demos/tree/master/springboot-usingstarter我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy —————————————————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"Spring Boot从入门到实战（四）：Spring Boot配置","slug":"springboot-config","date":"2019-06-11T07:46:02.000Z","updated":"2019-07-22T10:28:12.660Z","comments":true,"path":"springboot-config.html","link":"","permalink":"http://blog.jboost.cn/springboot-config.html","excerpt":"Spring Boot之所以受开发者欢迎， 其中最重要的一个因素就是其配置简单。传统的Spring应用需要手动配置各种.xml文件，为数据库访问，事务支持，缓存功能等提供各项繁杂且重复的配置。Spring Boot将这种繁杂且重复的工作通过预定义的启动器（starter）来实现，只要引入即可拥有相应的功能支持，从而将开发者从复杂的配置工作中解放出来，能够更专注于业务逻辑的开发。","text":"Spring Boot之所以受开发者欢迎， 其中最重要的一个因素就是其配置简单。传统的Spring应用需要手动配置各种.xml文件，为数据库访问，事务支持，缓存功能等提供各项繁杂且重复的配置。Spring Boot将这种繁杂且重复的工作通过预定义的启动器（starter）来实现，只要引入即可拥有相应的功能支持，从而将开发者从复杂的配置工作中解放出来，能够更专注于业务逻辑的开发。 配置方式在Spring Boot中，虽然仍然可以通过之前的.xml文件方式来进行配置，但最好还是通过基于java的配置来进行配置管理。在Spring Boot中，基于java的配置是通过注解@Configuration来实现的12345678@Configurationpublic class MyConfig &#123; @Bean public MyService myService()&#123; return new MyService(); &#125;&#125; 上述代码将一个MyService的Bean注入了容器，这样在其它地方就可以直接通过@Autowired来引用访问。与.xml文件中通过&lt;bean&gt;&lt;/bean&gt;实例化的效果是一样的。1234567@Autowiredprivate MyService myService;@RequestMapping(\"/hi\")public String sayHello(@RequestParam String name)&#123; return myService.sayHello(name);&#125; 实际项目开发中，有可能存在一些基于xml配置的旧服务，比如以jar包的形式发布，如果要复用该怎么引入呢？很简单，在@Configuration注解标注的类上，加入@ImportResource注解引用相应的xml文件即可，123456789@Configuration@ImportResource(\"spring.xml\")public class MyConfig &#123; @Bean public MyService myService()&#123; return new MyService(); &#125;&#125; 这样类路径下spring.xml配置文件中声明的内容都将生效。在一个应用中，可以定义多个@Configuration配置类，这些配置类可以被@ComponentScan自动扫描并注入容器。 如果应用中没有通过@ComponentScan进行自动扫描，则可在主配置类（一般为入口类）上通过@Import({MyConfig.class})的方式类引入其它配置类 自动配置个人认为，自动配置是Spring Boot非常基础但又核心的部分。曾经遇到几个面试者，简历写着精通Spring Boot，当问及自动配置时却支支吾吾不知所云。其实理解Spring Boot的自动配置也不难，基本了解如下几部分差不多就够了： @EnableAutoConfiguration注解 SpringApplication类 spring-boot-autoconfigure jar包 spring.factories文件 @EnableAutoConfiguration注解这个注解的作用是告诉Spring Boot基于添加的jar依赖来自动配置Spring，比如添加了spring-boot-starter-web依赖，则Spring Boot认为你在开发一个web应用，就会自动做好web相应配置。这个注解一般放在主类上。在前面的示例项目中， 我们在主类上都是使用@SpringBootApplication， 查看源码可以知道： @SpringBootApplication 这个注解实际上等效于 @SpringBootConfiguration（等效于@Configuration）， @EnableAutoConfiguration，启用自动配置 @ComponentScan 自动扫描@Component, @Service, @Controller等注解标注的各类组件 三者的组合。如果去掉@EnableAutoConfiguration注解，则Spring Boot将不会自动配置Spring（如实例化必要的Bean），将可能导致应用启动失败。 SpringApplication类在应用主类中，我们是通过SpringApplication的run方法来启动应用的，如：1234567@SpringBootApplicationpublic class SpringbootConfigApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootConfigApplication.class, args); &#125;&#125; 查看源码，SpringApplication的静态run方法，实际也是通过创建SpringApplication实例，调用实例方法执行，在SpringApplication构造器方法中，调用了getSpringFactoriesInstances 方法，12345678910public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources&#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, \"PrimarySources must not be null\"); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath(); setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass();&#125; 追溯下去，最终会调用到SpringFactoriesLoader的loadSpringFactories方法，123456789101112131415161718192021222324252627private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(@Nullable ClassLoader classLoader) &#123; ... try &#123; Enumeration&lt;URL&gt; urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) : ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION)); result = new LinkedMultiValueMap&lt;&gt;(); while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); Properties properties = PropertiesLoaderUtils.loadProperties(resource); for (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) &#123; String factoryClassName = ((String) entry.getKey()).trim(); for (String factoryName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) &#123; result.add(factoryClassName, factoryName.trim()); &#125; &#125; &#125; cache.put(classLoader, result); return result; &#125; catch (IOException ex) &#123; throw new IllegalArgumentException(\"Unable to load factories from location [\" + FACTORIES_RESOURCE_LOCATION + \"]\", ex); &#125;&#125; 在该方法中，会从所有的META-INF目录下加载spring.factories文件里配置的各类型的类名称（包括初始化器，监听器，自动配置类等）。然后上层方法中通过反射机制实例化这些初始化器、监听器，自动配置等，从而完成相应Bean的自动化配置与注入。 spring-boot-autoconfigure 官方提供的starter，如spring-boot-starter-web， 都依赖了spring-boot-starter， 而spring-boot-starter又依赖了spring-boot-autoconfigure。 在spring-boot-autoconfigure中提供了大量官方提供的自动配置类，并且包含META-INF/spring.factories文件，如下图 spring.factories 由上图可看出，spring.factories包含了 org.springframework.context.ApplicationContextInitializer 应用初始化器 org.springframework.context.ApplicationListener 应用监听器 org.springframework.boot.autoconfigure.AutoConfigurationImportListener 自动配置引入监听器 org.springframework.boot.autoconfigure.AutoConfigurationImportFilter 自动配置引入过滤器 org.springframework.boot.autoconfigure.EnableAutoConfiguration 自动配置类 org.springframework.boot.diagnostics.FailureAnalyzer 失败分析器 org.springframework.boot.autoconfigure.template.TemplateAvailabilityProvider 模板提供者 其中org.springframework.boot.autoconfigure.EnableAutoConfiguration即实现自动配置的@Configuration配置类列表。 Spring Boot就是通过这种自动配置机制，以starter依赖包的方式，使开发者非常方便地使用项目开发中的许多常用功能，如数据库访问、缓存、队列等。同时，用户也可以根据自身需求，自定义自己的starter（后面介绍）。 通过注解控制自动配置Spring Boot自动配置包含了许多条件类注解及顺序类注解，这些注解可方便地让自动配置按照某种条件或者顺序进行配置。 其中条件类注解包括： 类级别条件注解 @ConditionalOnClass： 类路径中存在指定的类才进行该配置；@ConditionalOnMissingClass： 类路径中不存在指定的类才进行该配置 实例级别条件注解 @ConditionalOnBean：只有在当前上下文中存在指定Bean时，才进行该配置@ConditionalOnMissingBean： 只有在当前上下文不存在指定Bean时，才进行该配置 属性级别条件注解 @ConditionalOnProperty：当存在某个指定属性，且值为指定值时，才进行该配置 资源级别条件注解 @ConditionalOnResource：在类路径下存在指定的Resource时，才进行配置 Web应用条件注解 @ConditionalOnWebApplication：该应用为Web应用时进行该配置@ConditionalOnNotWebApplication： 该应用不为Web应用时进行该配置 SpEL（ Spring Expression Language）表达式注解 @ConditionalOnExpression： 计算SpEL表达式值，值为true时才进行该配置 顺序类注解包括： @AutoConfigureAfter： 在指定的配置类初始化后再加载 @AutoConfigureBefore： 在指定的配置类初始化前加载 @AutoConfigureOrder： 数值越小越先初始化 注意：自动配置类不应该位于组件扫描路径（@ComponentScan注解指定的扫描路径）下，否则上述条件注解与顺序注解可能不会生效。建议只在自动配置的类上注解@ConditionalOnBean， @ConditionalOnMissingBean，因为这可以保证在用户定义bean已经添加到ApplicationContext之后才会加载。这两个注解放在class上，则相当于class里面每一个@Bean标注的方法都加上了。 自动配置是非侵入式的，你可以在任何地方自定义配置来覆盖自动配置中的某些内容，比如你在应用中通过@Configuration类注入一个自定义的DataSource，默认的基于内存的DataSource将被覆盖 禁用某个自动配置类有时候引入的自动配置可能包含我们不想让其生效的配置类，这时候可以通过@EnableAutoConfiguration注解的属性进行排除，使其不生效。1@EnableAutoConfiguration(exclude = &#123;XXAutoConfiguration.class&#125;) 其中XXAutoConfiguration为某个自动配置类，如果该类不在应用的类路径中，则可以通过属性excludeName指定完整类路径来排除。@SpringBootApplicationz注解同样支持1@SpringBootApplication(exclude = &#123;XXAutoConfiguration.class&#125;) 本文示例项目源码地址：https://github.com/ronwxy/springboot-demos/tree/master/springboot-config我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy —————————————————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"Spring Boot从入门到实战（三）：Spring Boot自定义属性","slug":"springboot-properties","date":"2019-06-10T10:47:51.000Z","updated":"2020-01-13T11:34:42.896Z","comments":true,"path":"springboot-properties.html","link":"","permalink":"http://blog.jboost.cn/springboot-properties.html","excerpt":"Web项目开发中，经常需要自定义一些属性，如数据库连接，第三方服务接口地址，第三方服务的appKey、appSecret等，以及针对不同环境，这些属性的值还需要有相应的调整，如开发环境、测试环境、生产环境所用数据库不同，则针对不同环境的同一属性需要配置不同的值。","text":"Web项目开发中，经常需要自定义一些属性，如数据库连接，第三方服务接口地址，第三方服务的appKey、appSecret等，以及针对不同环境，这些属性的值还需要有相应的调整，如开发环境、测试环境、生产环境所用数据库不同，则针对不同环境的同一属性需要配置不同的值。 传统自定义属性配置及访问（参考Github示例测试类）在传统的Spring Web应用中，自定义属性一般是通过在类路径中（如resources目录）添加一个类似my.properties配置文件（文件名自定义），然后在xml配置中通过 1&lt;util:properties id=\"myProps\" location=\"classpath:my.properties\"/&gt; 引入属性文件。再定义一个Bean来读取这些属性，Bean配置： 12345678&lt;bean class=\"org.springframework.beans.factory.config.MethodInvokingFactoryBean\"&gt; &lt;property name=\"staticMethod\" value=\"cn.jboost.springboot.properties.MyPropertiesUtil.init\"/&gt; &lt;property name=\"arguments\"&gt; &lt;list&gt; &lt;ref bean=\"myProps\"/&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; Bean定义：123456789101112public class MyPropertiesUtil &#123; private static Properties properties; public static void init(Properties props) &#123; properties = props; &#125; public static String getValue(String key) &#123; return properties.getProperty(key); &#125;&#125; 在其它需要访问的地方通过 MyPropertiesUtil.getValue() 方法来访问具体某个属性的值。 Spring Boot自定义属性配置及优先级在Spring Boot中，可以在多个地方配置属性，包括.properties文件，.yaml文件，环境变量， 系统属性，命令行参数等， 这些属性都会被Spring Boot加载到Environment中，可通过@Value注解，Environment实例，或 @ConfigurationProperties注解的类来访问。 属性加载优先级顺序： 如果有使用devtools，devtools 全局设置的属性（用户目录 ~/.spring-bootdevtools.properties） 测试类的注解@TestPropertySource 测试类注解 @SpringBootTest#properties 配置的属性 命令行参数 SPRING_APPLICATION_JSON里的属性（环境变量或系统属性） ServletConfig初始化参数 ServletContext初始化参数 JNDI参数 java:comp/env Java系统属性 System.getProperties() 操作系统环境变量 RandomValuePropertySource 配置的属性 random.* jar包外部的applictaion-{profile}.properties，applictaion-{profile}.yml配置文件 jar包内部的applictaion-{profile}.properties，applictaion-{profile}.yml配置文件 jar包外部的applictaion.properties，applictaion.yml配置文件 jar包内部的applictaion.properties，applictaion.yml配置文件 @Configuration类上的 @PropertySource注解指定的配置文件 默认属性： SpringApplication.setDefaultProperties 上述属性配置，除了粗体标注的外，其它一般应用较少。序号低的配置优先级高于序号高的配置，即如果存在相同属性配置 ，则序号低的配置会覆盖序号高的配置。applictaion-{profile}.properties 一般用于具体某个环境特有的属性配置，如application-dev.properties用于开发环境，可通过 spring.profiles.active=dev指定加载dev环境配置 常用属性配置方式 命令行参数启动Spring Boot应用时，可以指定命令行参数，如：1java -jar springboot-properties.jar --my.name=jboost@command_line 该参数值将会覆盖应用在其它地方配置的同名属性值。命令行参数放在xx.jar 的后面。 可以通过SpringApplication.setAddCommandLineProperties(false) 禁用命令行参数配置 Java系统属性同样在启动Spring Boot应用时，可以指定Java系统属性，一般见于自定义jvm参数，如：1java -Dmy.name=jboost@system_properties -jar springboot-properties.jar Java系统属性放在java命令之后。 操作系统环境变量（实际应用其实较少）配置过JAVA_HOME的应该理解何为环境变量。某些操作系统可能不支持.分隔的属性名，可以改为以下划线连接。Spring Boot将myName, my.name, MY_NAME视为等效。 应用属性配置文件（.properties文件或 .yml文件）.properties文件属性配置格式： 123my.name=jboostmy.list[0]=aaa //配置列表my.list[1]=bbb .yml文件属性配置格式： 12345my: name: devlink list: //配置列表 - aaa - bbb yml中，属性名与值之间冒号后面必须有空格。 应用属性配置文件位置： jar包所在当前目录下的子目录/config（外置属性文件） jar包所在当前目录（外置属性文件） classpath根目录下的子目录/config（内置属性文件） classpath根目录（内置属性文件） 序号低的优先级高于序号高的优先级，即jar包外的配置优先级高于jar包内的配置。同一目录下，.properties文件的优先级高于.yml文件。application-{profile}.properties的优先级高于application.properties。 Spring Boot自定义属性访问方式（参考Github示例测试类） 类中属性上添加 @Value(“${xx}”) 注解方式。如：12@Value(\"$&#123;my.name&#125;\")private String name; 可以指定默认值，如 @Value(“${my.name:jboost}”)， 当my.name未配置时，默认使用值”jboost” 通过@ConfigurationProperties注解的类来访问。如定义：12345678@Component@ConfigurationProperties(prefix = \"my\")public class MyConfigProperties &#123; private String name; private String website; //省略了getter、setter函数&#125; 然后在需要访问的Bean中，通过@Autowired 注入MyConfigProperties实例，通过getName()方法即可访问my.name属性值。123456789@Autowiredprivate MyConfigProperties myConfigProperties;@Testpublic void testConfigurationProperties()&#123; System.out.println(\"test @ConfigurationProperties ==========\"); System.out.println(myConfigProperties.getName()); System.out.println(myConfigProperties.getWebsite());&#125; 通过Environment 实例访问。如：123456789@Autowiredprivate Environment env;@Testpublic void testEnvironment()&#123; System.out.println(\"test Environment ==========\"); System.out.println(env.getProperty(\"my.name\")); System.out.println(env.getProperty(\"my.website\", \"default value\"));&#125; 另外也可以通过 spring-boot-starter-actuator 的接口来查看项目加载的属性配置，在pom.xml中加入 spring-boot-starter-actuator 依赖，因为 spring-boot-starter-actuator 在2.x版本中，出于安全性考虑，将actuator 控件中的端口，只默认开放/health 和/info 两个端口，其他端口默认关闭，因此需要添加配置management.endpoints.web.exposure.include= *，management.endpoints.web.exposure.exclude=beans,trace，management.endpoint.health.show-details=ALWAYS，启动项目后，访问 http://localhost:8080/actuator/env ，返回的 propertySources 即为加载的所有属性源，优先级从上往下依次降低，与上文所述优先级相符 本文示例项目源码地址：https://github.com/ronwxy/springboot-demos/tree/master/springboot-properties 我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ——————————————————————————————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"Spring Boot从入门到实战（二）：第一个Spring Boot应用","slug":"springboot-firstapp","date":"2019-06-06T12:46:50.000Z","updated":"2019-07-22T10:27:17.454Z","comments":true,"path":"springboot-firstapp.html","link":"","permalink":"http://blog.jboost.cn/springboot-firstapp.html","excerpt":"Spring Boot应用可以通过如下三种方法创建： 通过 https://start.spring.io/ 网站创建 通过 Spring Initializr 创建 自主创建","text":"Spring Boot应用可以通过如下三种方法创建： 通过 https://start.spring.io/ 网站创建 通过 Spring Initializr 创建 自主创建 推荐开发工具 JDK 1.8+ IntelliJ IDEA maven 3.3+ 在开始之前，先确认是否安装上述工具，在命令行输入 java -version 查看JDK是否正确安装， 输入 mvn -version 查看maven是否正确安装，如果未正确安装，请先查阅相关文档完成安装。12345678910111213PS D:\\&gt; java -versionjava version \"1.8.0_201\"Java(TM) SE Runtime Environment (build 1.8.0_201-b09)Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode)PS D:\\&gt;PS D:\\&gt;PS D:\\&gt; mvn -versionApache Maven 3.6.0 (97c98ec64a1fdfee7767ce5ffb20918da4f719f3; 2018-10-25T02:41:47+08:00)Maven home: D:\\tool\\apache-maven-3.6.0\\bin\\..Java version: 1.8.0_201, vendor: Oracle Corporation, runtime: C:\\Program Files\\Java\\jdk1.8.0_201\\jreDefault locale: zh_CN, platform encoding: GBKOS name: \"windows 10\", version: \"10.0\", arch: \"amd64\", family: \"windows\"PS D:\\&gt; 1. 通过 https://start.spring.io/ 网站创建进入 https://start.spring.io/，填写对应的信息，如下图所示其中project选 Maven Project， Spring Boot版本选 2.1.5 版， Project Metadata部分， Group一般用你域名的倒序字符串，Artifact即项目名称，选择Packaging类型为Jar，Java版本为8，在Dependencies部分输入Web，选中第一个Spring Web Starter，然后点击“Generate the project”按钮，下载生成的项目。解压项目，在IntelliJ IDEA中 File -&gt; Open 选中项目解压目录打开，即可看到生成的项目结构如下图具体各文件含义后面详述。 2. 通过Spring Initializr创建（推荐）IntelliJ IDEA中File -&gt; New -&gt; Project...打开新建项目窗口（这里也可以选择New Module, IDEA的Project类似于Eclipse的Workspace，Module则类似于Eclipse的Project，有时候为了将一些项目统一管理，可以建一个Project，然后在Project内部建立Module），如下图所示 选择Spring Initializr，点击Next，填写相应信息， 如下图所示 点击Next，选择Spring Boot版本以及相应依赖，如下图（这里选择2.1.5版本及Spring Web Starter依赖） 然后依次点击Next, Finish完成项目创建。可以看到创建的项目结构与第一种方法一致。 有的旧IDEA版本下项目可能不能编译，IDE未将其识别为maven项目，只需在pom.xml文件上右键，点击Add as Maven project即可。 3. 自主创建自主创建即像普通Java Maven项目一样，先创建maven项目，然后参考1、2方法中创建的项目结构与目录，手动进行添加。 上述三种创建方法，第1种需要网站生成再下载解压导入，第2种直接基于IDE创建，第3种完全自主手动创建。实际开发中推荐采用第2种创建初始项目原型，再根据具体需求删除或添加相应目录与文件。 4. 项目结构通过上述方法创建的项目，结构如下图所示 其中 SpringbootFirstappApplication 为项目入口类，通过SpringApplication.run()方法来启动项目 入口类上的注解 @SpringBootApplication 表明，这是一个Spring Boot项目，它会为你自动做一些Spring Boot项目的处理 resources 下的static目录为静态资源目录，可以放置js，css，img之类的资源，templates目录可放置模板文件，一般做前后端分离开发，这两个目录可删除 application.properties 文件为项目的配置文件，可在该文件中配置项目所需要的各项配置属性 SpringbootFirstappApplicationTests 生成的测试类，可基于此进行单元测试编写 pom.xml即为maven配置文档，可看到项目已继承spring-boot-starter-parent，并且引入了spring-boot-starter-web，spring-boot-starter-test两项依赖，以及spring-boot-maven-plugin 5. 运行 上述创建的项目可直接运行，大致有如下几种运行方式： 直接在项目入口类SpringbootFirstappApplication中右键，点击Run &#39;SpringbootFirstappAp...&#39;运行 在项目根目录下打开终端，或IDEA的Terminal中执行mvn spring-boot:run（前提是项目pom.xml文件中引入了spring-boot-maven-plugin） 使用mvn package打包，然后通过java -jar target\\springboot-firstapp-1.0.0-SNAPSHOT.jar 启动（一般用于远程环境的部署启动） 如果打包成war，将war包部署到tomcat等Servlet容器运行 项目启动后，从启动日志可看出默认端口为8080，但打开 http://localhost:8080 会显示一个404报错页面，这是因为我们还没有编写任何服务。下面我们添加一个非常简单的Rest服务接口，在项目的根包下（我这里是cn.jboost.springboot.firstapp，实际项目中一般会创建一个controller的子包）添加HelloController类，代码如下 1234567@RestController(\"/hello\")public class HelloController &#123; @GetMapping public String hello(@RequestParam(name = \"name\")String name)&#123; return \"您好，\" + name; &#125;&#125; 其中@RestController注解会将返回结果以字符串的方式解析，@GetMapping等效于@RequestMapping(method = {RequestMethod.GET})重启应用，然后浏览器地址栏中输入 http://localhost:8080/hello?name=jboost， 页面输出如下图： 至此，一个可运行的Web项目即已搭建完成，是不是非常简单。 本文示例项目源码地址：https://github.com/ronwxy/springboot-demos/tree/master/springboot-firstapp我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ——————————————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"Spring Boot从入门到实战（一）：Spring Boot简介","slug":"springboot-overview","date":"2019-06-06T06:29:02.000Z","updated":"2019-07-22T10:26:52.326Z","comments":true,"path":"springboot-overview.html","link":"","permalink":"http://blog.jboost.cn/springboot-overview.html","excerpt":"Spring Boot这几年非常流行，差不多是基于Spring框架应用开发的首选，同时在微服务架构领域，如Spring Cloud 框架中，Spring Boot也是基础，因此掌握Spring Boot，应成为Java开发人员必不可少的技能。","text":"Spring Boot这几年非常流行，差不多是基于Spring框架应用开发的首选，同时在微服务架构领域，如Spring Cloud 框架中，Spring Boot也是基础，因此掌握Spring Boot，应成为Java开发人员必不可少的技能。 简述传统的基于Spring的Java Web应用，需要配置 web.xml, applicationContext.xml 等大量xml配置信息，然后将应用打成war包放入web应用服务器(如Tomcat, Jetty等)中运行。有过实践经验的开发者应能体会到这个过程繁杂且重复。Spring Boot将这种繁杂且重复的工作通过自动化配置等手段实现，从而将开发者从复杂的配置工作中解放出来，能够更专注于业务逻辑的开发。因此，Spring Boot并不是Spring的替代解决方案，它本身并不提供Spring框架的核心特性以及扩展功能，而是和Spring框架紧密结合用于提升Spring开发者体验，提高开发效率的的工具框架。截至本文，Spring Boot最新GA版本为2.1.5。 特性Spring Boot框架大致包括如下特性： 自动化配置。Spring Boot 通过autoconfiguration的方式（后面会详细讨论何为autoconfiguration）来简化配置管理。比如如果需要访问数据库，则只需要引入相应的starter依赖包，Spring Boot便会自动为你配置访问数据库所需要的Bean，如 DataSource， JdbcTemplate等。使用Spring Boot，项目中几乎不需要任何 xml 配置文件。 内嵌的Web服务容器。Spring Boot内嵌了Tomcat、Jetty、Undertow。因此，Spring Boot应用可以像普通java应用一样打成jar包直接通过 java -jar 执行，而不需传统web应用一样需要打成war包部署到独立的web服务容器中。 简化依赖管理。Spring Boot官方提供了大量的starter依赖包，帮你管理了使用某个功能所需要的依赖，开发者只需要引入starter依赖，即可使用对应的功能。如spring-boot-starter-web，spring-boot-starter-jdbc等。同时自己也可以自定义starter，为某些通用功能提供模块化共享支持。 提供生产环境级的应用配置、度量指标、操作控制接口。Spring Boot的spring-boot-starter-actuator提供了查看应用配置信息，获取应用运行指标，以及控制应用（如关闭应用）三种类型的接口。通过这些接口，可以排查问题，监控服务运行情况等。 Spring Boot的这些特性，使得应用Spring Boot开发Web应用非常便捷、高效，因此在快速应用开发（Rapid Application Development）领域以及微服务架构方面，Spring Boot都是比较好的选择。 工具该序列涉及的开发工具包括但不限于： JDK 1.8+ , 一般用的是1.8 Maven 3.3+ , 我们用的是Maven3.6.0 IntelliJ IDEA Ultimate Edition， 需要激活，参考这里 MySQL，可选，数据库访问示例需要 Redis， 可选，缓存示例需要 我的个人博客地址：http://blog.jboost.cn我的头条空间： https://www.toutiao.com/c/user/5833678517/#mid=1636101215791112我的github地址：https://github.com/ronwxy我的微信公众号：jboost-ksxy ——————————————————————————————————————————————————————————————— 欢迎关注我的微信公众号，及时获取最新分享","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.jboost.cn/categories/SpringBoot/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jboost.cn/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://blog.jboost.cn/tags/springboot/"}]},{"title":"写在前面","slug":"ahead","date":"2019-06-05T08:48:37.000Z","updated":"2019-06-10T07:36:24.244Z","comments":true,"path":"ahead.html","link":"","permalink":"http://blog.jboost.cn/ahead.html","excerpt":"","text":"一点感悟在软件与互联网技术领域从业多年，从一个一知半解的职场菜鸟成长为行业“老司机”，也从一个邯郸学步的技术新手晋升成为能带领团队披荆斩棘，在技术范畴能掌握话语权的技术管理者。其间也与大多数同行一样，踩过不少坑，加过不少班，背过不少锅……，但同时，也为自己不断成长、进步——包括技术、能力层面，也包括薪酬、职位层面，而感到欣慰。但技术领域日新月异，接触的越多，越发现自己的无知，因此 Stay hungry，Stay foolish，保持持续学习的热情，永远不要满足于现状，才能保持自身竞争力，不至于在年龄增长时，出现所谓的“中年危机”。 一点初衷大学期间也曾玩过新浪博客，写过一些心路历程与人生感悟（^_^），随着年龄的增长，逐渐失去了用文字来抒发情感的激情。工作后，开始接触技术博客，也断断续续写过一些分享，但终因阶段性忙或懒惰，没能坚持下来。与之前抒发情感与感悟不同，技术博客更多的是一种经验的自我梳理总结与分享。一方面为那些踏入职场不久实践经验较缺乏的同行提供参考，另一方面也是对自我日常技术工作的整理，以达到“好记性不如烂笔头”的效果。因此，虽然现今从事一线编码工作相对较少，心中一直还是有一个将以往及现在所接触的实践经验记录与分享出来的想法。于是，花了点时间整了这个博客，希望能坚持下去。 一点期望凡事做了，总希望有所回报。整理文章其实需要花费不少时间与精力，因此也希望发出来的分享能为大家带来切实的收获，获得大家的肯定与良性反馈。有更好建议，也欢迎大家通过留言或其它方式与我交流。希望这是一个好的开始，加油！","categories":[],"tags":[]}]}